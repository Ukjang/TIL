{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3fhVcu7puEv",
        "outputId": "83c4c54e-9f84-4572-d229-7df960c11056"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "f8y1Fk0KczxA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "import re\n",
        "import random\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "r3xi6tPMczxH"
      },
      "outputs": [],
      "source": [
        "# data = pd.read_csv('Textranked.csv')\n",
        "# data.head()\n",
        "\n",
        "# # data.dropna(inplace=True)\n",
        "# # data.rename(columns={'본문':'question', '답변':'answer'}, inplace=True)\n",
        "# # data.to_csv('prep_data_dotsplits.csv', index=False, encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "c-7o54LdczxJ"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class QNA:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1:\"EOS\"}\n",
        "        self.n_words = 2\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split('.'):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        for sen in word:\n",
        "            if sen not in self.word2index:             \n",
        "                self.word2index[sen] = self.n_words\n",
        "                self.word2count[sen] = 1\n",
        "                self.index2word[self.n_words] = sen\n",
        "                self.n_words += 1\n",
        "            else:\n",
        "                self.word2count[sen] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gwKOho4ZczxK"
      },
      "outputs": [],
      "source": [
        "def normalizeString(s):\n",
        "    s = re.sub(r\"([.!?])\", r\" \", s)\n",
        "    s = re.sub(r\"[^가-힣.!?]+\", r\" \", s)\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yMtd_cjZczxL"
      },
      "outputs": [],
      "source": [
        "def readchat(question, answer, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    lines = open('/content/drive/MyDrive/multi/202206/0609/data/prep_data_dotsplits.csv', encoding='utf-8').read().strip().split('\\n')[1:]\n",
        "    \n",
        "    pairs = [[normalizeString(s) for s in l.split(',')] for l in lines]\n",
        "\n",
        "    if reverse:\n",
        "        paris = [list(reversed(p)) for p in pairs]\n",
        "        input_q = QNA(answer)\n",
        "        output_a = QNA(question)\n",
        "    else:\n",
        "        input_q = QNA(question)\n",
        "        output_a = QNA(answer)\n",
        "    \n",
        "    return input_q, output_a, pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-T96fC-dczxM"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 2000\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INrWGRYbczxN",
        "outputId": "2999b901-26bb-4ebe-dcb2-7179749406ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 18271 sentence pairs\n",
            "Counted words:\n",
            "answer 1657\n",
            "question 1171\n",
            "['전 세입자입니다 년에 만원에 세입자로 들어가서 현재 까지 살고 있습니다 그런데 제가 힘이들어서 세를 밀렸습니다 그래서 집주인께서 월말에 만원 월말까지 만원 을 지불안하면 방을 빼 깻다고 했습니다 그래서 월 일 날 두달분을 지불하고 월 일 까지 두달분을 지불하기로 했는데 직장에서 돈이 나오지가 않아서 월 말일날 지불했습니다 그런데 집주인께서 나가라고 합니다 현재 제가 밀려 있는 방세는 개월 정도 밀려 잇는데 월 말까지 집을 비우라고 합니다 그래서 제가 돈이 없어서 못나간다고 말했습니다 그랫더니만 월 달에 집주인 아저씨께서 집수리를 해야 하니 꼭옥 나가야 한다고 합니다 그래서 저는 못나간다고 말햇습니다 돈이 없다 라고영 그래더니만 집주인께서 명도 소송을 진행할거니깐 방 어더서 나가라고 합니다 오늘 은 집주인께서 법원에 지급 명령을 신청 하고 왓다고 문자가왔습니다 방 어드면 취소할테니 그럴게 알라고요 그리고 일방적으로 나가라고만 하는데 어떻게해야 하나요 저는 현재 통장 잔고나 부동산 같은게 하나도 없습니다 질문 제가 안나간다고 버티면 어떻게 되나요 명도소송에서 지게 되면 강제로 제짐을 뺄수 있는지용 그리고 나간다면 제가 이사 비용을 받을수있는지용 명도 소송해서 패소까지 기간이 얼마나 걸릴까요 현재 저는 수입이 없습니다 프리랜서 라서영 그런데 자꾸 나가 라고 하니 어떻게 해야 할지 모르겠습니다', '우선 결론부터 말씀드리면 집주인이 명도소송을 진행하여 승소하면 명도집행을 단행하게 됩니다 네 그렇습니다 귀하가 소송비용을 부담하게 됩니다 명도소송은 통상 개월 정도 소요됩니다 아래 내용은 채권자 입장에서 정리한 것입니다 채무자 관점에서 읽어보시면 나름대로의 해결방향을 찾을 수 있을 것입니다 채권추심에서 가장 중요한 가지는 정보력 신속 정확입니다 왜냐하면 다른 채권자들보다 먼저 재산을 확보해야만 자금을 회수할 수 있기 때문입니다 기타 채권추심에 필요한 집행 권원 및 강제집행 방법에 대해서는 아래 내용을 참고하시기 바랍니다 채권추심에 필요한 집행권원및 강제집행 방법에 대해서는 아래 내용을 참고하시기 바랍니다 사전준비 내용증명과 재산조사 본격적인 추심에 들어가기 앞서 채무자에게 내용증명을 보내는 것이 좋습니다 내용증명은 그 자체로 최고 라는 법률적 효과가 인정되고 이 단계에서 추심이 완료되는 경우도 있습니다 아울러 입증자료가 부족할 경우 증거자료 확보라는 의미도 있습니다 또한 추심에 들어가 비용과 시간을 고려할 때 내용증명을 보내 채무자의 반응을 살펴보는 것도 좋은 방법입니다 변호사 명의로 내용증명을 보낼 수 있다면 더욱 효과가 있습니다 또한 추심절차 진행에 앞서 미리 재산조사아래에서 설명드릴 재산조회 와는 별개의 절차입니다 를 한 후 추심 가능성을 미리 가늠해 볼 필요도 있습니다 집행권원 채권 추심을 하려면 가장 먼저 해야 하는 일은 집행권원 을 확보하는 것입니다 집행권원 이란 일정한 사법상의 이행청구권의 존재 및 범위를 표시하고 그 청구권에 집행력을 인정한 공정의 문서를 말법원실무제요 참고하는데 확정된 종국판결 가집행의 선고가 있는 종국판결 외국법원의 판결에 대한 집행판결 소송상의 화해조서 청구의 인낙조서 확정된 지급명령 가압류 가처분명령 확정된 화해권고결정 등이 있습니다 만일 계약서 차용증만 있고 집행권원 이 없다면 먼저 지급명령신청을 하거나 소송을 제기해서 집행권원을 획득해야 합니다 그래야 채권추심 절차를 시작 할 수 있습니다 부동산 강제집행 채권 추심에 있어서 가장 확실 하고 효과 적인 방법은 부동산에 대한 강제집행 즉 경매를 신청하는 것입니다 이를 위해서는 부동산이 있는지 있다면 부동산의 주소는 어디인지를 알아야 하는데 채무자의 주민등록초본상 주소지 등기부등본을 열람하거나 재산명시 신청 및 재산조회신청을 통해 알아냅니다 필요한 경우 재산조사 전문 인력을 활용하는 방법도 있습니다 부동산이 확인되었다면 즉시 경매를 신청하세요 물론 경매비용으로 약 여만이 필요하지만 경매비용은 경락대금에서 최우선 적으로 회수됩니다 경매가 시작되면 의 경우 채무자가 경매취하를 요청하면서 자발적으로 채무를 변제합니다 예금채권 압류 채권 추심에서 있어서 가장 쉽고 빠른 방법이 있다면 채무자의 예금을 추심하는 것입니다 기간은 채권추심명령까지 약 일 이후 채권추심실행까지 약 일 등 일 정도가 걸립니다 예금채권 압류는 은행 별로 진행합니다 따라서 구체적인 계좌번호는 몰라도 됩니다 채무자의 주 거래은행을 중심으로 개 은행을 임의로 선정해서 진행하시는 것이 가장 효과적입니다 실제로 예금채권이 추심되면 반드시 추심신고 를 하셔야 합니다 그래야 다른 채권자들의 배당요구를 물리칠 수 있습니다 기타 강제집행이 가능한 재산 기타 강제집행이 가능한 재산에는 선박 자동차 건설기계 유체동산집이나 사무실에 에 있는 가전제품 가구 등 보험금 골프회원권 주식주권발행전 주식 및 신주인수권 예탁 유가증권 포함 특허권 의장권 실용신안권 저작권 사원의 지분권 등이 있습니다 채무자가 회사이거나 상인인 경우에는 매매대금 채권 공사대금 채권 등에 대한 강제집행이 매우 유력합니다 다만 이를 위해서는 채권을 특정 해야 하는데 치밀한 사전 조사가 필요합니다 재산명시 신청 및 재산 조회 채권자는 법원에 채무자로 하여금 강제집행의 대상이 되는 재산과 그 재산의 일정한 기간 내의 처분상황을 명시한 재산목록을 제출 하도록 명령 을 내려달라는 재산명시 신청을 할 수 있습니다 민사집행법 제 조나아가 채무자가 재산목록을 제출하면 위 목록의 진실여부를 확인하기 위해 재산조회를 신청할 수 있습니다 재산조회는 국가 및 공공기관 보유 데이터 를 사용하여 채무자의 재산현황을 확인하는 가장 확실한 방법입니다 채무불이행자 명부 등재신청 필요한 경우 채권자는 법원에 채무자에 대한 인적사항 등을 법원이 관리하는 채무불이행자 명부에 기록해서 일반인이 열람할 수 있게 비치해달라 는 채무불이행자 명부 등재 신청을 할 수 있습니다 민사집행법 제 조 참고 채무자의 경제활동이 극도로 제한됩니다 그러나 사견 으로는 채무불이행자 명부 등록 신청을 가급적 하지 않는 것이 좋다고 생각합니다 왜냐하면 채무자가 활발한 경제활동을 할 수 있어야 이를 통해 돈을 벌고 그래야 돈을 받아 낼 수 있는 확률도 더 높아지기 때문입니다 특별한 수단 사기죄 고소 채무자가 변제자력 및 변제의사가 없음에도 불구하고 돈을 빌린 것이라면 사기죄 로 고소할 수 있습니다 피해금액이 억 원이 넘고 범죄 혐의가 일응 인정된다면 채무자는 구속될 확률도 있는데 이 경우 채무자는 석방되기 위해서라도 채무를 변제할 것입니다 그러나 형사고소는 민감한 부분이 많고 최악의 경우 역공 을 받을 수도 있습니다 따라서 반드시 변호사와 직접 상담을 한 후에 진행해야 합니다 특별한 수단 사해행위 취소 소송 채무자가 채무자 명의 재산을 제 자주로 배우자 가족 등에게 빼 돌렸다면 이에 대해서 사해행위 취소 소송을 제기하여 위 재산을 환원시킨 후 강제집행을 할 수 있습니다']\n"
          ]
        }
      ],
      "source": [
        "def prepareData(question, answer, reverse=False):\n",
        "    input_q, output_a, pairs = readchat(question, answer, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    for pair in pairs:\n",
        "        input_q.addSentence(pair[0])\n",
        "        output_a.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_q.name, input_q.n_words)\n",
        "    print(output_a.name, output_a.n_words)\n",
        "    return input_q, output_a, pairs\n",
        "\n",
        "input_q, output_a, pairs = prepareData('question', 'answer', True)\n",
        "print(random.choice(pairs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "oYrxPkwtczxP"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "UaBNEqW0czxR"
      },
      "outputs": [],
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "-nCbAWDfczxS"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(QNA, sentence):\n",
        "    word2index_list = []\n",
        "    for sen in sentence.split('.'):\n",
        "        for word in sen:\n",
        "            word2index_list.append(QNA.word2index[word])\n",
        "    return word2index_list\n",
        "\n",
        "\n",
        "def tensorFromSentence(QNA, sentence):\n",
        "    indexes = indexesFromSentence(QNA, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=DEVICE).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_q, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_a, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "lwCS0GjMczxT"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "    if input_length >= max_length :\n",
        "        input_length = max_length - 1\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=DEVICE)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=DEVICE)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing 포함: 목표를 다음 입력으로 전달\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Teacher forcing 미포함: 자신의 예측을 다음 입력으로 사용\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # 입력으로 사용할 부분을 히스토리에서 분리\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "9z_qaI_aczxU"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "w-ENEYUxczxV"
      },
      "outputs": [],
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # print_every 마다 초기화\n",
        "    plot_loss_total = 0  # plot_every 마다 초기화\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "DfsqroyBczxV"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # 주기적인 간격에 이 locator가 tick을 설정\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "PkfSIYsEczxW"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_q, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=DEVICE)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=DEVICE)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_a.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "4K2LE7v-czxW"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyRLuArvczxX"
      },
      "outputs": [],
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_q.n_words, hidden_size).to(DEVICE)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_a.n_words, dropout_p=0.1).to(DEVICE)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder1.size(0)"
      ],
      "metadata": {
        "id": "gZI4P7qG_xYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence2 = '직원과 사장으로 만나신분에게 대가성없이 통장을 대여해드렸습니다. 제 명의로 사업자를 내서 사업을 했으나 빛뿐이였습니다.'"
      ],
      "metadata": {
        "id": "A89bz8pM22hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1 = pairs[0][0]\n",
        "sentence1"
      ],
      "metadata": {
        "id": "biUGBSi-1r-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_q.word2index"
      ],
      "metadata": {
        "id": "lRk6nIsB3bCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(encoder1, attn_decoder1, sentence1)"
      ],
      "metadata": {
        "id": "z2iOYwfWw4Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(encoder1, attn_decoder1, sentence2)"
      ],
      "metadata": {
        "id": "xOW33aW53BEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dZw1pxmczxX"
      },
      "outputs": [],
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efs6ZsNmczxY"
      },
      "outputs": [],
      "source": [
        "pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdh3AwdKczxY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "68756eb6c044f31c46e3e1f38723aea1f0146198488dd3d60c0e4241eb6f7dd0"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "seq2seq.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}