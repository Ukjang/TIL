{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torchtext\n",
        "torchtext.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uM7lWyOa3Lk8",
        "outputId": "7f05e0e7-45c7-4307-920c-44d946028760"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.8.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.8.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mUom6Fe0GNr",
        "outputId": "0234df40-bba7-4a92-f4eb-878d90953889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.8.1\n",
            "  Downloading torchtext-0.8.1-cp39-cp39-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchtext==0.8.1) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchtext==0.8.1) (2.27.1)\n",
            "Collecting torch==1.7.1\n",
            "  Downloading torch-1.7.1-cp39-cp39-manylinux1_x86_64.whl (776.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.8/776.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext==0.8.1) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.7.1->torchtext==0.8.1) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.8.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.8.1) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.8.1) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext==0.8.1) (1.26.15)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.1+cu116\n",
            "    Uninstalling torch-1.13.1+cu116:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmXA0CBly-MV",
        "outputId": "7772b0c2-fa5e-429f-ddc7-0bf1f5a476bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:05<00:00, 16.5MB/s]\n",
            "/usr/local/lib/python3.9/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
          ]
        }
      ],
      "source": [
        "from torchtext import data \n",
        "from torchtext import datasets\n",
        "\n",
        "TEXT = data.Field(lower = True, batch_first = True)\n",
        "LABEL = data.Field(sequential=True)\n",
        "\n",
        "train, test = datasets.IMDB.splits(TEXT, LABEL)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "from torchtext import data, datasets\n",
        "TEXT = data.Field(batch_first = True, \n",
        "                  fix_length = 500,\n",
        "                  tokenize = str.split,\n",
        "                  pad_first = True,\n",
        "                  pad_token = '[PAD]',\n",
        "                  unk_token='[UNK]')\n",
        "\n",
        "LABEL = data.LabelField(dtype = torch.float)\n",
        "\n",
        "train_data, test_data  = datasets.IMDB.splits(text_field = TEXT,\n",
        "                                             label_field = LABEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9h7J7jk3jCH",
        "outputId": "1e4db9f8-6345-4906-c92a-6608c4756f4a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchtext/data/field.py:150: UserWarning: LabelField class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Train_data_Length : {len(train_data.examples)}')\n",
        "print(f'test_data_Length : {len(test_data.examples)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TJO0HPW3r_e",
        "outputId": "3f1c1c66-9e8c-4602-8bf6-281923703216"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_data_Length : 25000\n",
            "test_data_Length : 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.fields)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYbBYhz536Kj",
        "outputId": "7792704b-c875-4435-f0ff-cced4cd2dc43"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': <torchtext.data.field.Field object at 0x7f2c2d80a7f0>, 'label': <torchtext.data.field.LabelField object at 0x7f2c2d829730>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('---Data Sample---')\n",
        "print('\\nInput : ')\n",
        "print(' '.join(vars(train_data.examples[1])['text']), '\\\\n')\n",
        "print('\\nLabel : ')\n",
        "print(vars(train_data.examples[1])['label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o58zTtix37WH",
        "outputId": "35a739aa-5d76-4c2e-b4af-20ee5bd96cbf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---Data Sample---\n",
            "\n",
            "Input : \n",
            "Certainly any others I have seen pale in comparison. The series gives balanced coverage to all theatres of operation. No one country is given undue credit for the Allied victory. Laurence Olivier brings great weight and dignity to his role as narrator. \\n\n",
            "\n",
            "Label : \n",
            "pos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def PreProcessingText(input_sentence) :\n",
        "    input_sentence = input_sentence.lower()\n",
        "    # <br /> 처리\n",
        "    input_sentence = re.sub('<[^>]*>', repl= ' ', string = input_sentence)\n",
        "    input_sentence = re.sub('[^a-z0-9]', ' ', input_sentence)\n",
        "    input_sentence = re.sub('\\\\s+', ' ', input_sentence)\n",
        "    if input_sentence :\n",
        "        return input_sentence\n",
        "for example in train_data.examples :\n",
        "    vars(example)['text'] = PreProcessingText(' '.join(vars(example)['text'])).split()\n",
        "\n",
        "for example in test_data.examples :\n",
        "    vars(example)['text'] = PreProcessingText(' '.join(vars(example)['text'])).split()\n"
      ],
      "metadata": {
        "id": "00ZzU5o_4fhB"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.build_vocab(train_data,\n",
        "                 min_freq=2,\n",
        "                 max_size = None,\n",
        "                 vectors  = 'glove.6B.300d')\n",
        "LABEL.build_vocab(train_data)"
      ],
      "metadata": {
        "id": "hq3bxM5E7a2J"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Vocab Size : {len(TEXT.vocab)}')\n",
        "\n",
        "print('Vocab Examples : ')\n",
        "for idx, (k, v) in enumerate(TEXT.vocab.stoi.items()) :\n",
        "    if idx >= 10 :\n",
        "        break \n",
        "    print('\\\\t', k, v)\n",
        "\n",
        "print('---------------------------------------')\n",
        "\n",
        "print(f'Label Size : {len(LABEL.vocab)}')\n",
        "\n",
        "for idx, (k, v) in enumerate(LABEL.vocab.stoi.items()) :\n",
        "    if idx >= 10 :\n",
        "        break \n",
        "    print('\\\\t', k, v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmAVMUMn83Rf",
        "outputId": "51545a4a-f70f-4250-9965-8ca1ce7f8f5d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab Size : 340\n",
            "Vocab Examples : \n",
            "\\t [UNK] 0\n",
            "\\t [PAD] 1\n",
            "\\t a 2\n",
            "\\t b 3\n",
            "\\t ab 4\n",
            "\\t ba 5\n",
            "\\t 10 6\n",
            "\\t bab 7\n",
            "\\t 2 8\n",
            "\\t bb 9\n",
            "---------------------------------------\n",
            "Label Size : 2\n",
            "\\t neg 0\n",
            "\\t pos 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random \n",
        "\n",
        "train_data, valid_data = train_data.split(random_state= random.seed(0),\n",
        "                                          split_ratio = 0.8)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(datasets = (train_data, valid_data, test_data), batch_size = 32, device = device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxgGYYTW9beb",
        "outputId": "f207977e-4c0d-46e3-a315-30efbb51a67f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn \n",
        "class SentenceClassification(nn.Module) :\n",
        "    def __init__(self, **model_config) :\n",
        "        super(SentenceClassification, self).__init__()\n",
        "\n",
        "        if model_config['emb_type'] == 'glove' or 'fasttext' :\n",
        "            self.emb = nn.Embedding(model_config['vocab_size'],\n",
        "                                    model_config['emb_dim'],\n",
        "                                    _weight = TEXT.vocab.vectors)\n",
        "            \n",
        "        else :\n",
        "            self.emb = nn.Embedding(model_config['vocab_size'],\n",
        "                                    model_config['emb_dim'])\n",
        "            \n",
        "        self.bidirectional = model_config['bidirectional']\n",
        "        self.num_directions = 2 if model_config['bidirectional'] else 1 \n",
        "        self.model_type = model_config['model_type']\n",
        "\n",
        "        self.RNN = nn.RNN(input_size = model_config['emb_dim'],\n",
        "                          hidden_size = model_config['hidden_dim'],\n",
        "                          dropout = model_config['dropout'],\n",
        "                          bidirectional = model_config['bidirectional'],\n",
        "                          batch_first = model_config['batch_first'])\n",
        "        \n",
        "        self.LSTM = nn.LSTM(input_size = model_config['emb_dim'],\n",
        "                          hidden_size = model_config['hidden_dim'],\n",
        "                          dropout = model_config['dropout'],\n",
        "                          bidirectional = model_config['bidirectional'],\n",
        "                          batch_first = model_config['batch_first'])\n",
        "        \n",
        "        self.GRU = nn.GRU(input_size = model_config['emb_dim'],\n",
        "                          hidden_size = model_config['hidden_dim'],\n",
        "                          dropout = model_config['dropout'],\n",
        "                          bidirectional = model_config['bidirectional'],\n",
        "                          batch_first = model_config['batch_first'])\n",
        "        \n",
        "        self.fc = nn.Linear(model_config['hidden_dim'] * self.num_directions,\n",
        "                            model_config['output_dim'])\n",
        "\n",
        "        self.drop = nn.Dropout(model_config['dropout'])\n",
        "\n",
        "\n",
        "    def forward(self, x) :\n",
        "        emb = self.emb(x)\n",
        "\n",
        "        if self.model_type == 'RNN' :\n",
        "            output, hidden = self.RNN(emb)\n",
        "        elif self.model_type == 'LSTM' :\n",
        "            output, hidden = self.LSTM(emb)\n",
        "        elif self.model_type == 'GRU' :\n",
        "            output, hidden = self.GRU(emb)\n",
        "        else :\n",
        "            raise NameError('Select model_type in [RNN, LSTM, GUR]')\n",
        "\n",
        "        last_output = output[:, -1, :]\n",
        "\n",
        "        return self.fc(self.drop(last_output))"
      ],
      "metadata": {
        "id": "s7fRmfNF963-"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_for_check = next(iter(train_iterator))\n",
        "print(sample_for_check)\n",
        "print(sample_for_check.text)\n",
        "print(sample_for_check.label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R96q0k8_j0J",
        "outputId": "98a3cc55-2f74-437c-9fe3-af612d659e6a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[torchtext.data.batch.Batch of size 32]\n",
            "\t[.text]:[torch.LongTensor of size 32x500]\n",
            "\t[.label]:[torch.FloatTensor of size 32]\n",
            "tensor([[1, 1, 1,  ..., 2, 2, 2],\n",
            "        [1, 1, 1,  ..., 2, 2, 2],\n",
            "        [1, 1, 1,  ..., 2, 2, 3],\n",
            "        ...,\n",
            "        [1, 1, 1,  ..., 3, 2, 2],\n",
            "        [1, 1, 1,  ..., 2, 2, 2],\n",
            "        [1, 1, 1,  ..., 2, 2, 2]])\n",
            "tensor([1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
            "        1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1.])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "AiPxR4qoEvHK"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = {'emb_type' : 'glove', 'emb_dim' : 300, 'vocab_size' : len(TEXT.vocab), 'batch_size' : 32}\n",
        "model_config.update(dict(batch_first = True, \n",
        "                         model_type = 'RNN',\n",
        "                         bidirectional = True,\n",
        "                         hidden_dim = 128,\n",
        "                         output_dim = 1,\n",
        "                         dropout = 0))\n",
        "model = SentenceClassification(**model_config).to(device)\n",
        "loss_fn = nn.BCEWithLogitsLoss().to(device) \n",
        "\n",
        "def binary_accuracy(pred,y) :\n",
        "    rounded_preds = torch.round(torch.sigmoid(pred))\n",
        "    correct = (rounded_preds == y).float()\n",
        "    acc = correct.sum() / len(correct) \n",
        "    return acc \n",
        "\n",
        "predictions = model.forward(sample_for_check.text).squeeze()\n",
        "loss = loss_fn(predictions, sample_for_check.label)\n",
        "acc = binary_accuracy(predictions, sample_for_check.label)\n",
        "\n",
        "print(predictions)\n",
        "print(loss.item(), acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dt64IB-XBVOY",
        "outputId": "e5c16808-e4f6-4330-de83-191553b78c39"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.0717,  0.0470, -0.1022,  0.2179,  0.0679,  0.0679, -0.1241,  0.1152,\n",
            "         0.0636, -0.1022,  0.0687,  0.0677,  0.0854,  0.0998,  0.1848,  0.0633,\n",
            "         0.0679, -0.1022,  0.0679,  0.0357,  0.0697,  0.0534,  0.0679,  0.1529,\n",
            "         0.2122,  0.1775,  0.1346,  0.0721, -0.0441, -0.0415,  0.0686,  0.0369],\n",
            "       grad_fn=<SqueezeBackward0>)\n",
            "0.6852755546569824 tensor(0.5625)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_for_check.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bPksuaoDcHP",
        "outputId": "1dadeb3b-6f70-4299-8a98-a5ed84a6bfed"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  1,  1,  ...,  2,  8,  2],\n",
              "        [ 1,  1,  1,  ...,  3,  3,  2],\n",
              "        [ 1,  1,  1,  ...,  3,  2,  3],\n",
              "        ...,\n",
              "        [ 1,  1,  1,  ...,  2, 26,  2],\n",
              "        [ 1,  1,  1,  ...,  2,  2,  2],\n",
              "        [ 1,  1,  1,  ...,  2,  2,  2]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IegW0cVwClBM",
        "outputId": "ead3bf5f-4029-440c-d25c-b25d7fa76d19"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'emb_type': 'glove',\n",
              " 'emb_dim': 300,\n",
              " 'vocab_size': 340,\n",
              " 'batch_first': True,\n",
              " 'model_type': 'RNN',\n",
              " 'bidirectional': True,\n",
              " 'hidden_dim': 128,\n",
              " 'output_dim': 1,\n",
              " 'dropout': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT.vocab.vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9vDF_jv-YVv",
        "outputId": "2b0fafbc-f5e2-4d45-dac2-a0f28d153d0f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0466,  0.2132, -0.0074,  ...,  0.0091, -0.2099,  0.0539],\n",
              "        ...,\n",
              "        [ 0.5106, -0.1357,  0.2680,  ...,  0.1161, -0.0522,  0.3853],\n",
              "        [ 0.1081, -0.3056, -0.0545,  ..., -0.0378,  0.0010,  0.7474],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}