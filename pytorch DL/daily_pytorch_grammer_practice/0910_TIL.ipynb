{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available() :\n",
    "    DEVICE = torch.device('cuda')\n",
    "else :\n",
    "    DEVICE = torch.device('cpu')\n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0 cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='../../data/MNIST/',\n",
    "                               download=True,\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor())\n",
    "\n",
    "test_dataset = datasets.MNIST(root='../../data/MNIST/',\n",
    "                              download=True,\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           shuffle=True,\n",
    "                                           batch_size=BATCH_SIZE)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          shuffle=False,\n",
    "                                          batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n",
      "torch.FloatTensor torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "for (X_train, y_train) in train_loader:\n",
    "    print(X_train.size(), y_train.size())\n",
    "    print(X_train.type(), y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pltsize= 1\n",
    "plt.figure(figsize=(pltsize*10, pltsize))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10 ,i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i, :, :, :].numpy().reshape(28, 28), cmap='gray_r')\n",
    "    plt.title('Class :' + str(y_train[i].item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28* 28)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, log_interval=100):\n",
    "    model.train()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        output = model(image)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f'Train_Epoch: {Epoch}, [{batch_idx*len(image)} / {len(train_loader.dataset)}({(100. *batch_idx / len(train_loader)):.0f}%]\\tTrain_Loss ; {(loss.item()):.6f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim=True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_3976\\2108691685.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Epoch: 1, [0 / 60000(0%]\tTrain_Loss ; 2.316052\n",
      "Train_Epoch: 1, [3200 / 60000(5%]\tTrain_Loss ; 2.182207\n",
      "Train_Epoch: 1, [6400 / 60000(11%]\tTrain_Loss ; 1.927364\n",
      "Train_Epoch: 1, [9600 / 60000(16%]\tTrain_Loss ; 1.516931\n",
      "Train_Epoch: 1, [12800 / 60000(21%]\tTrain_Loss ; 0.850173\n",
      "Train_Epoch: 1, [16000 / 60000(27%]\tTrain_Loss ; 0.780806\n",
      "Train_Epoch: 1, [19200 / 60000(32%]\tTrain_Loss ; 0.656368\n",
      "Train_Epoch: 1, [22400 / 60000(37%]\tTrain_Loss ; 0.386519\n",
      "Train_Epoch: 1, [25600 / 60000(43%]\tTrain_Loss ; 0.672741\n",
      "Train_Epoch: 1, [28800 / 60000(48%]\tTrain_Loss ; 0.450741\n",
      "Train_Epoch: 1, [32000 / 60000(53%]\tTrain_Loss ; 0.455507\n",
      "Train_Epoch: 1, [35200 / 60000(59%]\tTrain_Loss ; 0.463340\n",
      "Train_Epoch: 1, [38400 / 60000(64%]\tTrain_Loss ; 0.323001\n",
      "Train_Epoch: 1, [41600 / 60000(69%]\tTrain_Loss ; 0.293447\n",
      "Train_Epoch: 1, [44800 / 60000(75%]\tTrain_Loss ; 0.333297\n",
      "Train_Epoch: 1, [48000 / 60000(80%]\tTrain_Loss ; 0.247876\n",
      "Train_Epoch: 1, [51200 / 60000(85%]\tTrain_Loss ; 0.453338\n",
      "Train_Epoch: 1, [54400 / 60000(91%]\tTrain_Loss ; 0.384882\n",
      "Train_Epoch: 1, [57600 / 60000(96%]\tTrain_Loss ; 0.431484\n",
      "\n",
      "[EPOCH: 1, \tTest_loss : 0.3146, \tTest_accuracy : 91.09%\n",
      "\n",
      "Train_Epoch: 2, [0 / 60000(0%]\tTrain_Loss ; 0.272722\n",
      "Train_Epoch: 2, [3200 / 60000(5%]\tTrain_Loss ; 0.270916\n",
      "Train_Epoch: 2, [6400 / 60000(11%]\tTrain_Loss ; 0.238031\n",
      "Train_Epoch: 2, [9600 / 60000(16%]\tTrain_Loss ; 0.322466\n",
      "Train_Epoch: 2, [12800 / 60000(21%]\tTrain_Loss ; 0.453360\n",
      "Train_Epoch: 2, [16000 / 60000(27%]\tTrain_Loss ; 0.627775\n",
      "Train_Epoch: 2, [19200 / 60000(32%]\tTrain_Loss ; 0.460553\n",
      "Train_Epoch: 2, [22400 / 60000(37%]\tTrain_Loss ; 0.247842\n",
      "Train_Epoch: 2, [25600 / 60000(43%]\tTrain_Loss ; 0.386082\n",
      "Train_Epoch: 2, [28800 / 60000(48%]\tTrain_Loss ; 0.152501\n",
      "Train_Epoch: 2, [32000 / 60000(53%]\tTrain_Loss ; 0.239981\n",
      "Train_Epoch: 2, [35200 / 60000(59%]\tTrain_Loss ; 0.231578\n",
      "Train_Epoch: 2, [38400 / 60000(64%]\tTrain_Loss ; 0.133511\n",
      "Train_Epoch: 2, [41600 / 60000(69%]\tTrain_Loss ; 0.309813\n",
      "Train_Epoch: 2, [44800 / 60000(75%]\tTrain_Loss ; 0.373618\n",
      "Train_Epoch: 2, [48000 / 60000(80%]\tTrain_Loss ; 0.145199\n",
      "Train_Epoch: 2, [51200 / 60000(85%]\tTrain_Loss ; 0.376268\n",
      "Train_Epoch: 2, [54400 / 60000(91%]\tTrain_Loss ; 0.524199\n",
      "Train_Epoch: 2, [57600 / 60000(96%]\tTrain_Loss ; 0.301363\n",
      "\n",
      "[EPOCH: 2, \tTest_loss : 0.2360, \tTest_accuracy : 93.07%\n",
      "\n",
      "Train_Epoch: 3, [0 / 60000(0%]\tTrain_Loss ; 0.341441\n",
      "Train_Epoch: 3, [3200 / 60000(5%]\tTrain_Loss ; 0.062263\n",
      "Train_Epoch: 3, [6400 / 60000(11%]\tTrain_Loss ; 0.105371\n",
      "Train_Epoch: 3, [9600 / 60000(16%]\tTrain_Loss ; 0.195899\n",
      "Train_Epoch: 3, [12800 / 60000(21%]\tTrain_Loss ; 0.337172\n",
      "Train_Epoch: 3, [16000 / 60000(27%]\tTrain_Loss ; 0.195388\n",
      "Train_Epoch: 3, [19200 / 60000(32%]\tTrain_Loss ; 0.184503\n",
      "Train_Epoch: 3, [22400 / 60000(37%]\tTrain_Loss ; 0.129567\n",
      "Train_Epoch: 3, [25600 / 60000(43%]\tTrain_Loss ; 0.232379\n",
      "Train_Epoch: 3, [28800 / 60000(48%]\tTrain_Loss ; 0.496984\n",
      "Train_Epoch: 3, [32000 / 60000(53%]\tTrain_Loss ; 0.198328\n",
      "Train_Epoch: 3, [35200 / 60000(59%]\tTrain_Loss ; 0.076577\n",
      "Train_Epoch: 3, [38400 / 60000(64%]\tTrain_Loss ; 0.232517\n",
      "Train_Epoch: 3, [41600 / 60000(69%]\tTrain_Loss ; 0.291154\n",
      "Train_Epoch: 3, [44800 / 60000(75%]\tTrain_Loss ; 0.064954\n",
      "Train_Epoch: 3, [48000 / 60000(80%]\tTrain_Loss ; 0.161897\n",
      "Train_Epoch: 3, [51200 / 60000(85%]\tTrain_Loss ; 0.211267\n",
      "Train_Epoch: 3, [54400 / 60000(91%]\tTrain_Loss ; 0.049049\n",
      "Train_Epoch: 3, [57600 / 60000(96%]\tTrain_Loss ; 0.222290\n",
      "\n",
      "[EPOCH: 3, \tTest_loss : 0.1863, \tTest_accuracy : 94.52%\n",
      "\n",
      "Train_Epoch: 4, [0 / 60000(0%]\tTrain_Loss ; 0.210863\n",
      "Train_Epoch: 4, [3200 / 60000(5%]\tTrain_Loss ; 0.222394\n",
      "Train_Epoch: 4, [6400 / 60000(11%]\tTrain_Loss ; 0.476549\n",
      "Train_Epoch: 4, [9600 / 60000(16%]\tTrain_Loss ; 0.065355\n",
      "Train_Epoch: 4, [12800 / 60000(21%]\tTrain_Loss ; 0.108092\n",
      "Train_Epoch: 4, [16000 / 60000(27%]\tTrain_Loss ; 0.155082\n",
      "Train_Epoch: 4, [19200 / 60000(32%]\tTrain_Loss ; 0.169075\n",
      "Train_Epoch: 4, [22400 / 60000(37%]\tTrain_Loss ; 0.411408\n",
      "Train_Epoch: 4, [25600 / 60000(43%]\tTrain_Loss ; 0.155848\n",
      "Train_Epoch: 4, [28800 / 60000(48%]\tTrain_Loss ; 0.093728\n",
      "Train_Epoch: 4, [32000 / 60000(53%]\tTrain_Loss ; 0.052775\n",
      "Train_Epoch: 4, [35200 / 60000(59%]\tTrain_Loss ; 0.042360\n",
      "Train_Epoch: 4, [38400 / 60000(64%]\tTrain_Loss ; 0.421790\n",
      "Train_Epoch: 4, [41600 / 60000(69%]\tTrain_Loss ; 0.115420\n",
      "Train_Epoch: 4, [44800 / 60000(75%]\tTrain_Loss ; 0.038032\n",
      "Train_Epoch: 4, [48000 / 60000(80%]\tTrain_Loss ; 0.081338\n",
      "Train_Epoch: 4, [51200 / 60000(85%]\tTrain_Loss ; 0.089712\n",
      "Train_Epoch: 4, [54400 / 60000(91%]\tTrain_Loss ; 0.184855\n",
      "Train_Epoch: 4, [57600 / 60000(96%]\tTrain_Loss ; 0.075399\n",
      "\n",
      "[EPOCH: 4, \tTest_loss : 0.1513, \tTest_accuracy : 95.53%\n",
      "\n",
      "Train_Epoch: 5, [0 / 60000(0%]\tTrain_Loss ; 0.044886\n",
      "Train_Epoch: 5, [3200 / 60000(5%]\tTrain_Loss ; 0.051733\n",
      "Train_Epoch: 5, [6400 / 60000(11%]\tTrain_Loss ; 0.119696\n",
      "Train_Epoch: 5, [9600 / 60000(16%]\tTrain_Loss ; 0.231004\n",
      "Train_Epoch: 5, [12800 / 60000(21%]\tTrain_Loss ; 0.042589\n",
      "Train_Epoch: 5, [16000 / 60000(27%]\tTrain_Loss ; 0.243669\n",
      "Train_Epoch: 5, [19200 / 60000(32%]\tTrain_Loss ; 0.087136\n",
      "Train_Epoch: 5, [22400 / 60000(37%]\tTrain_Loss ; 0.059214\n",
      "Train_Epoch: 5, [25600 / 60000(43%]\tTrain_Loss ; 0.136393\n",
      "Train_Epoch: 5, [28800 / 60000(48%]\tTrain_Loss ; 0.015373\n",
      "Train_Epoch: 5, [32000 / 60000(53%]\tTrain_Loss ; 0.603808\n",
      "Train_Epoch: 5, [35200 / 60000(59%]\tTrain_Loss ; 0.043531\n",
      "Train_Epoch: 5, [38400 / 60000(64%]\tTrain_Loss ; 0.273310\n",
      "Train_Epoch: 5, [41600 / 60000(69%]\tTrain_Loss ; 0.121151\n",
      "Train_Epoch: 5, [44800 / 60000(75%]\tTrain_Loss ; 0.050277\n",
      "Train_Epoch: 5, [48000 / 60000(80%]\tTrain_Loss ; 0.148721\n",
      "Train_Epoch: 5, [51200 / 60000(85%]\tTrain_Loss ; 0.047426\n",
      "Train_Epoch: 5, [54400 / 60000(91%]\tTrain_Loss ; 0.056105\n",
      "Train_Epoch: 5, [57600 / 60000(96%]\tTrain_Loss ; 0.034804\n",
      "\n",
      "[EPOCH: 5, \tTest_loss : 0.1379, \tTest_accuracy : 95.70%\n",
      "\n",
      "Train_Epoch: 6, [0 / 60000(0%]\tTrain_Loss ; 0.167655\n",
      "Train_Epoch: 6, [3200 / 60000(5%]\tTrain_Loss ; 0.048878\n",
      "Train_Epoch: 6, [6400 / 60000(11%]\tTrain_Loss ; 0.272773\n",
      "Train_Epoch: 6, [9600 / 60000(16%]\tTrain_Loss ; 0.271190\n",
      "Train_Epoch: 6, [12800 / 60000(21%]\tTrain_Loss ; 0.019298\n",
      "Train_Epoch: 6, [16000 / 60000(27%]\tTrain_Loss ; 0.064363\n",
      "Train_Epoch: 6, [19200 / 60000(32%]\tTrain_Loss ; 0.053448\n",
      "Train_Epoch: 6, [22400 / 60000(37%]\tTrain_Loss ; 0.034545\n",
      "Train_Epoch: 6, [25600 / 60000(43%]\tTrain_Loss ; 0.141343\n",
      "Train_Epoch: 6, [28800 / 60000(48%]\tTrain_Loss ; 0.032044\n",
      "Train_Epoch: 6, [32000 / 60000(53%]\tTrain_Loss ; 0.274524\n",
      "Train_Epoch: 6, [35200 / 60000(59%]\tTrain_Loss ; 0.067407\n",
      "Train_Epoch: 6, [38400 / 60000(64%]\tTrain_Loss ; 0.041726\n",
      "Train_Epoch: 6, [41600 / 60000(69%]\tTrain_Loss ; 0.079954\n",
      "Train_Epoch: 6, [44800 / 60000(75%]\tTrain_Loss ; 0.145602\n",
      "Train_Epoch: 6, [48000 / 60000(80%]\tTrain_Loss ; 0.059267\n",
      "Train_Epoch: 6, [51200 / 60000(85%]\tTrain_Loss ; 0.048543\n",
      "Train_Epoch: 6, [54400 / 60000(91%]\tTrain_Loss ; 0.104946\n",
      "Train_Epoch: 6, [57600 / 60000(96%]\tTrain_Loss ; 0.117058\n",
      "\n",
      "[EPOCH: 6, \tTest_loss : 0.1159, \tTest_accuracy : 96.55%\n",
      "\n",
      "Train_Epoch: 7, [0 / 60000(0%]\tTrain_Loss ; 0.176280\n",
      "Train_Epoch: 7, [3200 / 60000(5%]\tTrain_Loss ; 0.048170\n",
      "Train_Epoch: 7, [6400 / 60000(11%]\tTrain_Loss ; 0.127866\n",
      "Train_Epoch: 7, [9600 / 60000(16%]\tTrain_Loss ; 0.153610\n",
      "Train_Epoch: 7, [12800 / 60000(21%]\tTrain_Loss ; 0.039698\n",
      "Train_Epoch: 7, [16000 / 60000(27%]\tTrain_Loss ; 0.196192\n",
      "Train_Epoch: 7, [19200 / 60000(32%]\tTrain_Loss ; 0.014743\n",
      "Train_Epoch: 7, [22400 / 60000(37%]\tTrain_Loss ; 0.078300\n",
      "Train_Epoch: 7, [25600 / 60000(43%]\tTrain_Loss ; 0.098475\n",
      "Train_Epoch: 7, [28800 / 60000(48%]\tTrain_Loss ; 0.159739\n",
      "Train_Epoch: 7, [32000 / 60000(53%]\tTrain_Loss ; 0.044769\n",
      "Train_Epoch: 7, [35200 / 60000(59%]\tTrain_Loss ; 0.112299\n",
      "Train_Epoch: 7, [38400 / 60000(64%]\tTrain_Loss ; 0.060660\n",
      "Train_Epoch: 7, [41600 / 60000(69%]\tTrain_Loss ; 0.137680\n",
      "Train_Epoch: 7, [44800 / 60000(75%]\tTrain_Loss ; 0.089386\n",
      "Train_Epoch: 7, [48000 / 60000(80%]\tTrain_Loss ; 0.274240\n",
      "Train_Epoch: 7, [51200 / 60000(85%]\tTrain_Loss ; 0.030605\n",
      "Train_Epoch: 7, [54400 / 60000(91%]\tTrain_Loss ; 0.054380\n",
      "Train_Epoch: 7, [57600 / 60000(96%]\tTrain_Loss ; 0.309726\n",
      "\n",
      "[EPOCH: 7, \tTest_loss : 0.1026, \tTest_accuracy : 96.97%\n",
      "\n",
      "Train_Epoch: 8, [0 / 60000(0%]\tTrain_Loss ; 0.037106\n",
      "Train_Epoch: 8, [3200 / 60000(5%]\tTrain_Loss ; 0.080309\n",
      "Train_Epoch: 8, [6400 / 60000(11%]\tTrain_Loss ; 0.140134\n",
      "Train_Epoch: 8, [9600 / 60000(16%]\tTrain_Loss ; 0.030034\n",
      "Train_Epoch: 8, [12800 / 60000(21%]\tTrain_Loss ; 0.096499\n",
      "Train_Epoch: 8, [16000 / 60000(27%]\tTrain_Loss ; 0.146446\n",
      "Train_Epoch: 8, [19200 / 60000(32%]\tTrain_Loss ; 0.053510\n",
      "Train_Epoch: 8, [22400 / 60000(37%]\tTrain_Loss ; 0.099157\n",
      "Train_Epoch: 8, [25600 / 60000(43%]\tTrain_Loss ; 0.039907\n",
      "Train_Epoch: 8, [28800 / 60000(48%]\tTrain_Loss ; 0.051468\n",
      "Train_Epoch: 8, [32000 / 60000(53%]\tTrain_Loss ; 0.011346\n",
      "Train_Epoch: 8, [35200 / 60000(59%]\tTrain_Loss ; 0.161953\n",
      "Train_Epoch: 8, [38400 / 60000(64%]\tTrain_Loss ; 0.044820\n",
      "Train_Epoch: 8, [41600 / 60000(69%]\tTrain_Loss ; 0.003934\n",
      "Train_Epoch: 8, [44800 / 60000(75%]\tTrain_Loss ; 0.065216\n",
      "Train_Epoch: 8, [48000 / 60000(80%]\tTrain_Loss ; 0.011202\n",
      "Train_Epoch: 8, [51200 / 60000(85%]\tTrain_Loss ; 0.119933\n",
      "Train_Epoch: 8, [54400 / 60000(91%]\tTrain_Loss ; 0.122490\n",
      "Train_Epoch: 8, [57600 / 60000(96%]\tTrain_Loss ; 0.065297\n",
      "\n",
      "[EPOCH: 8, \tTest_loss : 0.0959, \tTest_accuracy : 97.13%\n",
      "\n",
      "Train_Epoch: 9, [0 / 60000(0%]\tTrain_Loss ; 0.040149\n",
      "Train_Epoch: 9, [3200 / 60000(5%]\tTrain_Loss ; 0.051164\n",
      "Train_Epoch: 9, [6400 / 60000(11%]\tTrain_Loss ; 0.035337\n",
      "Train_Epoch: 9, [9600 / 60000(16%]\tTrain_Loss ; 0.084156\n",
      "Train_Epoch: 9, [12800 / 60000(21%]\tTrain_Loss ; 0.027732\n",
      "Train_Epoch: 9, [16000 / 60000(27%]\tTrain_Loss ; 0.101717\n",
      "Train_Epoch: 9, [19200 / 60000(32%]\tTrain_Loss ; 0.125752\n",
      "Train_Epoch: 9, [22400 / 60000(37%]\tTrain_Loss ; 0.084015\n",
      "Train_Epoch: 9, [25600 / 60000(43%]\tTrain_Loss ; 0.034203\n",
      "Train_Epoch: 9, [28800 / 60000(48%]\tTrain_Loss ; 0.152312\n",
      "Train_Epoch: 9, [32000 / 60000(53%]\tTrain_Loss ; 0.262245\n",
      "Train_Epoch: 9, [35200 / 60000(59%]\tTrain_Loss ; 0.161130\n",
      "Train_Epoch: 9, [38400 / 60000(64%]\tTrain_Loss ; 0.058967\n",
      "Train_Epoch: 9, [41600 / 60000(69%]\tTrain_Loss ; 0.037607\n",
      "Train_Epoch: 9, [44800 / 60000(75%]\tTrain_Loss ; 0.052102\n",
      "Train_Epoch: 9, [48000 / 60000(80%]\tTrain_Loss ; 0.303779\n",
      "Train_Epoch: 9, [51200 / 60000(85%]\tTrain_Loss ; 0.039468\n",
      "Train_Epoch: 9, [54400 / 60000(91%]\tTrain_Loss ; 0.148976\n",
      "Train_Epoch: 9, [57600 / 60000(96%]\tTrain_Loss ; 0.044921\n",
      "\n",
      "[EPOCH: 9, \tTest_loss : 0.0937, \tTest_accuracy : 97.15%\n",
      "\n",
      "Train_Epoch: 10, [0 / 60000(0%]\tTrain_Loss ; 0.060353\n",
      "Train_Epoch: 10, [3200 / 60000(5%]\tTrain_Loss ; 0.090891\n",
      "Train_Epoch: 10, [6400 / 60000(11%]\tTrain_Loss ; 0.167070\n",
      "Train_Epoch: 10, [9600 / 60000(16%]\tTrain_Loss ; 0.031678\n",
      "Train_Epoch: 10, [12800 / 60000(21%]\tTrain_Loss ; 0.012937\n",
      "Train_Epoch: 10, [16000 / 60000(27%]\tTrain_Loss ; 0.043695\n",
      "Train_Epoch: 10, [19200 / 60000(32%]\tTrain_Loss ; 0.011667\n",
      "Train_Epoch: 10, [22400 / 60000(37%]\tTrain_Loss ; 0.288401\n",
      "Train_Epoch: 10, [25600 / 60000(43%]\tTrain_Loss ; 0.057027\n",
      "Train_Epoch: 10, [28800 / 60000(48%]\tTrain_Loss ; 0.048729\n",
      "Train_Epoch: 10, [32000 / 60000(53%]\tTrain_Loss ; 0.062531\n",
      "Train_Epoch: 10, [35200 / 60000(59%]\tTrain_Loss ; 0.081984\n",
      "Train_Epoch: 10, [38400 / 60000(64%]\tTrain_Loss ; 0.172840\n",
      "Train_Epoch: 10, [41600 / 60000(69%]\tTrain_Loss ; 0.042465\n",
      "Train_Epoch: 10, [44800 / 60000(75%]\tTrain_Loss ; 0.020642\n",
      "Train_Epoch: 10, [48000 / 60000(80%]\tTrain_Loss ; 0.013620\n",
      "Train_Epoch: 10, [51200 / 60000(85%]\tTrain_Loss ; 0.189183\n",
      "Train_Epoch: 10, [54400 / 60000(91%]\tTrain_Loss ; 0.135155\n",
      "Train_Epoch: 10, [57600 / 60000(96%]\tTrain_Loss ; 0.013647\n",
      "\n",
      "[EPOCH: 10, \tTest_loss : 0.0813, \tTest_accuracy : 97.62%\n",
      "\n",
      "Train_Epoch: 11, [0 / 60000(0%]\tTrain_Loss ; 0.166779\n",
      "Train_Epoch: 11, [3200 / 60000(5%]\tTrain_Loss ; 0.052722\n",
      "Train_Epoch: 11, [6400 / 60000(11%]\tTrain_Loss ; 0.008674\n",
      "Train_Epoch: 11, [9600 / 60000(16%]\tTrain_Loss ; 0.073438\n",
      "Train_Epoch: 11, [12800 / 60000(21%]\tTrain_Loss ; 0.038492\n",
      "Train_Epoch: 11, [16000 / 60000(27%]\tTrain_Loss ; 0.015768\n",
      "Train_Epoch: 11, [19200 / 60000(32%]\tTrain_Loss ; 0.008563\n",
      "Train_Epoch: 11, [22400 / 60000(37%]\tTrain_Loss ; 0.090926\n",
      "Train_Epoch: 11, [25600 / 60000(43%]\tTrain_Loss ; 0.033306\n",
      "Train_Epoch: 11, [28800 / 60000(48%]\tTrain_Loss ; 0.045667\n",
      "Train_Epoch: 11, [32000 / 60000(53%]\tTrain_Loss ; 0.023435\n",
      "Train_Epoch: 11, [35200 / 60000(59%]\tTrain_Loss ; 0.049250\n",
      "Train_Epoch: 11, [38400 / 60000(64%]\tTrain_Loss ; 0.056684\n",
      "Train_Epoch: 11, [41600 / 60000(69%]\tTrain_Loss ; 0.018845\n",
      "Train_Epoch: 11, [44800 / 60000(75%]\tTrain_Loss ; 0.005575\n",
      "Train_Epoch: 11, [48000 / 60000(80%]\tTrain_Loss ; 0.016091\n",
      "Train_Epoch: 11, [51200 / 60000(85%]\tTrain_Loss ; 0.088086\n",
      "Train_Epoch: 11, [54400 / 60000(91%]\tTrain_Loss ; 0.021124\n",
      "Train_Epoch: 11, [57600 / 60000(96%]\tTrain_Loss ; 0.030000\n",
      "\n",
      "[EPOCH: 11, \tTest_loss : 0.0778, \tTest_accuracy : 97.67%\n",
      "\n",
      "Train_Epoch: 12, [0 / 60000(0%]\tTrain_Loss ; 0.089527\n",
      "Train_Epoch: 12, [3200 / 60000(5%]\tTrain_Loss ; 0.018360\n",
      "Train_Epoch: 12, [6400 / 60000(11%]\tTrain_Loss ; 0.023229\n",
      "Train_Epoch: 12, [9600 / 60000(16%]\tTrain_Loss ; 0.091163\n",
      "Train_Epoch: 12, [12800 / 60000(21%]\tTrain_Loss ; 0.022610\n",
      "Train_Epoch: 12, [16000 / 60000(27%]\tTrain_Loss ; 0.011857\n",
      "Train_Epoch: 12, [19200 / 60000(32%]\tTrain_Loss ; 0.040662\n",
      "Train_Epoch: 12, [22400 / 60000(37%]\tTrain_Loss ; 0.023190\n",
      "Train_Epoch: 12, [25600 / 60000(43%]\tTrain_Loss ; 0.021874\n",
      "Train_Epoch: 12, [28800 / 60000(48%]\tTrain_Loss ; 0.009663\n",
      "Train_Epoch: 12, [32000 / 60000(53%]\tTrain_Loss ; 0.090148\n",
      "Train_Epoch: 12, [35200 / 60000(59%]\tTrain_Loss ; 0.151086\n",
      "Train_Epoch: 12, [38400 / 60000(64%]\tTrain_Loss ; 0.014821\n",
      "Train_Epoch: 12, [41600 / 60000(69%]\tTrain_Loss ; 0.130655\n",
      "Train_Epoch: 12, [44800 / 60000(75%]\tTrain_Loss ; 0.041495\n",
      "Train_Epoch: 12, [48000 / 60000(80%]\tTrain_Loss ; 0.039067\n",
      "Train_Epoch: 12, [51200 / 60000(85%]\tTrain_Loss ; 0.204811\n",
      "Train_Epoch: 12, [54400 / 60000(91%]\tTrain_Loss ; 0.004402\n",
      "Train_Epoch: 12, [57600 / 60000(96%]\tTrain_Loss ; 0.009688\n",
      "\n",
      "[EPOCH: 12, \tTest_loss : 0.0769, \tTest_accuracy : 97.66%\n",
      "\n",
      "Train_Epoch: 13, [0 / 60000(0%]\tTrain_Loss ; 0.014903\n",
      "Train_Epoch: 13, [3200 / 60000(5%]\tTrain_Loss ; 0.019764\n",
      "Train_Epoch: 13, [6400 / 60000(11%]\tTrain_Loss ; 0.026141\n",
      "Train_Epoch: 13, [9600 / 60000(16%]\tTrain_Loss ; 0.021154\n",
      "Train_Epoch: 13, [12800 / 60000(21%]\tTrain_Loss ; 0.006306\n",
      "Train_Epoch: 13, [16000 / 60000(27%]\tTrain_Loss ; 0.018969\n",
      "Train_Epoch: 13, [19200 / 60000(32%]\tTrain_Loss ; 0.028267\n",
      "Train_Epoch: 13, [22400 / 60000(37%]\tTrain_Loss ; 0.038826\n",
      "Train_Epoch: 13, [25600 / 60000(43%]\tTrain_Loss ; 0.018599\n",
      "Train_Epoch: 13, [28800 / 60000(48%]\tTrain_Loss ; 0.021234\n",
      "Train_Epoch: 13, [32000 / 60000(53%]\tTrain_Loss ; 0.178910\n",
      "Train_Epoch: 13, [35200 / 60000(59%]\tTrain_Loss ; 0.006693\n",
      "Train_Epoch: 13, [38400 / 60000(64%]\tTrain_Loss ; 0.023951\n",
      "Train_Epoch: 13, [41600 / 60000(69%]\tTrain_Loss ; 0.285467\n",
      "Train_Epoch: 13, [44800 / 60000(75%]\tTrain_Loss ; 0.060693\n",
      "Train_Epoch: 13, [48000 / 60000(80%]\tTrain_Loss ; 0.163085\n",
      "Train_Epoch: 13, [51200 / 60000(85%]\tTrain_Loss ; 0.090442\n",
      "Train_Epoch: 13, [54400 / 60000(91%]\tTrain_Loss ; 0.011769\n",
      "Train_Epoch: 13, [57600 / 60000(96%]\tTrain_Loss ; 0.018055\n",
      "\n",
      "[EPOCH: 13, \tTest_loss : 0.0722, \tTest_accuracy : 97.72%\n",
      "\n",
      "Train_Epoch: 14, [0 / 60000(0%]\tTrain_Loss ; 0.116746\n",
      "Train_Epoch: 14, [3200 / 60000(5%]\tTrain_Loss ; 0.155377\n",
      "Train_Epoch: 14, [6400 / 60000(11%]\tTrain_Loss ; 0.138872\n",
      "Train_Epoch: 14, [9600 / 60000(16%]\tTrain_Loss ; 0.031529\n",
      "Train_Epoch: 14, [12800 / 60000(21%]\tTrain_Loss ; 0.089950\n",
      "Train_Epoch: 14, [16000 / 60000(27%]\tTrain_Loss ; 0.024363\n",
      "Train_Epoch: 14, [19200 / 60000(32%]\tTrain_Loss ; 0.013696\n",
      "Train_Epoch: 14, [22400 / 60000(37%]\tTrain_Loss ; 0.038629\n",
      "Train_Epoch: 14, [25600 / 60000(43%]\tTrain_Loss ; 0.093046\n",
      "Train_Epoch: 14, [28800 / 60000(48%]\tTrain_Loss ; 0.040415\n",
      "Train_Epoch: 14, [32000 / 60000(53%]\tTrain_Loss ; 0.015995\n",
      "Train_Epoch: 14, [35200 / 60000(59%]\tTrain_Loss ; 0.048229\n",
      "Train_Epoch: 14, [38400 / 60000(64%]\tTrain_Loss ; 0.088980\n",
      "Train_Epoch: 14, [41600 / 60000(69%]\tTrain_Loss ; 0.036957\n",
      "Train_Epoch: 14, [44800 / 60000(75%]\tTrain_Loss ; 0.077535\n",
      "Train_Epoch: 14, [48000 / 60000(80%]\tTrain_Loss ; 0.063620\n",
      "Train_Epoch: 14, [51200 / 60000(85%]\tTrain_Loss ; 0.022628\n",
      "Train_Epoch: 14, [54400 / 60000(91%]\tTrain_Loss ; 0.010167\n",
      "Train_Epoch: 14, [57600 / 60000(96%]\tTrain_Loss ; 0.021728\n",
      "\n",
      "[EPOCH: 14, \tTest_loss : 0.0713, \tTest_accuracy : 97.77%\n",
      "\n",
      "Train_Epoch: 15, [0 / 60000(0%]\tTrain_Loss ; 0.024340\n",
      "Train_Epoch: 15, [3200 / 60000(5%]\tTrain_Loss ; 0.011192\n",
      "Train_Epoch: 15, [6400 / 60000(11%]\tTrain_Loss ; 0.027663\n",
      "Train_Epoch: 15, [9600 / 60000(16%]\tTrain_Loss ; 0.012823\n",
      "Train_Epoch: 15, [12800 / 60000(21%]\tTrain_Loss ; 0.012595\n",
      "Train_Epoch: 15, [16000 / 60000(27%]\tTrain_Loss ; 0.068055\n",
      "Train_Epoch: 15, [19200 / 60000(32%]\tTrain_Loss ; 0.096613\n",
      "Train_Epoch: 15, [22400 / 60000(37%]\tTrain_Loss ; 0.006190\n",
      "Train_Epoch: 15, [25600 / 60000(43%]\tTrain_Loss ; 0.007902\n",
      "Train_Epoch: 15, [28800 / 60000(48%]\tTrain_Loss ; 0.028131\n",
      "Train_Epoch: 15, [32000 / 60000(53%]\tTrain_Loss ; 0.088987\n",
      "Train_Epoch: 15, [35200 / 60000(59%]\tTrain_Loss ; 0.019340\n",
      "Train_Epoch: 15, [38400 / 60000(64%]\tTrain_Loss ; 0.038349\n",
      "Train_Epoch: 15, [41600 / 60000(69%]\tTrain_Loss ; 0.016009\n",
      "Train_Epoch: 15, [44800 / 60000(75%]\tTrain_Loss ; 0.026378\n",
      "Train_Epoch: 15, [48000 / 60000(80%]\tTrain_Loss ; 0.058604\n",
      "Train_Epoch: 15, [51200 / 60000(85%]\tTrain_Loss ; 0.001748\n",
      "Train_Epoch: 15, [54400 / 60000(91%]\tTrain_Loss ; 0.023140\n",
      "Train_Epoch: 15, [57600 / 60000(96%]\tTrain_Loss ; 0.118957\n",
      "\n",
      "[EPOCH: 15, \tTest_loss : 0.0716, \tTest_accuracy : 97.73%\n",
      "\n",
      "Train_Epoch: 16, [0 / 60000(0%]\tTrain_Loss ; 0.146680\n",
      "Train_Epoch: 16, [3200 / 60000(5%]\tTrain_Loss ; 0.015634\n",
      "Train_Epoch: 16, [6400 / 60000(11%]\tTrain_Loss ; 0.084453\n",
      "Train_Epoch: 16, [9600 / 60000(16%]\tTrain_Loss ; 0.027798\n",
      "Train_Epoch: 16, [12800 / 60000(21%]\tTrain_Loss ; 0.103119\n",
      "Train_Epoch: 16, [16000 / 60000(27%]\tTrain_Loss ; 0.074290\n",
      "Train_Epoch: 16, [19200 / 60000(32%]\tTrain_Loss ; 0.012954\n",
      "Train_Epoch: 16, [22400 / 60000(37%]\tTrain_Loss ; 0.003866\n",
      "Train_Epoch: 16, [25600 / 60000(43%]\tTrain_Loss ; 0.021361\n",
      "Train_Epoch: 16, [28800 / 60000(48%]\tTrain_Loss ; 0.023530\n",
      "Train_Epoch: 16, [32000 / 60000(53%]\tTrain_Loss ; 0.023535\n",
      "Train_Epoch: 16, [35200 / 60000(59%]\tTrain_Loss ; 0.004747\n",
      "Train_Epoch: 16, [38400 / 60000(64%]\tTrain_Loss ; 0.121332\n",
      "Train_Epoch: 16, [41600 / 60000(69%]\tTrain_Loss ; 0.005537\n",
      "Train_Epoch: 16, [44800 / 60000(75%]\tTrain_Loss ; 0.032947\n",
      "Train_Epoch: 16, [48000 / 60000(80%]\tTrain_Loss ; 0.023428\n",
      "Train_Epoch: 16, [51200 / 60000(85%]\tTrain_Loss ; 0.011165\n",
      "Train_Epoch: 16, [54400 / 60000(91%]\tTrain_Loss ; 0.012083\n",
      "Train_Epoch: 16, [57600 / 60000(96%]\tTrain_Loss ; 0.009241\n",
      "\n",
      "[EPOCH: 16, \tTest_loss : 0.0671, \tTest_accuracy : 97.86%\n",
      "\n",
      "Train_Epoch: 17, [0 / 60000(0%]\tTrain_Loss ; 0.018294\n",
      "Train_Epoch: 17, [3200 / 60000(5%]\tTrain_Loss ; 0.032322\n",
      "Train_Epoch: 17, [6400 / 60000(11%]\tTrain_Loss ; 0.075171\n",
      "Train_Epoch: 17, [9600 / 60000(16%]\tTrain_Loss ; 0.010962\n",
      "Train_Epoch: 17, [12800 / 60000(21%]\tTrain_Loss ; 0.011435\n",
      "Train_Epoch: 17, [16000 / 60000(27%]\tTrain_Loss ; 0.003925\n",
      "Train_Epoch: 17, [19200 / 60000(32%]\tTrain_Loss ; 0.019006\n",
      "Train_Epoch: 17, [22400 / 60000(37%]\tTrain_Loss ; 0.029476\n",
      "Train_Epoch: 17, [25600 / 60000(43%]\tTrain_Loss ; 0.014837\n",
      "Train_Epoch: 17, [28800 / 60000(48%]\tTrain_Loss ; 0.128443\n",
      "Train_Epoch: 17, [32000 / 60000(53%]\tTrain_Loss ; 0.043999\n",
      "Train_Epoch: 17, [35200 / 60000(59%]\tTrain_Loss ; 0.020570\n",
      "Train_Epoch: 17, [38400 / 60000(64%]\tTrain_Loss ; 0.019895\n",
      "Train_Epoch: 17, [41600 / 60000(69%]\tTrain_Loss ; 0.034925\n",
      "Train_Epoch: 17, [44800 / 60000(75%]\tTrain_Loss ; 0.026752\n",
      "Train_Epoch: 17, [48000 / 60000(80%]\tTrain_Loss ; 0.013964\n",
      "Train_Epoch: 17, [51200 / 60000(85%]\tTrain_Loss ; 0.012931\n",
      "Train_Epoch: 17, [54400 / 60000(91%]\tTrain_Loss ; 0.008288\n",
      "Train_Epoch: 17, [57600 / 60000(96%]\tTrain_Loss ; 0.013698\n",
      "\n",
      "[EPOCH: 17, \tTest_loss : 0.0664, \tTest_accuracy : 97.91%\n",
      "\n",
      "Train_Epoch: 18, [0 / 60000(0%]\tTrain_Loss ; 0.009692\n",
      "Train_Epoch: 18, [3200 / 60000(5%]\tTrain_Loss ; 0.027193\n",
      "Train_Epoch: 18, [6400 / 60000(11%]\tTrain_Loss ; 0.017371\n",
      "Train_Epoch: 18, [9600 / 60000(16%]\tTrain_Loss ; 0.044283\n",
      "Train_Epoch: 18, [12800 / 60000(21%]\tTrain_Loss ; 0.003896\n",
      "Train_Epoch: 18, [16000 / 60000(27%]\tTrain_Loss ; 0.055934\n",
      "Train_Epoch: 18, [19200 / 60000(32%]\tTrain_Loss ; 0.021809\n",
      "Train_Epoch: 18, [22400 / 60000(37%]\tTrain_Loss ; 0.003945\n",
      "Train_Epoch: 18, [25600 / 60000(43%]\tTrain_Loss ; 0.008376\n",
      "Train_Epoch: 18, [28800 / 60000(48%]\tTrain_Loss ; 0.025810\n",
      "Train_Epoch: 18, [32000 / 60000(53%]\tTrain_Loss ; 0.007807\n",
      "Train_Epoch: 18, [35200 / 60000(59%]\tTrain_Loss ; 0.053001\n",
      "Train_Epoch: 18, [38400 / 60000(64%]\tTrain_Loss ; 0.028385\n",
      "Train_Epoch: 18, [41600 / 60000(69%]\tTrain_Loss ; 0.042502\n",
      "Train_Epoch: 18, [44800 / 60000(75%]\tTrain_Loss ; 0.017648\n",
      "Train_Epoch: 18, [48000 / 60000(80%]\tTrain_Loss ; 0.299154\n",
      "Train_Epoch: 18, [51200 / 60000(85%]\tTrain_Loss ; 0.004993\n",
      "Train_Epoch: 18, [54400 / 60000(91%]\tTrain_Loss ; 0.023878\n",
      "Train_Epoch: 18, [57600 / 60000(96%]\tTrain_Loss ; 0.038438\n",
      "\n",
      "[EPOCH: 18, \tTest_loss : 0.0647, \tTest_accuracy : 97.93%\n",
      "\n",
      "Train_Epoch: 19, [0 / 60000(0%]\tTrain_Loss ; 0.014453\n",
      "Train_Epoch: 19, [3200 / 60000(5%]\tTrain_Loss ; 0.010934\n",
      "Train_Epoch: 19, [6400 / 60000(11%]\tTrain_Loss ; 0.003370\n",
      "Train_Epoch: 19, [9600 / 60000(16%]\tTrain_Loss ; 0.001709\n",
      "Train_Epoch: 19, [12800 / 60000(21%]\tTrain_Loss ; 0.180224\n",
      "Train_Epoch: 19, [16000 / 60000(27%]\tTrain_Loss ; 0.047131\n",
      "Train_Epoch: 19, [19200 / 60000(32%]\tTrain_Loss ; 0.026515\n",
      "Train_Epoch: 19, [22400 / 60000(37%]\tTrain_Loss ; 0.054735\n",
      "Train_Epoch: 19, [25600 / 60000(43%]\tTrain_Loss ; 0.026049\n",
      "Train_Epoch: 19, [28800 / 60000(48%]\tTrain_Loss ; 0.012876\n",
      "Train_Epoch: 19, [32000 / 60000(53%]\tTrain_Loss ; 0.006641\n",
      "Train_Epoch: 19, [35200 / 60000(59%]\tTrain_Loss ; 0.040530\n",
      "Train_Epoch: 19, [38400 / 60000(64%]\tTrain_Loss ; 0.009961\n",
      "Train_Epoch: 19, [41600 / 60000(69%]\tTrain_Loss ; 0.002588\n",
      "Train_Epoch: 19, [44800 / 60000(75%]\tTrain_Loss ; 0.004002\n",
      "Train_Epoch: 19, [48000 / 60000(80%]\tTrain_Loss ; 0.027322\n",
      "Train_Epoch: 19, [51200 / 60000(85%]\tTrain_Loss ; 0.018145\n",
      "Train_Epoch: 19, [54400 / 60000(91%]\tTrain_Loss ; 0.182272\n",
      "Train_Epoch: 19, [57600 / 60000(96%]\tTrain_Loss ; 0.077561\n",
      "\n",
      "[EPOCH: 19, \tTest_loss : 0.0652, \tTest_accuracy : 97.87%\n",
      "\n",
      "Train_Epoch: 20, [0 / 60000(0%]\tTrain_Loss ; 0.009346\n",
      "Train_Epoch: 20, [3200 / 60000(5%]\tTrain_Loss ; 0.008474\n",
      "Train_Epoch: 20, [6400 / 60000(11%]\tTrain_Loss ; 0.002360\n",
      "Train_Epoch: 20, [9600 / 60000(16%]\tTrain_Loss ; 0.020617\n",
      "Train_Epoch: 20, [12800 / 60000(21%]\tTrain_Loss ; 0.039712\n",
      "Train_Epoch: 20, [16000 / 60000(27%]\tTrain_Loss ; 0.009056\n",
      "Train_Epoch: 20, [19200 / 60000(32%]\tTrain_Loss ; 0.008554\n",
      "Train_Epoch: 20, [22400 / 60000(37%]\tTrain_Loss ; 0.028203\n",
      "Train_Epoch: 20, [25600 / 60000(43%]\tTrain_Loss ; 0.063677\n",
      "Train_Epoch: 20, [28800 / 60000(48%]\tTrain_Loss ; 0.012062\n",
      "Train_Epoch: 20, [32000 / 60000(53%]\tTrain_Loss ; 0.013826\n",
      "Train_Epoch: 20, [35200 / 60000(59%]\tTrain_Loss ; 0.004145\n",
      "Train_Epoch: 20, [38400 / 60000(64%]\tTrain_Loss ; 0.265407\n",
      "Train_Epoch: 20, [41600 / 60000(69%]\tTrain_Loss ; 0.014377\n",
      "Train_Epoch: 20, [44800 / 60000(75%]\tTrain_Loss ; 0.004738\n",
      "Train_Epoch: 20, [48000 / 60000(80%]\tTrain_Loss ; 0.008509\n",
      "Train_Epoch: 20, [51200 / 60000(85%]\tTrain_Loss ; 0.012728\n",
      "Train_Epoch: 20, [54400 / 60000(91%]\tTrain_Loss ; 0.017178\n",
      "Train_Epoch: 20, [57600 / 60000(96%]\tTrain_Loss ; 0.028379\n",
      "\n",
      "[EPOCH: 20, \tTest_loss : 0.0635, \tTest_accuracy : 97.97%\n",
      "\n",
      "Train_Epoch: 21, [0 / 60000(0%]\tTrain_Loss ; 0.008501\n",
      "Train_Epoch: 21, [3200 / 60000(5%]\tTrain_Loss ; 0.005203\n",
      "Train_Epoch: 21, [6400 / 60000(11%]\tTrain_Loss ; 0.004353\n",
      "Train_Epoch: 21, [9600 / 60000(16%]\tTrain_Loss ; 0.003317\n",
      "Train_Epoch: 21, [12800 / 60000(21%]\tTrain_Loss ; 0.003281\n",
      "Train_Epoch: 21, [16000 / 60000(27%]\tTrain_Loss ; 0.017502\n",
      "Train_Epoch: 21, [19200 / 60000(32%]\tTrain_Loss ; 0.006631\n",
      "Train_Epoch: 21, [22400 / 60000(37%]\tTrain_Loss ; 0.005077\n",
      "Train_Epoch: 21, [25600 / 60000(43%]\tTrain_Loss ; 0.018663\n",
      "Train_Epoch: 21, [28800 / 60000(48%]\tTrain_Loss ; 0.057030\n",
      "Train_Epoch: 21, [32000 / 60000(53%]\tTrain_Loss ; 0.017024\n",
      "Train_Epoch: 21, [35200 / 60000(59%]\tTrain_Loss ; 0.023680\n",
      "Train_Epoch: 21, [38400 / 60000(64%]\tTrain_Loss ; 0.053152\n",
      "Train_Epoch: 21, [41600 / 60000(69%]\tTrain_Loss ; 0.020756\n",
      "Train_Epoch: 21, [44800 / 60000(75%]\tTrain_Loss ; 0.013799\n",
      "Train_Epoch: 21, [48000 / 60000(80%]\tTrain_Loss ; 0.001173\n",
      "Train_Epoch: 21, [51200 / 60000(85%]\tTrain_Loss ; 0.012801\n",
      "Train_Epoch: 21, [54400 / 60000(91%]\tTrain_Loss ; 0.254597\n",
      "Train_Epoch: 21, [57600 / 60000(96%]\tTrain_Loss ; 0.009316\n",
      "\n",
      "[EPOCH: 21, \tTest_loss : 0.0622, \tTest_accuracy : 98.05%\n",
      "\n",
      "Train_Epoch: 22, [0 / 60000(0%]\tTrain_Loss ; 0.001963\n",
      "Train_Epoch: 22, [3200 / 60000(5%]\tTrain_Loss ; 0.004590\n",
      "Train_Epoch: 22, [6400 / 60000(11%]\tTrain_Loss ; 0.108534\n",
      "Train_Epoch: 22, [9600 / 60000(16%]\tTrain_Loss ; 0.016733\n",
      "Train_Epoch: 22, [12800 / 60000(21%]\tTrain_Loss ; 0.008940\n",
      "Train_Epoch: 22, [16000 / 60000(27%]\tTrain_Loss ; 0.011369\n",
      "Train_Epoch: 22, [19200 / 60000(32%]\tTrain_Loss ; 0.008092\n",
      "Train_Epoch: 22, [22400 / 60000(37%]\tTrain_Loss ; 0.001180\n",
      "Train_Epoch: 22, [25600 / 60000(43%]\tTrain_Loss ; 0.008220\n",
      "Train_Epoch: 22, [28800 / 60000(48%]\tTrain_Loss ; 0.004591\n",
      "Train_Epoch: 22, [32000 / 60000(53%]\tTrain_Loss ; 0.011072\n",
      "Train_Epoch: 22, [35200 / 60000(59%]\tTrain_Loss ; 0.002066\n",
      "Train_Epoch: 22, [38400 / 60000(64%]\tTrain_Loss ; 0.023378\n",
      "Train_Epoch: 22, [41600 / 60000(69%]\tTrain_Loss ; 0.000718\n",
      "Train_Epoch: 22, [44800 / 60000(75%]\tTrain_Loss ; 0.005471\n",
      "Train_Epoch: 22, [48000 / 60000(80%]\tTrain_Loss ; 0.005799\n",
      "Train_Epoch: 22, [51200 / 60000(85%]\tTrain_Loss ; 0.031732\n",
      "Train_Epoch: 22, [54400 / 60000(91%]\tTrain_Loss ; 0.004905\n",
      "Train_Epoch: 22, [57600 / 60000(96%]\tTrain_Loss ; 0.026387\n",
      "\n",
      "[EPOCH: 22, \tTest_loss : 0.0641, \tTest_accuracy : 98.06%\n",
      "\n",
      "Train_Epoch: 23, [0 / 60000(0%]\tTrain_Loss ; 0.019278\n",
      "Train_Epoch: 23, [3200 / 60000(5%]\tTrain_Loss ; 0.007148\n",
      "Train_Epoch: 23, [6400 / 60000(11%]\tTrain_Loss ; 0.002980\n",
      "Train_Epoch: 23, [9600 / 60000(16%]\tTrain_Loss ; 0.029542\n",
      "Train_Epoch: 23, [12800 / 60000(21%]\tTrain_Loss ; 0.013314\n",
      "Train_Epoch: 23, [16000 / 60000(27%]\tTrain_Loss ; 0.001664\n",
      "Train_Epoch: 23, [19200 / 60000(32%]\tTrain_Loss ; 0.032191\n",
      "Train_Epoch: 23, [22400 / 60000(37%]\tTrain_Loss ; 0.007146\n",
      "Train_Epoch: 23, [25600 / 60000(43%]\tTrain_Loss ; 0.005320\n",
      "Train_Epoch: 23, [28800 / 60000(48%]\tTrain_Loss ; 0.023015\n",
      "Train_Epoch: 23, [32000 / 60000(53%]\tTrain_Loss ; 0.015933\n",
      "Train_Epoch: 23, [35200 / 60000(59%]\tTrain_Loss ; 0.004485\n",
      "Train_Epoch: 23, [38400 / 60000(64%]\tTrain_Loss ; 0.040637\n",
      "Train_Epoch: 23, [41600 / 60000(69%]\tTrain_Loss ; 0.035350\n",
      "Train_Epoch: 23, [44800 / 60000(75%]\tTrain_Loss ; 0.005874\n",
      "Train_Epoch: 23, [48000 / 60000(80%]\tTrain_Loss ; 0.001958\n",
      "Train_Epoch: 23, [51200 / 60000(85%]\tTrain_Loss ; 0.024168\n",
      "Train_Epoch: 23, [54400 / 60000(91%]\tTrain_Loss ; 0.003691\n",
      "Train_Epoch: 23, [57600 / 60000(96%]\tTrain_Loss ; 0.003005\n",
      "\n",
      "[EPOCH: 23, \tTest_loss : 0.0614, \tTest_accuracy : 98.03%\n",
      "\n",
      "Train_Epoch: 24, [0 / 60000(0%]\tTrain_Loss ; 0.010131\n",
      "Train_Epoch: 24, [3200 / 60000(5%]\tTrain_Loss ; 0.008730\n",
      "Train_Epoch: 24, [6400 / 60000(11%]\tTrain_Loss ; 0.022244\n",
      "Train_Epoch: 24, [9600 / 60000(16%]\tTrain_Loss ; 0.022800\n",
      "Train_Epoch: 24, [12800 / 60000(21%]\tTrain_Loss ; 0.001571\n",
      "Train_Epoch: 24, [16000 / 60000(27%]\tTrain_Loss ; 0.004606\n",
      "Train_Epoch: 24, [19200 / 60000(32%]\tTrain_Loss ; 0.024557\n",
      "Train_Epoch: 24, [22400 / 60000(37%]\tTrain_Loss ; 0.001154\n",
      "Train_Epoch: 24, [25600 / 60000(43%]\tTrain_Loss ; 0.007512\n",
      "Train_Epoch: 24, [28800 / 60000(48%]\tTrain_Loss ; 0.003862\n",
      "Train_Epoch: 24, [32000 / 60000(53%]\tTrain_Loss ; 0.004798\n",
      "Train_Epoch: 24, [35200 / 60000(59%]\tTrain_Loss ; 0.012681\n",
      "Train_Epoch: 24, [38400 / 60000(64%]\tTrain_Loss ; 0.012698\n",
      "Train_Epoch: 24, [41600 / 60000(69%]\tTrain_Loss ; 0.088496\n",
      "Train_Epoch: 24, [44800 / 60000(75%]\tTrain_Loss ; 0.015362\n",
      "Train_Epoch: 24, [48000 / 60000(80%]\tTrain_Loss ; 0.006145\n",
      "Train_Epoch: 24, [51200 / 60000(85%]\tTrain_Loss ; 0.002718\n",
      "Train_Epoch: 24, [54400 / 60000(91%]\tTrain_Loss ; 0.011312\n",
      "Train_Epoch: 24, [57600 / 60000(96%]\tTrain_Loss ; 0.009564\n",
      "\n",
      "[EPOCH: 24, \tTest_loss : 0.0629, \tTest_accuracy : 98.02%\n",
      "\n",
      "Train_Epoch: 25, [0 / 60000(0%]\tTrain_Loss ; 0.020584\n",
      "Train_Epoch: 25, [3200 / 60000(5%]\tTrain_Loss ; 0.000724\n",
      "Train_Epoch: 25, [6400 / 60000(11%]\tTrain_Loss ; 0.004172\n",
      "Train_Epoch: 25, [9600 / 60000(16%]\tTrain_Loss ; 0.002437\n",
      "Train_Epoch: 25, [12800 / 60000(21%]\tTrain_Loss ; 0.038981\n",
      "Train_Epoch: 25, [16000 / 60000(27%]\tTrain_Loss ; 0.013711\n",
      "Train_Epoch: 25, [19200 / 60000(32%]\tTrain_Loss ; 0.020550\n",
      "Train_Epoch: 25, [22400 / 60000(37%]\tTrain_Loss ; 0.002751\n",
      "Train_Epoch: 25, [25600 / 60000(43%]\tTrain_Loss ; 0.003702\n",
      "Train_Epoch: 25, [28800 / 60000(48%]\tTrain_Loss ; 0.003861\n",
      "Train_Epoch: 25, [32000 / 60000(53%]\tTrain_Loss ; 0.011883\n",
      "Train_Epoch: 25, [35200 / 60000(59%]\tTrain_Loss ; 0.049709\n",
      "Train_Epoch: 25, [38400 / 60000(64%]\tTrain_Loss ; 0.015404\n",
      "Train_Epoch: 25, [41600 / 60000(69%]\tTrain_Loss ; 0.000222\n",
      "Train_Epoch: 25, [44800 / 60000(75%]\tTrain_Loss ; 0.017982\n",
      "Train_Epoch: 25, [48000 / 60000(80%]\tTrain_Loss ; 0.004942\n",
      "Train_Epoch: 25, [51200 / 60000(85%]\tTrain_Loss ; 0.015191\n",
      "Train_Epoch: 25, [54400 / 60000(91%]\tTrain_Loss ; 0.011153\n",
      "Train_Epoch: 25, [57600 / 60000(96%]\tTrain_Loss ; 0.026580\n",
      "\n",
      "[EPOCH: 25, \tTest_loss : 0.0629, \tTest_accuracy : 98.09%\n",
      "\n",
      "Train_Epoch: 26, [0 / 60000(0%]\tTrain_Loss ; 0.002760\n",
      "Train_Epoch: 26, [3200 / 60000(5%]\tTrain_Loss ; 0.044618\n",
      "Train_Epoch: 26, [6400 / 60000(11%]\tTrain_Loss ; 0.012563\n",
      "Train_Epoch: 26, [9600 / 60000(16%]\tTrain_Loss ; 0.002478\n",
      "Train_Epoch: 26, [12800 / 60000(21%]\tTrain_Loss ; 0.002261\n",
      "Train_Epoch: 26, [16000 / 60000(27%]\tTrain_Loss ; 0.003845\n",
      "Train_Epoch: 26, [19200 / 60000(32%]\tTrain_Loss ; 0.000691\n",
      "Train_Epoch: 26, [22400 / 60000(37%]\tTrain_Loss ; 0.016787\n",
      "Train_Epoch: 26, [25600 / 60000(43%]\tTrain_Loss ; 0.002573\n",
      "Train_Epoch: 26, [28800 / 60000(48%]\tTrain_Loss ; 0.002248\n",
      "Train_Epoch: 26, [32000 / 60000(53%]\tTrain_Loss ; 0.010652\n",
      "Train_Epoch: 26, [35200 / 60000(59%]\tTrain_Loss ; 0.003778\n",
      "Train_Epoch: 26, [38400 / 60000(64%]\tTrain_Loss ; 0.027330\n",
      "Train_Epoch: 26, [41600 / 60000(69%]\tTrain_Loss ; 0.014128\n",
      "Train_Epoch: 26, [44800 / 60000(75%]\tTrain_Loss ; 0.003746\n",
      "Train_Epoch: 26, [48000 / 60000(80%]\tTrain_Loss ; 0.009318\n",
      "Train_Epoch: 26, [51200 / 60000(85%]\tTrain_Loss ; 0.001673\n",
      "Train_Epoch: 26, [54400 / 60000(91%]\tTrain_Loss ; 0.002755\n",
      "Train_Epoch: 26, [57600 / 60000(96%]\tTrain_Loss ; 0.010070\n",
      "\n",
      "[EPOCH: 26, \tTest_loss : 0.0622, \tTest_accuracy : 98.10%\n",
      "\n",
      "Train_Epoch: 27, [0 / 60000(0%]\tTrain_Loss ; 0.007396\n",
      "Train_Epoch: 27, [3200 / 60000(5%]\tTrain_Loss ; 0.001013\n",
      "Train_Epoch: 27, [6400 / 60000(11%]\tTrain_Loss ; 0.063675\n",
      "Train_Epoch: 27, [9600 / 60000(16%]\tTrain_Loss ; 0.017298\n",
      "Train_Epoch: 27, [12800 / 60000(21%]\tTrain_Loss ; 0.006961\n",
      "Train_Epoch: 27, [16000 / 60000(27%]\tTrain_Loss ; 0.013157\n",
      "Train_Epoch: 27, [19200 / 60000(32%]\tTrain_Loss ; 0.001550\n",
      "Train_Epoch: 27, [22400 / 60000(37%]\tTrain_Loss ; 0.003525\n",
      "Train_Epoch: 27, [25600 / 60000(43%]\tTrain_Loss ; 0.000463\n",
      "Train_Epoch: 27, [28800 / 60000(48%]\tTrain_Loss ; 0.005015\n",
      "Train_Epoch: 27, [32000 / 60000(53%]\tTrain_Loss ; 0.040051\n",
      "Train_Epoch: 27, [35200 / 60000(59%]\tTrain_Loss ; 0.002908\n",
      "Train_Epoch: 27, [38400 / 60000(64%]\tTrain_Loss ; 0.013552\n",
      "Train_Epoch: 27, [41600 / 60000(69%]\tTrain_Loss ; 0.017020\n",
      "Train_Epoch: 27, [44800 / 60000(75%]\tTrain_Loss ; 0.011252\n",
      "Train_Epoch: 27, [48000 / 60000(80%]\tTrain_Loss ; 0.005159\n",
      "Train_Epoch: 27, [51200 / 60000(85%]\tTrain_Loss ; 0.003442\n",
      "Train_Epoch: 27, [54400 / 60000(91%]\tTrain_Loss ; 0.008095\n",
      "Train_Epoch: 27, [57600 / 60000(96%]\tTrain_Loss ; 0.004335\n",
      "\n",
      "[EPOCH: 27, \tTest_loss : 0.0623, \tTest_accuracy : 98.04%\n",
      "\n",
      "Train_Epoch: 28, [0 / 60000(0%]\tTrain_Loss ; 0.008702\n",
      "Train_Epoch: 28, [3200 / 60000(5%]\tTrain_Loss ; 0.004858\n",
      "Train_Epoch: 28, [6400 / 60000(11%]\tTrain_Loss ; 0.012465\n",
      "Train_Epoch: 28, [9600 / 60000(16%]\tTrain_Loss ; 0.011822\n",
      "Train_Epoch: 28, [12800 / 60000(21%]\tTrain_Loss ; 0.017139\n",
      "Train_Epoch: 28, [16000 / 60000(27%]\tTrain_Loss ; 0.004871\n",
      "Train_Epoch: 28, [19200 / 60000(32%]\tTrain_Loss ; 0.005717\n",
      "Train_Epoch: 28, [22400 / 60000(37%]\tTrain_Loss ; 0.026573\n",
      "Train_Epoch: 28, [25600 / 60000(43%]\tTrain_Loss ; 0.023902\n",
      "Train_Epoch: 28, [28800 / 60000(48%]\tTrain_Loss ; 0.002567\n",
      "Train_Epoch: 28, [32000 / 60000(53%]\tTrain_Loss ; 0.016928\n",
      "Train_Epoch: 28, [35200 / 60000(59%]\tTrain_Loss ; 0.008400\n",
      "Train_Epoch: 28, [38400 / 60000(64%]\tTrain_Loss ; 0.015987\n",
      "Train_Epoch: 28, [41600 / 60000(69%]\tTrain_Loss ; 0.006993\n",
      "Train_Epoch: 28, [44800 / 60000(75%]\tTrain_Loss ; 0.009067\n",
      "Train_Epoch: 28, [48000 / 60000(80%]\tTrain_Loss ; 0.009090\n",
      "Train_Epoch: 28, [51200 / 60000(85%]\tTrain_Loss ; 0.002407\n",
      "Train_Epoch: 28, [54400 / 60000(91%]\tTrain_Loss ; 0.003931\n",
      "Train_Epoch: 28, [57600 / 60000(96%]\tTrain_Loss ; 0.005850\n",
      "\n",
      "[EPOCH: 28, \tTest_loss : 0.0630, \tTest_accuracy : 98.07%\n",
      "\n",
      "Train_Epoch: 29, [0 / 60000(0%]\tTrain_Loss ; 0.011499\n",
      "Train_Epoch: 29, [3200 / 60000(5%]\tTrain_Loss ; 0.004444\n",
      "Train_Epoch: 29, [6400 / 60000(11%]\tTrain_Loss ; 0.009405\n",
      "Train_Epoch: 29, [9600 / 60000(16%]\tTrain_Loss ; 0.001825\n",
      "Train_Epoch: 29, [12800 / 60000(21%]\tTrain_Loss ; 0.009324\n",
      "Train_Epoch: 29, [16000 / 60000(27%]\tTrain_Loss ; 0.009679\n",
      "Train_Epoch: 29, [19200 / 60000(32%]\tTrain_Loss ; 0.003825\n",
      "Train_Epoch: 29, [22400 / 60000(37%]\tTrain_Loss ; 0.002752\n",
      "Train_Epoch: 29, [25600 / 60000(43%]\tTrain_Loss ; 0.013141\n",
      "Train_Epoch: 29, [28800 / 60000(48%]\tTrain_Loss ; 0.002084\n",
      "Train_Epoch: 29, [32000 / 60000(53%]\tTrain_Loss ; 0.003418\n",
      "Train_Epoch: 29, [35200 / 60000(59%]\tTrain_Loss ; 0.009260\n",
      "Train_Epoch: 29, [38400 / 60000(64%]\tTrain_Loss ; 0.002774\n",
      "Train_Epoch: 29, [41600 / 60000(69%]\tTrain_Loss ; 0.091554\n",
      "Train_Epoch: 29, [44800 / 60000(75%]\tTrain_Loss ; 0.002197\n",
      "Train_Epoch: 29, [48000 / 60000(80%]\tTrain_Loss ; 0.010244\n",
      "Train_Epoch: 29, [51200 / 60000(85%]\tTrain_Loss ; 0.002145\n",
      "Train_Epoch: 29, [54400 / 60000(91%]\tTrain_Loss ; 0.014688\n",
      "Train_Epoch: 29, [57600 / 60000(96%]\tTrain_Loss ; 0.004650\n",
      "\n",
      "[EPOCH: 29, \tTest_loss : 0.0615, \tTest_accuracy : 98.17%\n",
      "\n",
      "Train_Epoch: 30, [0 / 60000(0%]\tTrain_Loss ; 0.003905\n",
      "Train_Epoch: 30, [3200 / 60000(5%]\tTrain_Loss ; 0.000683\n",
      "Train_Epoch: 30, [6400 / 60000(11%]\tTrain_Loss ; 0.025487\n",
      "Train_Epoch: 30, [9600 / 60000(16%]\tTrain_Loss ; 0.001871\n",
      "Train_Epoch: 30, [12800 / 60000(21%]\tTrain_Loss ; 0.005398\n",
      "Train_Epoch: 30, [16000 / 60000(27%]\tTrain_Loss ; 0.001071\n",
      "Train_Epoch: 30, [19200 / 60000(32%]\tTrain_Loss ; 0.001855\n",
      "Train_Epoch: 30, [22400 / 60000(37%]\tTrain_Loss ; 0.002389\n",
      "Train_Epoch: 30, [25600 / 60000(43%]\tTrain_Loss ; 0.006701\n",
      "Train_Epoch: 30, [28800 / 60000(48%]\tTrain_Loss ; 0.000757\n",
      "Train_Epoch: 30, [32000 / 60000(53%]\tTrain_Loss ; 0.002716\n",
      "Train_Epoch: 30, [35200 / 60000(59%]\tTrain_Loss ; 0.021282\n",
      "Train_Epoch: 30, [38400 / 60000(64%]\tTrain_Loss ; 0.003771\n",
      "Train_Epoch: 30, [41600 / 60000(69%]\tTrain_Loss ; 0.035467\n",
      "Train_Epoch: 30, [44800 / 60000(75%]\tTrain_Loss ; 0.007154\n",
      "Train_Epoch: 30, [48000 / 60000(80%]\tTrain_Loss ; 0.005588\n",
      "Train_Epoch: 30, [51200 / 60000(85%]\tTrain_Loss ; 0.006644\n",
      "Train_Epoch: 30, [54400 / 60000(91%]\tTrain_Loss ; 0.000819\n",
      "Train_Epoch: 30, [57600 / 60000(96%]\tTrain_Loss ; 0.009202\n",
      "\n",
      "[EPOCH: 30, \tTest_loss : 0.0619, \tTest_accuracy : 98.08%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "for Epoch in range(1, EPOCHS+1):\n",
    "    train(model, train_loader, optimizer)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        best_model = model\n",
    "    print(f'\\n[EPOCH: {Epoch}, \\tTest_loss : {(test_loss):.4f}, \\tTest_accuracy : {(test_accuracy):.2f}%\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.17 OrderedDict([('fc1.weight', tensor([[-7.5899e-05, -1.7329e-02,  2.9495e-02,  ..., -2.3345e-02,\n",
      "          2.8946e-02, -2.2269e-02],\n",
      "        [-3.5383e-02, -5.9891e-03,  3.2126e-02,  ...,  2.2320e-03,\n",
      "         -1.6744e-02,  1.7532e-02],\n",
      "        [ 3.3040e-02, -1.6697e-02, -2.0733e-02,  ..., -2.1317e-03,\n",
      "         -3.4657e-02,  4.7622e-03],\n",
      "        ...,\n",
      "        [ 3.0991e-02,  3.4051e-02,  2.9256e-02,  ..., -1.1826e-02,\n",
      "          3.2236e-02, -3.5086e-02],\n",
      "        [ 1.9918e-02,  4.9862e-03,  1.2175e-03,  ...,  2.0819e-02,\n",
      "         -7.8109e-03, -2.5359e-02],\n",
      "        [-2.3862e-02, -3.5468e-02,  2.1325e-02,  ..., -1.0364e-02,\n",
      "         -6.5366e-03, -5.6773e-03]], device='cuda:0')), ('fc1.bias', tensor([-7.7873e-02, -4.6205e-02,  3.8034e-02,  5.3612e-02,  2.1900e-02,\n",
      "         8.7030e-02, -3.2439e-02, -7.2824e-02,  2.6272e-02,  3.7349e-03,\n",
      "         4.4609e-02,  6.3178e-02, -3.7934e-03,  4.2325e-03, -3.2951e-02,\n",
      "         2.0851e-03, -8.7217e-02,  2.3843e-02,  5.3513e-03, -2.1503e-02,\n",
      "        -7.4589e-03,  4.1473e-02, -3.3638e-02, -1.9362e-02,  4.9830e-03,\n",
      "         1.8638e-02, -3.1091e-02,  1.3175e-02,  1.8158e-02, -2.9306e-02,\n",
      "         3.9246e-02, -7.1980e-03, -4.1416e-02, -1.2641e-03, -1.8155e-03,\n",
      "        -9.7786e-02,  6.1235e-02,  4.4059e-02, -6.0668e-02,  6.3179e-02,\n",
      "         6.4131e-02,  2.8893e-02, -2.8961e-02,  2.0026e-02,  1.0191e-01,\n",
      "         4.0476e-03, -5.0472e-02, -8.5421e-02, -5.7937e-02,  1.6135e-02,\n",
      "         3.8320e-02,  3.4634e-02,  6.9658e-03, -5.4916e-03, -3.1395e-02,\n",
      "         5.0034e-03,  7.3177e-02, -3.6910e-03,  3.9345e-02,  5.6948e-02,\n",
      "         1.9252e-03,  5.0072e-02,  3.0958e-02, -2.7846e-02,  3.7838e-02,\n",
      "         1.1945e-02, -2.1492e-02,  5.0303e-02,  8.8443e-03, -2.2649e-02,\n",
      "        -2.9256e-02, -8.4479e-03,  5.0799e-03,  4.9130e-02,  3.3612e-03,\n",
      "         5.0076e-02,  3.4290e-02,  1.7165e-02, -2.2737e-02, -4.3764e-02,\n",
      "        -1.0693e-02, -3.0501e-02,  2.1168e-02,  5.0206e-02,  4.1221e-02,\n",
      "         3.8198e-02, -3.6015e-02, -9.2904e-03,  2.9413e-03,  8.2123e-02,\n",
      "        -2.3907e-02, -1.7562e-02,  4.4472e-02, -1.6364e-02,  5.1030e-02,\n",
      "         4.8585e-02,  6.3037e-02,  2.7442e-02,  6.0853e-02,  4.9882e-03,\n",
      "         8.6519e-02, -2.9132e-02,  1.9377e-02,  3.9556e-04,  2.7509e-02,\n",
      "         2.6699e-02, -4.4570e-02,  4.2221e-02,  1.0884e-01,  3.0231e-02,\n",
      "         8.0809e-03,  5.0894e-02,  4.3406e-02,  7.3475e-02, -5.4262e-03,\n",
      "         6.9634e-02,  6.2098e-02, -3.1538e-02, -6.6700e-02,  2.2236e-02,\n",
      "         1.8432e-02,  6.6584e-02,  4.5715e-02,  4.9823e-02, -2.9574e-02,\n",
      "         2.4445e-03, -4.3248e-02,  1.3920e-02, -3.2551e-02, -2.9646e-02,\n",
      "         1.6780e-02, -4.3487e-02,  3.1845e-02, -7.0471e-03,  1.6990e-02,\n",
      "         5.3466e-02,  6.1455e-02,  5.5817e-02, -2.3445e-02, -1.4091e-02,\n",
      "        -9.4035e-03, -2.0302e-02, -8.1429e-03,  1.0668e-02,  2.5588e-02,\n",
      "         3.2185e-02,  2.4522e-02,  3.0475e-02,  1.8296e-02,  6.8701e-02,\n",
      "         3.8606e-02,  5.8382e-02,  5.1691e-04,  6.5647e-02, -4.4858e-03,\n",
      "         1.3206e-02, -4.0451e-02,  1.4847e-02, -5.2600e-02,  7.5579e-02,\n",
      "         1.5798e-02,  3.8809e-02,  5.8151e-02, -6.7454e-03, -4.9031e-02,\n",
      "         2.7036e-02,  4.6311e-02,  4.0593e-02, -5.4648e-02,  5.2366e-02,\n",
      "        -1.2443e-02,  3.9545e-02, -1.6021e-02,  8.4030e-03, -6.1457e-02,\n",
      "         4.2523e-02,  2.9941e-02, -2.6774e-02,  6.5607e-02,  4.9405e-02,\n",
      "        -1.4061e-02, -2.6284e-02,  8.7604e-02, -2.7948e-02, -4.6941e-02,\n",
      "        -3.1490e-02,  3.6483e-03,  3.9812e-02, -2.0294e-02,  4.2012e-02,\n",
      "         4.1546e-03, -1.4633e-02,  6.0351e-02, -8.5701e-03,  6.2998e-02,\n",
      "         4.2265e-02, -3.7276e-02, -2.3371e-02,  7.5673e-03, -1.3768e-02,\n",
      "        -3.2240e-03,  4.4846e-02,  7.0790e-02,  4.7842e-02,  3.3172e-02,\n",
      "        -5.3603e-02,  1.2098e-02, -8.1801e-03, -1.2035e-02,  6.1398e-03,\n",
      "         7.3122e-02, -3.4947e-02,  6.9427e-03,  1.7924e-02, -3.5125e-02,\n",
      "         5.2501e-02,  6.5811e-02,  5.5203e-02,  2.4622e-02,  8.4316e-04,\n",
      "        -1.6758e-02, -1.7529e-02,  1.0699e-04,  4.6670e-02,  1.6788e-02,\n",
      "         2.7088e-02, -3.3182e-02,  3.5867e-02, -3.2096e-02,  2.8100e-04,\n",
      "         3.7562e-02,  5.5340e-02,  5.2885e-02, -3.4975e-02,  5.6069e-02,\n",
      "        -2.1775e-02, -4.5099e-03, -6.0407e-03,  4.1237e-02,  2.7207e-02,\n",
      "         5.1291e-02,  6.3367e-02, -2.1604e-02,  2.8026e-03,  4.5520e-02,\n",
      "        -7.2916e-03, -3.5572e-02, -8.4117e-03,  2.1026e-02,  1.0158e-02,\n",
      "         1.7050e-02,  3.4871e-02,  6.4766e-03, -6.0292e-02, -1.6637e-02,\n",
      "        -5.7903e-02, -7.3795e-04,  4.9163e-02,  1.1431e-02,  2.8135e-02,\n",
      "        -1.0463e-02,  6.2970e-02,  6.1325e-02,  3.0296e-03, -1.1368e-02,\n",
      "         9.2350e-02, -4.6806e-02, -7.7017e-03, -3.5029e-02,  1.3011e-03,\n",
      "         4.6667e-02,  1.1451e-01,  9.5902e-03,  1.8791e-04, -6.3633e-02,\n",
      "         1.0012e-02, -1.0200e-02, -5.8135e-02, -3.4850e-02, -3.9899e-02,\n",
      "         7.9281e-02, -3.0794e-02,  1.1414e-01,  6.8653e-02,  2.0537e-02,\n",
      "        -2.9649e-03,  1.1709e-02,  9.3560e-03, -7.8651e-02,  9.9157e-03,\n",
      "        -3.4193e-02,  5.4691e-02, -4.6612e-02,  8.5176e-03, -5.8473e-02,\n",
      "        -8.9637e-02,  3.1695e-02,  3.2925e-02, -4.3671e-02,  6.7393e-02,\n",
      "         6.1095e-02, -3.2344e-02,  2.5361e-02, -9.9552e-03, -6.4800e-03,\n",
      "         1.9934e-02,  3.1179e-02,  8.5294e-03, -4.0048e-03, -2.0473e-02,\n",
      "         5.2714e-03, -5.0906e-03, -5.2323e-03, -2.1452e-02, -7.1933e-02,\n",
      "         5.5678e-03, -1.1594e-02,  1.5143e-02,  9.0056e-03, -3.7236e-02,\n",
      "        -2.7789e-02,  2.1754e-02, -3.5336e-02,  3.2109e-02, -2.3285e-02,\n",
      "        -1.2858e-02,  3.3596e-02, -4.9810e-03,  4.1813e-02, -1.8241e-03,\n",
      "         5.7956e-02, -2.5110e-02, -6.2423e-02,  2.9047e-02, -2.9559e-02,\n",
      "         6.4867e-03,  5.5832e-03,  6.2169e-02, -1.2371e-02,  2.0036e-02,\n",
      "         5.1381e-02, -4.3180e-03,  4.1899e-02,  5.7348e-02,  5.9939e-02,\n",
      "        -2.1421e-02,  6.3622e-02, -9.4296e-02, -5.3672e-03, -1.0550e-02,\n",
      "         4.4190e-02,  7.4793e-02, -2.6404e-02,  4.1542e-02, -2.7380e-02,\n",
      "         2.8111e-02, -1.4344e-02,  1.3970e-02,  7.5477e-03, -8.9864e-03,\n",
      "         4.9764e-02, -4.3079e-02,  6.8526e-03, -1.6674e-02, -6.5536e-02,\n",
      "        -7.4649e-02, -3.5320e-03,  7.6029e-02, -2.2460e-03,  5.4034e-02,\n",
      "         2.7340e-02, -9.8097e-02, -5.9937e-04,  2.2180e-02,  1.6447e-02,\n",
      "        -1.6055e-02,  5.7155e-02, -2.3210e-02, -2.3402e-03,  2.3447e-02,\n",
      "         3.7380e-02, -2.7678e-03, -1.0481e-02, -3.6676e-02, -1.0031e-02,\n",
      "         6.4604e-02,  1.2862e-02,  1.2142e-02,  2.7929e-02,  5.9707e-03,\n",
      "        -1.1189e-02,  1.6245e-02,  1.1041e-02,  1.0463e-01, -7.1540e-02,\n",
      "        -2.1755e-02,  3.3930e-02,  2.0000e-02,  5.2599e-03,  2.5946e-02,\n",
      "         1.9189e-02,  3.3791e-02,  9.2566e-02,  7.8768e-03,  6.0252e-02,\n",
      "         2.7216e-02,  1.8160e-02, -4.0222e-02, -8.7398e-04,  1.6435e-02,\n",
      "         8.3634e-02,  1.8984e-02,  2.8220e-02,  1.3272e-02, -1.3277e-02,\n",
      "         1.7578e-02, -1.9616e-02,  5.7115e-03, -3.5794e-02, -2.8237e-02,\n",
      "         1.1179e-03, -1.4674e-02,  2.7270e-02,  4.2388e-02,  6.1985e-02,\n",
      "         1.3477e-02,  4.7684e-02,  1.4366e-02, -1.8443e-02,  3.3388e-02,\n",
      "        -4.3370e-02, -6.4156e-02,  1.5597e-02,  6.2864e-03,  6.5232e-02,\n",
      "        -2.2770e-02,  1.9635e-02, -3.8661e-02,  1.0966e-01,  7.6677e-02,\n",
      "         2.9228e-02,  3.9530e-02, -1.2080e-03,  3.3284e-02, -9.1643e-03,\n",
      "         1.7696e-03, -7.7774e-03,  5.1813e-02, -3.0416e-03,  4.2896e-02,\n",
      "         3.2698e-02,  3.8543e-03,  3.8340e-02, -9.5359e-03,  2.8324e-02,\n",
      "         3.9507e-02,  5.8692e-03,  1.2398e-01,  3.4476e-02,  2.6443e-02,\n",
      "         1.4721e-02, -1.5315e-02,  1.1026e-02,  2.0805e-02, -1.6881e-02,\n",
      "         3.5103e-02,  7.3235e-02, -2.3234e-02,  1.2202e-02,  5.4288e-02,\n",
      "         3.7269e-02,  4.6750e-03, -4.3867e-03,  1.4494e-02, -1.1817e-02,\n",
      "         4.0360e-02, -2.7772e-02, -7.5154e-03,  1.3732e-02, -1.9668e-03,\n",
      "        -4.9624e-02,  1.4834e-02, -2.1754e-03,  1.3863e-02, -3.8820e-03,\n",
      "         6.4917e-02,  7.5554e-02,  3.3870e-03, -2.9158e-02, -1.1308e-02,\n",
      "         2.9760e-02, -5.0679e-02, -3.3455e-02,  1.5699e-02,  5.7958e-02,\n",
      "        -3.3681e-02,  5.2361e-03,  4.8509e-02,  1.9532e-02,  3.5095e-02,\n",
      "         1.9730e-02,  2.4310e-02,  1.1522e-02, -2.3607e-02, -2.0881e-02,\n",
      "         3.4091e-02,  5.8247e-04,  2.1551e-03,  2.7053e-02,  6.4791e-03,\n",
      "         3.9129e-02,  2.1201e-02], device='cuda:0')), ('fc2.weight', tensor([[-0.0282, -0.0169,  0.0333,  ...,  0.0201,  0.0182,  0.0463],\n",
      "        [-0.0097,  0.0116, -0.0383,  ...,  0.0198, -0.0281,  0.0327],\n",
      "        [ 0.0461,  0.0212, -0.0264,  ..., -0.0200, -0.0566,  0.0233],\n",
      "        ...,\n",
      "        [-0.0232, -0.0161, -0.0550,  ..., -0.0397,  0.0364, -0.0403],\n",
      "        [-0.0272, -0.0504,  0.0553,  ...,  0.0060,  0.0707,  0.0246],\n",
      "        [ 0.0388, -0.0035,  0.0466,  ..., -0.0140,  0.0187, -0.0116]],\n",
      "       device='cuda:0')), ('fc2.bias', tensor([ 0.0582, -0.0290,  0.0260,  0.0412,  0.0396, -0.0464,  0.0043,  0.0157,\n",
      "         0.0055, -0.0050,  0.0304,  0.0900,  0.0113,  0.0283,  0.0469,  0.0693,\n",
      "         0.0340,  0.0180,  0.0076,  0.0228,  0.0463, -0.0345,  0.0440,  0.0187,\n",
      "         0.0712,  0.0942,  0.0887,  0.0969,  0.0316,  0.0326, -0.0522, -0.0319,\n",
      "        -0.0294,  0.0437,  0.0245,  0.0919, -0.0088, -0.0086,  0.0354, -0.0357,\n",
      "         0.0372,  0.0661,  0.0489,  0.1239,  0.0427,  0.0433,  0.0762, -0.0425,\n",
      "         0.0200,  0.0730, -0.0185,  0.1153, -0.0272, -0.0252,  0.0055,  0.0305,\n",
      "         0.0400,  0.0365, -0.0351,  0.0348, -0.0205,  0.0265,  0.0108,  0.0260,\n",
      "         0.0249, -0.0256,  0.0002,  0.0779,  0.0413,  0.0481,  0.0374,  0.0296,\n",
      "         0.0766, -0.0141,  0.0407, -0.0102, -0.0238,  0.0390,  0.0797,  0.0436,\n",
      "        -0.0111, -0.0193, -0.0309,  0.0406,  0.0294,  0.0637,  0.0176, -0.0235,\n",
      "         0.0386,  0.0080,  0.0003,  0.0265,  0.0637, -0.0300,  0.0217, -0.0374,\n",
      "        -0.0177, -0.0420, -0.0335,  0.0102, -0.0280,  0.0514,  0.1007,  0.0137,\n",
      "         0.0023, -0.0118,  0.0121,  0.0022,  0.0072, -0.0025,  0.0678,  0.0568,\n",
      "         0.0623, -0.0124,  0.0657,  0.0862,  0.0099, -0.0259, -0.0234,  0.0218,\n",
      "         0.0094,  0.0173,  0.0733,  0.0388, -0.0408,  0.0084,  0.0236,  0.0170,\n",
      "        -0.0065, -0.0326,  0.0192,  0.0100,  0.0878, -0.0260,  0.0586,  0.0506,\n",
      "         0.0266,  0.0619, -0.0156,  0.0252,  0.0124,  0.0088,  0.0940,  0.1015,\n",
      "         0.0064, -0.0005,  0.0342,  0.0664,  0.0198,  0.0361,  0.0185,  0.0283,\n",
      "         0.0197, -0.0278, -0.0069, -0.0410,  0.0668,  0.0474,  0.0136, -0.0006,\n",
      "         0.0192,  0.0028, -0.0194,  0.0057,  0.0364,  0.0393, -0.0164,  0.0766,\n",
      "        -0.0071,  0.0096, -0.0423, -0.0089,  0.0326,  0.0599, -0.0201, -0.0193,\n",
      "         0.0864,  0.0134,  0.0055,  0.0296,  0.0546,  0.0429,  0.0169, -0.0095,\n",
      "         0.0220,  0.0650,  0.0551,  0.0014,  0.0095, -0.0524, -0.0034,  0.0113,\n",
      "         0.0076,  0.0390,  0.0201,  0.0759,  0.0484, -0.0401,  0.0073, -0.0334,\n",
      "         0.0063,  0.0284,  0.0064, -0.0380,  0.0225, -0.0264,  0.0326, -0.0069,\n",
      "        -0.0387, -0.0166,  0.0230, -0.0243,  0.0514,  0.0731,  0.0253,  0.0187,\n",
      "         0.0068, -0.0245, -0.0180,  0.0753, -0.0399,  0.0034,  0.0658,  0.0643,\n",
      "        -0.0089,  0.0153,  0.0665,  0.0314,  0.0478,  0.0262,  0.0814,  0.0311,\n",
      "        -0.0007,  0.0042,  0.0263, -0.0167, -0.0178,  0.0555, -0.0195,  0.0309,\n",
      "        -0.0060, -0.0446, -0.0210, -0.0155,  0.0284,  0.0017,  0.0660,  0.0031,\n",
      "         0.0399,  0.0088,  0.0566,  0.0728,  0.0354,  0.0031,  0.0122, -0.0055],\n",
      "       device='cuda:0')), ('fc3.weight', tensor([[-0.1900, -0.0211, -0.0786,  ..., -0.1099,  0.2305,  0.1295],\n",
      "        [ 0.2310, -0.0219, -0.0983,  ..., -0.0438, -0.0283,  0.1222],\n",
      "        [-0.3623, -0.0509, -0.1884,  ...,  0.3313,  0.0917, -0.0585],\n",
      "        ...,\n",
      "        [-0.3187, -0.0017,  0.2747,  ...,  0.0990, -0.4294,  0.3531],\n",
      "        [ 0.2348,  0.0099, -0.1162,  ...,  0.0716,  0.2821, -0.1233],\n",
      "        [-0.1355,  0.0189,  0.3227,  ..., -0.2128,  0.2596, -0.1079]],\n",
      "       device='cuda:0')), ('fc3.bias', tensor([-2.2664e-01,  1.5044e-01, -1.1141e-02, -1.0492e-01, -6.6379e-03,\n",
      "         1.8339e-01, -1.7381e-02,  8.6552e-03, -1.4005e-01, -1.6142e-04],\n",
      "       device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(best_accuracy, best_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "334544a737ead5017040ac753f52220319955d2381f512ab105ce194db781c37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
