{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1650 \t torch Version :  1.12.0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available() :\n",
    "    DEVICE = torch.device('cuda')\n",
    "else :\n",
    "    DEVICE = torch.device('cpu')\n",
    "print(torch.cuda.get_device_name(), '\\t', 'torch Version : ', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='../../data/MNIST/',\n",
    "                                download=True,\n",
    "                                train=True,\n",
    "                                transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root='../../data/MNIST/',\n",
    "                                download=True,\n",
    "                                train=False,\n",
    "                                transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                            shuffle=True,\n",
    "                                            batch_size = BATCH_SIZE)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                            shuffle=False,\n",
    "                                            batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
      "torch.FloatTensor torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "for (X_train, y_train) in train_loader:\n",
    "    print(X_train.size(), y_train.size())\n",
    "    print(X_train.type(), y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pltsize = 1\n",
    "plt.figure(figsize=(pltsize * 10, pltsize))\n",
    "for i in range(10) :\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i, :, :, :].numpy().reshape(28, 28), cmap='gray_r')\n",
    "    plt.title('label :' + str(y_train[i].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import dropout\n",
    "\n",
    "\n",
    "class Net(nn.Module) :\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 64)\n",
    "        self.fc2 = nn.LSTM(input_size= 64, hidden_size = 128, dropout = 0.25)\n",
    "        self.fc3 = nn.GRU(input_size = 128, hidden_size = 256, dropout = 0.25)\n",
    "        self.fc4 = nn.Linear(256, 64)\n",
    "        self.fc5 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 28*28)\n",
    "        x = self.fc1(x)\n",
    "        x, _ = self.fc2(x)\n",
    "        x =  F.relu(x)\n",
    "        x, _ = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc5(x)\n",
    "        x = F.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): LSTM(64, 128, dropout=0.25)\n",
      "  (fc3): GRU(128, 256, dropout=0.25)\n",
      "  (fc4): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (fc5): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, log_intervals = 100):\n",
    "    model.train()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        output = model(image)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_intervals == 0:\n",
    "            print('Train_Epoch : {}, [{}/{}]({:.0f}%)\\tTrain_Loss : {:.4f}'.format(\n",
    "                Epoch, batch_idx * len(image), len(train_loader.dataset),\n",
    "                batch_idx * 100 / len(train_loader), loss.item()\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "    for image, label in test_loader:\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        output = model(image)\n",
    "        test_loss += criterion(output, label)\n",
    "        prediction = output.max(1, keepdim=True)[1]\n",
    "        correct +=  prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = correct * 100 / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_26064\\4181537889.py:23: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Epoch : 1, [0/60000](0%)\tTrain_Loss : 2.2939\n",
      "Train_Epoch : 1, [6400/60000](11%)\tTrain_Loss : 1.3171\n",
      "Train_Epoch : 1, [12800/60000](21%)\tTrain_Loss : 1.0035\n",
      "Train_Epoch : 1, [19200/60000](32%)\tTrain_Loss : 0.9063\n",
      "Train_Epoch : 1, [25600/60000](43%)\tTrain_Loss : 0.6590\n",
      "Train_Epoch : 1, [32000/60000](53%)\tTrain_Loss : 0.5919\n",
      "Train_Epoch : 1, [38400/60000](64%)\tTrain_Loss : 0.6112\n",
      "Train_Epoch : 1, [44800/60000](75%)\tTrain_Loss : 0.6824\n",
      "Train_Epoch : 1, [51200/60000](85%)\tTrain_Loss : 0.8441\n",
      "Train_Epoch : 1, [57600/60000](96%)\tTrain_Loss : 0.4290\n",
      "\n",
      "Epoch : 1\tTest_loss : 0.4472\tTest_accuracy : 86.79%\n",
      "\n",
      "Train_Epoch : 2, [0/60000](0%)\tTrain_Loss : 0.3036\n",
      "Train_Epoch : 2, [6400/60000](11%)\tTrain_Loss : 0.5648\n",
      "Train_Epoch : 2, [12800/60000](21%)\tTrain_Loss : 0.4350\n",
      "Train_Epoch : 2, [19200/60000](32%)\tTrain_Loss : 0.5339\n",
      "Train_Epoch : 2, [25600/60000](43%)\tTrain_Loss : 0.4646\n",
      "Train_Epoch : 2, [32000/60000](53%)\tTrain_Loss : 0.8054\n",
      "Train_Epoch : 2, [38400/60000](64%)\tTrain_Loss : 0.3193\n",
      "Train_Epoch : 2, [44800/60000](75%)\tTrain_Loss : 0.4971\n",
      "Train_Epoch : 2, [51200/60000](85%)\tTrain_Loss : 0.3754\n",
      "Train_Epoch : 2, [57600/60000](96%)\tTrain_Loss : 0.6688\n",
      "\n",
      "Epoch : 2\tTest_loss : 0.4556\tTest_accuracy : 86.77%\n",
      "\n",
      "Train_Epoch : 3, [0/60000](0%)\tTrain_Loss : 0.6005\n",
      "Train_Epoch : 3, [6400/60000](11%)\tTrain_Loss : 0.5155\n",
      "Train_Epoch : 3, [12800/60000](21%)\tTrain_Loss : 0.8343\n",
      "Train_Epoch : 3, [19200/60000](32%)\tTrain_Loss : 0.5763\n",
      "Train_Epoch : 3, [25600/60000](43%)\tTrain_Loss : 0.5696\n",
      "Train_Epoch : 3, [32000/60000](53%)\tTrain_Loss : 0.6926\n",
      "Train_Epoch : 3, [38400/60000](64%)\tTrain_Loss : 0.7030\n",
      "Train_Epoch : 3, [44800/60000](75%)\tTrain_Loss : 0.5235\n",
      "Train_Epoch : 3, [51200/60000](85%)\tTrain_Loss : 0.2731\n",
      "Train_Epoch : 3, [57600/60000](96%)\tTrain_Loss : 0.5017\n",
      "\n",
      "Epoch : 3\tTest_loss : 0.4040\tTest_accuracy : 87.82%\n",
      "\n",
      "Train_Epoch : 4, [0/60000](0%)\tTrain_Loss : 0.3521\n",
      "Train_Epoch : 4, [6400/60000](11%)\tTrain_Loss : 0.3347\n",
      "Train_Epoch : 4, [12800/60000](21%)\tTrain_Loss : 0.4388\n",
      "Train_Epoch : 4, [19200/60000](32%)\tTrain_Loss : 0.1861\n",
      "Train_Epoch : 4, [25600/60000](43%)\tTrain_Loss : 0.4042\n",
      "Train_Epoch : 4, [32000/60000](53%)\tTrain_Loss : 0.4118\n",
      "Train_Epoch : 4, [38400/60000](64%)\tTrain_Loss : 0.3753\n",
      "Train_Epoch : 4, [44800/60000](75%)\tTrain_Loss : 0.2867\n",
      "Train_Epoch : 4, [51200/60000](85%)\tTrain_Loss : 0.4552\n",
      "Train_Epoch : 4, [57600/60000](96%)\tTrain_Loss : 0.3478\n",
      "\n",
      "Epoch : 4\tTest_loss : 0.4039\tTest_accuracy : 87.89%\n",
      "\n",
      "Train_Epoch : 5, [0/60000](0%)\tTrain_Loss : 0.1969\n",
      "Train_Epoch : 5, [6400/60000](11%)\tTrain_Loss : 0.5526\n",
      "Train_Epoch : 5, [12800/60000](21%)\tTrain_Loss : 0.2954\n",
      "Train_Epoch : 5, [19200/60000](32%)\tTrain_Loss : 0.3419\n",
      "Train_Epoch : 5, [25600/60000](43%)\tTrain_Loss : 0.2983\n",
      "Train_Epoch : 5, [32000/60000](53%)\tTrain_Loss : 0.3380\n",
      "Train_Epoch : 5, [38400/60000](64%)\tTrain_Loss : 0.4114\n",
      "Train_Epoch : 5, [44800/60000](75%)\tTrain_Loss : 0.3038\n",
      "Train_Epoch : 5, [51200/60000](85%)\tTrain_Loss : 0.6065\n",
      "Train_Epoch : 5, [57600/60000](96%)\tTrain_Loss : 0.6243\n",
      "\n",
      "Epoch : 5\tTest_loss : 0.3985\tTest_accuracy : 87.24%\n",
      "\n",
      "Train_Epoch : 6, [0/60000](0%)\tTrain_Loss : 0.1971\n",
      "Train_Epoch : 6, [6400/60000](11%)\tTrain_Loss : 0.5300\n",
      "Train_Epoch : 6, [12800/60000](21%)\tTrain_Loss : 0.3732\n",
      "Train_Epoch : 6, [19200/60000](32%)\tTrain_Loss : 0.8037\n",
      "Train_Epoch : 6, [25600/60000](43%)\tTrain_Loss : 0.2917\n",
      "Train_Epoch : 6, [32000/60000](53%)\tTrain_Loss : 1.1607\n",
      "Train_Epoch : 6, [38400/60000](64%)\tTrain_Loss : 0.3928\n",
      "Train_Epoch : 6, [44800/60000](75%)\tTrain_Loss : 0.2514\n",
      "Train_Epoch : 6, [51200/60000](85%)\tTrain_Loss : 0.3137\n",
      "Train_Epoch : 6, [57600/60000](96%)\tTrain_Loss : 0.2554\n",
      "\n",
      "Epoch : 6\tTest_loss : 0.3955\tTest_accuracy : 88.48%\n",
      "\n",
      "Train_Epoch : 7, [0/60000](0%)\tTrain_Loss : 0.3395\n",
      "Train_Epoch : 7, [6400/60000](11%)\tTrain_Loss : 0.2190\n",
      "Train_Epoch : 7, [12800/60000](21%)\tTrain_Loss : 0.3687\n",
      "Train_Epoch : 7, [19200/60000](32%)\tTrain_Loss : 0.4204\n",
      "Train_Epoch : 7, [25600/60000](43%)\tTrain_Loss : 0.5074\n",
      "Train_Epoch : 7, [32000/60000](53%)\tTrain_Loss : 0.2318\n",
      "Train_Epoch : 7, [38400/60000](64%)\tTrain_Loss : 0.4035\n",
      "Train_Epoch : 7, [44800/60000](75%)\tTrain_Loss : 0.4238\n",
      "Train_Epoch : 7, [51200/60000](85%)\tTrain_Loss : 0.2672\n",
      "Train_Epoch : 7, [57600/60000](96%)\tTrain_Loss : 0.3168\n",
      "\n",
      "Epoch : 7\tTest_loss : 0.3889\tTest_accuracy : 88.44%\n",
      "\n",
      "Train_Epoch : 8, [0/60000](0%)\tTrain_Loss : 0.4702\n",
      "Train_Epoch : 8, [6400/60000](11%)\tTrain_Loss : 0.6860\n",
      "Train_Epoch : 8, [12800/60000](21%)\tTrain_Loss : 0.2686\n",
      "Train_Epoch : 8, [19200/60000](32%)\tTrain_Loss : 0.4066\n",
      "Train_Epoch : 8, [25600/60000](43%)\tTrain_Loss : 0.3215\n",
      "Train_Epoch : 8, [32000/60000](53%)\tTrain_Loss : 0.5241\n",
      "Train_Epoch : 8, [38400/60000](64%)\tTrain_Loss : 0.4355\n",
      "Train_Epoch : 8, [44800/60000](75%)\tTrain_Loss : 0.3150\n",
      "Train_Epoch : 8, [51200/60000](85%)\tTrain_Loss : 0.6088\n",
      "Train_Epoch : 8, [57600/60000](96%)\tTrain_Loss : 0.7129\n",
      "\n",
      "Epoch : 8\tTest_loss : 0.3856\tTest_accuracy : 89.08%\n",
      "\n",
      "Train_Epoch : 9, [0/60000](0%)\tTrain_Loss : 0.4436\n",
      "Train_Epoch : 9, [6400/60000](11%)\tTrain_Loss : 0.3299\n",
      "Train_Epoch : 9, [12800/60000](21%)\tTrain_Loss : 0.4120\n",
      "Train_Epoch : 9, [19200/60000](32%)\tTrain_Loss : 0.4312\n",
      "Train_Epoch : 9, [25600/60000](43%)\tTrain_Loss : 0.4737\n",
      "Train_Epoch : 9, [32000/60000](53%)\tTrain_Loss : 0.3384\n",
      "Train_Epoch : 9, [38400/60000](64%)\tTrain_Loss : 0.3474\n",
      "Train_Epoch : 9, [44800/60000](75%)\tTrain_Loss : 0.3635\n",
      "Train_Epoch : 9, [51200/60000](85%)\tTrain_Loss : 0.3318\n",
      "Train_Epoch : 9, [57600/60000](96%)\tTrain_Loss : 0.2183\n",
      "\n",
      "Epoch : 9\tTest_loss : 0.3966\tTest_accuracy : 88.51%\n",
      "\n",
      "Train_Epoch : 10, [0/60000](0%)\tTrain_Loss : 0.4952\n",
      "Train_Epoch : 10, [6400/60000](11%)\tTrain_Loss : 0.2819\n",
      "Train_Epoch : 10, [12800/60000](21%)\tTrain_Loss : 0.1983\n",
      "Train_Epoch : 10, [19200/60000](32%)\tTrain_Loss : 0.2893\n",
      "Train_Epoch : 10, [25600/60000](43%)\tTrain_Loss : 0.4216\n",
      "Train_Epoch : 10, [32000/60000](53%)\tTrain_Loss : 0.7264\n",
      "Train_Epoch : 10, [38400/60000](64%)\tTrain_Loss : 0.8478\n",
      "Train_Epoch : 10, [44800/60000](75%)\tTrain_Loss : 0.3454\n",
      "Train_Epoch : 10, [51200/60000](85%)\tTrain_Loss : 0.5312\n",
      "Train_Epoch : 10, [57600/60000](96%)\tTrain_Loss : 0.4968\n",
      "\n",
      "Epoch : 10\tTest_loss : 0.3979\tTest_accuracy : 88.55%\n",
      "\n",
      "Train_Epoch : 11, [0/60000](0%)\tTrain_Loss : 0.3287\n",
      "Train_Epoch : 11, [6400/60000](11%)\tTrain_Loss : 0.2181\n",
      "Train_Epoch : 11, [12800/60000](21%)\tTrain_Loss : 0.3068\n",
      "Train_Epoch : 11, [19200/60000](32%)\tTrain_Loss : 0.3760\n",
      "Train_Epoch : 11, [25600/60000](43%)\tTrain_Loss : 0.4652\n",
      "Train_Epoch : 11, [32000/60000](53%)\tTrain_Loss : 0.3836\n",
      "Train_Epoch : 11, [38400/60000](64%)\tTrain_Loss : 0.6344\n",
      "Train_Epoch : 11, [44800/60000](75%)\tTrain_Loss : 0.4146\n",
      "Train_Epoch : 11, [51200/60000](85%)\tTrain_Loss : 0.3886\n",
      "Train_Epoch : 11, [57600/60000](96%)\tTrain_Loss : 0.5940\n",
      "\n",
      "Epoch : 11\tTest_loss : 0.3585\tTest_accuracy : 90.03%\n",
      "\n",
      "Train_Epoch : 12, [0/60000](0%)\tTrain_Loss : 0.4189\n",
      "Train_Epoch : 12, [6400/60000](11%)\tTrain_Loss : 0.4509\n",
      "Train_Epoch : 12, [12800/60000](21%)\tTrain_Loss : 0.2222\n",
      "Train_Epoch : 12, [19200/60000](32%)\tTrain_Loss : 0.3563\n",
      "Train_Epoch : 12, [25600/60000](43%)\tTrain_Loss : 0.3081\n",
      "Train_Epoch : 12, [32000/60000](53%)\tTrain_Loss : 0.2412\n",
      "Train_Epoch : 12, [38400/60000](64%)\tTrain_Loss : 0.3823\n",
      "Train_Epoch : 12, [44800/60000](75%)\tTrain_Loss : 0.4488\n",
      "Train_Epoch : 12, [51200/60000](85%)\tTrain_Loss : 0.3887\n",
      "Train_Epoch : 12, [57600/60000](96%)\tTrain_Loss : 0.3926\n",
      "\n",
      "Epoch : 12\tTest_loss : 0.3812\tTest_accuracy : 88.86%\n",
      "\n",
      "Train_Epoch : 13, [0/60000](0%)\tTrain_Loss : 0.2278\n",
      "Train_Epoch : 13, [6400/60000](11%)\tTrain_Loss : 0.3151\n",
      "Train_Epoch : 13, [12800/60000](21%)\tTrain_Loss : 0.3787\n",
      "Train_Epoch : 13, [19200/60000](32%)\tTrain_Loss : 0.5191\n",
      "Train_Epoch : 13, [25600/60000](43%)\tTrain_Loss : 0.4313\n",
      "Train_Epoch : 13, [32000/60000](53%)\tTrain_Loss : 0.4308\n",
      "Train_Epoch : 13, [38400/60000](64%)\tTrain_Loss : 0.4154\n",
      "Train_Epoch : 13, [44800/60000](75%)\tTrain_Loss : 0.4507\n",
      "Train_Epoch : 13, [51200/60000](85%)\tTrain_Loss : 0.2574\n",
      "Train_Epoch : 13, [57600/60000](96%)\tTrain_Loss : 0.4284\n",
      "\n",
      "Epoch : 13\tTest_loss : 0.4070\tTest_accuracy : 87.96%\n",
      "\n",
      "Train_Epoch : 14, [0/60000](0%)\tTrain_Loss : 0.4468\n",
      "Train_Epoch : 14, [6400/60000](11%)\tTrain_Loss : 0.3638\n",
      "Train_Epoch : 14, [12800/60000](21%)\tTrain_Loss : 0.3176\n",
      "Train_Epoch : 14, [19200/60000](32%)\tTrain_Loss : 0.4677\n",
      "Train_Epoch : 14, [25600/60000](43%)\tTrain_Loss : 0.3675\n",
      "Train_Epoch : 14, [32000/60000](53%)\tTrain_Loss : 0.3051\n",
      "Train_Epoch : 14, [38400/60000](64%)\tTrain_Loss : 0.3002\n",
      "Train_Epoch : 14, [44800/60000](75%)\tTrain_Loss : 0.4930\n",
      "Train_Epoch : 14, [51200/60000](85%)\tTrain_Loss : 0.6543\n",
      "Train_Epoch : 14, [57600/60000](96%)\tTrain_Loss : 0.3726\n",
      "\n",
      "Epoch : 14\tTest_loss : 0.4023\tTest_accuracy : 87.57%\n",
      "\n",
      "Train_Epoch : 15, [0/60000](0%)\tTrain_Loss : 0.4045\n",
      "Train_Epoch : 15, [6400/60000](11%)\tTrain_Loss : 0.5090\n",
      "Train_Epoch : 15, [12800/60000](21%)\tTrain_Loss : 0.4288\n",
      "Train_Epoch : 15, [19200/60000](32%)\tTrain_Loss : 0.3522\n",
      "Train_Epoch : 15, [25600/60000](43%)\tTrain_Loss : 0.4092\n",
      "Train_Epoch : 15, [32000/60000](53%)\tTrain_Loss : 0.4156\n",
      "Train_Epoch : 15, [38400/60000](64%)\tTrain_Loss : 0.5739\n",
      "Train_Epoch : 15, [44800/60000](75%)\tTrain_Loss : 0.5194\n",
      "Train_Epoch : 15, [51200/60000](85%)\tTrain_Loss : 0.2605\n",
      "Train_Epoch : 15, [57600/60000](96%)\tTrain_Loss : 0.3237\n",
      "\n",
      "Epoch : 15\tTest_loss : 0.4017\tTest_accuracy : 87.97%\n",
      "\n",
      "Train_Epoch : 16, [0/60000](0%)\tTrain_Loss : 0.5116\n",
      "Train_Epoch : 16, [6400/60000](11%)\tTrain_Loss : 0.4392\n",
      "Train_Epoch : 16, [12800/60000](21%)\tTrain_Loss : 0.2176\n",
      "Train_Epoch : 16, [19200/60000](32%)\tTrain_Loss : 0.3295\n",
      "Train_Epoch : 16, [25600/60000](43%)\tTrain_Loss : 0.2679\n",
      "Train_Epoch : 16, [32000/60000](53%)\tTrain_Loss : 0.3479\n",
      "Train_Epoch : 16, [38400/60000](64%)\tTrain_Loss : 0.6193\n",
      "Train_Epoch : 16, [44800/60000](75%)\tTrain_Loss : 0.6383\n",
      "Train_Epoch : 16, [51200/60000](85%)\tTrain_Loss : 0.5163\n",
      "Train_Epoch : 16, [57600/60000](96%)\tTrain_Loss : 0.4232\n",
      "\n",
      "Epoch : 16\tTest_loss : 0.3816\tTest_accuracy : 88.33%\n",
      "\n",
      "Train_Epoch : 17, [0/60000](0%)\tTrain_Loss : 0.2326\n",
      "Train_Epoch : 17, [6400/60000](11%)\tTrain_Loss : 0.6892\n",
      "Train_Epoch : 17, [12800/60000](21%)\tTrain_Loss : 0.2856\n",
      "Train_Epoch : 17, [19200/60000](32%)\tTrain_Loss : 0.5871\n",
      "Train_Epoch : 17, [25600/60000](43%)\tTrain_Loss : 0.2565\n",
      "Train_Epoch : 17, [32000/60000](53%)\tTrain_Loss : 0.5097\n",
      "Train_Epoch : 17, [38400/60000](64%)\tTrain_Loss : 0.4646\n",
      "Train_Epoch : 17, [44800/60000](75%)\tTrain_Loss : 0.3617\n",
      "Train_Epoch : 17, [51200/60000](85%)\tTrain_Loss : 0.6886\n",
      "Train_Epoch : 17, [57600/60000](96%)\tTrain_Loss : 0.3320\n",
      "\n",
      "Epoch : 17\tTest_loss : 0.3846\tTest_accuracy : 88.56%\n",
      "\n",
      "Train_Epoch : 18, [0/60000](0%)\tTrain_Loss : 0.5324\n",
      "Train_Epoch : 18, [6400/60000](11%)\tTrain_Loss : 0.3253\n",
      "Train_Epoch : 18, [12800/60000](21%)\tTrain_Loss : 0.5597\n",
      "Train_Epoch : 18, [19200/60000](32%)\tTrain_Loss : 0.2360\n",
      "Train_Epoch : 18, [25600/60000](43%)\tTrain_Loss : 0.2683\n",
      "Train_Epoch : 18, [32000/60000](53%)\tTrain_Loss : 0.2698\n",
      "Train_Epoch : 18, [38400/60000](64%)\tTrain_Loss : 0.3887\n",
      "Train_Epoch : 18, [44800/60000](75%)\tTrain_Loss : 0.1777\n",
      "Train_Epoch : 18, [51200/60000](85%)\tTrain_Loss : 0.4014\n",
      "Train_Epoch : 18, [57600/60000](96%)\tTrain_Loss : 0.3113\n",
      "\n",
      "Epoch : 18\tTest_loss : 0.3797\tTest_accuracy : 88.80%\n",
      "\n",
      "Train_Epoch : 19, [0/60000](0%)\tTrain_Loss : 0.3410\n",
      "Train_Epoch : 19, [6400/60000](11%)\tTrain_Loss : 0.3981\n",
      "Train_Epoch : 19, [12800/60000](21%)\tTrain_Loss : 0.4210\n",
      "Train_Epoch : 19, [19200/60000](32%)\tTrain_Loss : 0.3997\n",
      "Train_Epoch : 19, [25600/60000](43%)\tTrain_Loss : 0.2779\n",
      "Train_Epoch : 19, [32000/60000](53%)\tTrain_Loss : 0.6951\n",
      "Train_Epoch : 19, [38400/60000](64%)\tTrain_Loss : 0.3169\n",
      "Train_Epoch : 19, [44800/60000](75%)\tTrain_Loss : 0.3112\n",
      "Train_Epoch : 19, [51200/60000](85%)\tTrain_Loss : 0.3756\n",
      "Train_Epoch : 19, [57600/60000](96%)\tTrain_Loss : 0.3654\n",
      "\n",
      "Epoch : 19\tTest_loss : 0.3452\tTest_accuracy : 90.09%\n",
      "\n",
      "Train_Epoch : 20, [0/60000](0%)\tTrain_Loss : 0.4095\n",
      "Train_Epoch : 20, [6400/60000](11%)\tTrain_Loss : 0.4712\n",
      "Train_Epoch : 20, [12800/60000](21%)\tTrain_Loss : 0.3141\n",
      "Train_Epoch : 20, [19200/60000](32%)\tTrain_Loss : 0.4563\n",
      "Train_Epoch : 20, [25600/60000](43%)\tTrain_Loss : 0.2183\n",
      "Train_Epoch : 20, [32000/60000](53%)\tTrain_Loss : 0.4272\n",
      "Train_Epoch : 20, [38400/60000](64%)\tTrain_Loss : 0.2948\n",
      "Train_Epoch : 20, [44800/60000](75%)\tTrain_Loss : 0.6223\n",
      "Train_Epoch : 20, [51200/60000](85%)\tTrain_Loss : 0.6035\n",
      "Train_Epoch : 20, [57600/60000](96%)\tTrain_Loss : 0.5776\n",
      "\n",
      "Epoch : 20\tTest_loss : 0.3879\tTest_accuracy : 88.48%\n",
      "\n",
      "Train_Epoch : 21, [0/60000](0%)\tTrain_Loss : 0.4118\n",
      "Train_Epoch : 21, [6400/60000](11%)\tTrain_Loss : 0.2077\n",
      "Train_Epoch : 21, [12800/60000](21%)\tTrain_Loss : 0.3678\n",
      "Train_Epoch : 21, [19200/60000](32%)\tTrain_Loss : 0.5172\n",
      "Train_Epoch : 21, [25600/60000](43%)\tTrain_Loss : 0.3009\n",
      "Train_Epoch : 21, [32000/60000](53%)\tTrain_Loss : 0.3281\n",
      "Train_Epoch : 21, [38400/60000](64%)\tTrain_Loss : 0.1852\n",
      "Train_Epoch : 21, [44800/60000](75%)\tTrain_Loss : 0.3600\n",
      "Train_Epoch : 21, [51200/60000](85%)\tTrain_Loss : 0.6088\n",
      "Train_Epoch : 21, [57600/60000](96%)\tTrain_Loss : 0.3554\n",
      "\n",
      "Epoch : 21\tTest_loss : 0.3976\tTest_accuracy : 88.19%\n",
      "\n",
      "Train_Epoch : 22, [0/60000](0%)\tTrain_Loss : 0.2851\n",
      "Train_Epoch : 22, [6400/60000](11%)\tTrain_Loss : 0.5377\n",
      "Train_Epoch : 22, [12800/60000](21%)\tTrain_Loss : 0.2751\n",
      "Train_Epoch : 22, [19200/60000](32%)\tTrain_Loss : 0.2671\n",
      "Train_Epoch : 22, [25600/60000](43%)\tTrain_Loss : 0.3093\n",
      "Train_Epoch : 22, [32000/60000](53%)\tTrain_Loss : 0.6604\n",
      "Train_Epoch : 22, [38400/60000](64%)\tTrain_Loss : 0.2549\n",
      "Train_Epoch : 22, [44800/60000](75%)\tTrain_Loss : 0.3479\n",
      "Train_Epoch : 22, [51200/60000](85%)\tTrain_Loss : 0.2948\n",
      "Train_Epoch : 22, [57600/60000](96%)\tTrain_Loss : 0.2109\n",
      "\n",
      "Epoch : 22\tTest_loss : 0.3571\tTest_accuracy : 89.34%\n",
      "\n",
      "Train_Epoch : 23, [0/60000](0%)\tTrain_Loss : 0.3117\n",
      "Train_Epoch : 23, [6400/60000](11%)\tTrain_Loss : 0.5216\n",
      "Train_Epoch : 23, [12800/60000](21%)\tTrain_Loss : 0.3909\n",
      "Train_Epoch : 23, [19200/60000](32%)\tTrain_Loss : 0.3512\n",
      "Train_Epoch : 23, [25600/60000](43%)\tTrain_Loss : 0.2787\n",
      "Train_Epoch : 23, [32000/60000](53%)\tTrain_Loss : 0.5049\n",
      "Train_Epoch : 23, [38400/60000](64%)\tTrain_Loss : 0.6803\n",
      "Train_Epoch : 23, [44800/60000](75%)\tTrain_Loss : 0.3165\n",
      "Train_Epoch : 23, [51200/60000](85%)\tTrain_Loss : 0.5508\n",
      "Train_Epoch : 23, [57600/60000](96%)\tTrain_Loss : 0.5780\n",
      "\n",
      "Epoch : 23\tTest_loss : 0.4238\tTest_accuracy : 87.36%\n",
      "\n",
      "Train_Epoch : 24, [0/60000](0%)\tTrain_Loss : 0.2771\n",
      "Train_Epoch : 24, [6400/60000](11%)\tTrain_Loss : 0.5596\n",
      "Train_Epoch : 24, [12800/60000](21%)\tTrain_Loss : 0.4171\n",
      "Train_Epoch : 24, [19200/60000](32%)\tTrain_Loss : 0.4161\n",
      "Train_Epoch : 24, [25600/60000](43%)\tTrain_Loss : 0.1794\n",
      "Train_Epoch : 24, [32000/60000](53%)\tTrain_Loss : 0.4332\n",
      "Train_Epoch : 24, [38400/60000](64%)\tTrain_Loss : 0.4595\n",
      "Train_Epoch : 24, [44800/60000](75%)\tTrain_Loss : 0.3021\n",
      "Train_Epoch : 24, [51200/60000](85%)\tTrain_Loss : 0.2523\n",
      "Train_Epoch : 24, [57600/60000](96%)\tTrain_Loss : 0.4705\n",
      "\n",
      "Epoch : 24\tTest_loss : 0.3762\tTest_accuracy : 88.88%\n",
      "\n",
      "Train_Epoch : 25, [0/60000](0%)\tTrain_Loss : 0.3735\n",
      "Train_Epoch : 25, [6400/60000](11%)\tTrain_Loss : 0.3601\n",
      "Train_Epoch : 25, [12800/60000](21%)\tTrain_Loss : 0.2643\n",
      "Train_Epoch : 25, [19200/60000](32%)\tTrain_Loss : 0.4961\n",
      "Train_Epoch : 25, [25600/60000](43%)\tTrain_Loss : 0.4731\n",
      "Train_Epoch : 25, [32000/60000](53%)\tTrain_Loss : 0.5984\n",
      "Train_Epoch : 25, [38400/60000](64%)\tTrain_Loss : 0.3893\n",
      "Train_Epoch : 25, [44800/60000](75%)\tTrain_Loss : 0.3731\n",
      "Train_Epoch : 25, [51200/60000](85%)\tTrain_Loss : 0.5802\n",
      "Train_Epoch : 25, [57600/60000](96%)\tTrain_Loss : 0.5713\n",
      "\n",
      "Epoch : 25\tTest_loss : 0.3988\tTest_accuracy : 88.20%\n",
      "\n",
      "Train_Epoch : 26, [0/60000](0%)\tTrain_Loss : 0.3989\n",
      "Train_Epoch : 26, [6400/60000](11%)\tTrain_Loss : 0.3874\n",
      "Train_Epoch : 26, [12800/60000](21%)\tTrain_Loss : 0.1991\n",
      "Train_Epoch : 26, [19200/60000](32%)\tTrain_Loss : 0.3343\n",
      "Train_Epoch : 26, [25600/60000](43%)\tTrain_Loss : 0.4181\n",
      "Train_Epoch : 26, [32000/60000](53%)\tTrain_Loss : 0.3117\n",
      "Train_Epoch : 26, [38400/60000](64%)\tTrain_Loss : 0.1605\n",
      "Train_Epoch : 26, [44800/60000](75%)\tTrain_Loss : 0.3172\n",
      "Train_Epoch : 26, [51200/60000](85%)\tTrain_Loss : 0.4769\n",
      "Train_Epoch : 26, [57600/60000](96%)\tTrain_Loss : 0.5638\n",
      "\n",
      "Epoch : 26\tTest_loss : 0.3700\tTest_accuracy : 88.79%\n",
      "\n",
      "Train_Epoch : 27, [0/60000](0%)\tTrain_Loss : 0.4423\n",
      "Train_Epoch : 27, [6400/60000](11%)\tTrain_Loss : 0.5581\n",
      "Train_Epoch : 27, [12800/60000](21%)\tTrain_Loss : 0.3283\n",
      "Train_Epoch : 27, [19200/60000](32%)\tTrain_Loss : 0.6835\n",
      "Train_Epoch : 27, [25600/60000](43%)\tTrain_Loss : 0.3172\n",
      "Train_Epoch : 27, [32000/60000](53%)\tTrain_Loss : 0.5527\n",
      "Train_Epoch : 27, [38400/60000](64%)\tTrain_Loss : 0.5014\n",
      "Train_Epoch : 27, [44800/60000](75%)\tTrain_Loss : 0.5002\n",
      "Train_Epoch : 27, [51200/60000](85%)\tTrain_Loss : 0.2905\n",
      "Train_Epoch : 27, [57600/60000](96%)\tTrain_Loss : 0.3279\n",
      "\n",
      "Epoch : 27\tTest_loss : 0.3521\tTest_accuracy : 89.73%\n",
      "\n",
      "Train_Epoch : 28, [0/60000](0%)\tTrain_Loss : 0.3927\n",
      "Train_Epoch : 28, [6400/60000](11%)\tTrain_Loss : 0.4998\n",
      "Train_Epoch : 28, [12800/60000](21%)\tTrain_Loss : 0.3081\n",
      "Train_Epoch : 28, [19200/60000](32%)\tTrain_Loss : 0.3968\n",
      "Train_Epoch : 28, [25600/60000](43%)\tTrain_Loss : 0.1482\n",
      "Train_Epoch : 28, [32000/60000](53%)\tTrain_Loss : 0.4131\n",
      "Train_Epoch : 28, [38400/60000](64%)\tTrain_Loss : 0.2479\n",
      "Train_Epoch : 28, [44800/60000](75%)\tTrain_Loss : 0.3269\n",
      "Train_Epoch : 28, [51200/60000](85%)\tTrain_Loss : 0.2641\n",
      "Train_Epoch : 28, [57600/60000](96%)\tTrain_Loss : 0.3437\n",
      "\n",
      "Epoch : 28\tTest_loss : 0.3723\tTest_accuracy : 88.65%\n",
      "\n",
      "Train_Epoch : 29, [0/60000](0%)\tTrain_Loss : 0.4059\n",
      "Train_Epoch : 29, [6400/60000](11%)\tTrain_Loss : 0.4499\n",
      "Train_Epoch : 29, [12800/60000](21%)\tTrain_Loss : 0.3687\n",
      "Train_Epoch : 29, [19200/60000](32%)\tTrain_Loss : 0.3128\n",
      "Train_Epoch : 29, [25600/60000](43%)\tTrain_Loss : 0.4015\n",
      "Train_Epoch : 29, [32000/60000](53%)\tTrain_Loss : 0.4132\n",
      "Train_Epoch : 29, [38400/60000](64%)\tTrain_Loss : 0.4175\n",
      "Train_Epoch : 29, [44800/60000](75%)\tTrain_Loss : 0.4579\n",
      "Train_Epoch : 29, [51200/60000](85%)\tTrain_Loss : 0.2539\n",
      "Train_Epoch : 29, [57600/60000](96%)\tTrain_Loss : 0.3677\n",
      "\n",
      "Epoch : 29\tTest_loss : 0.4091\tTest_accuracy : 87.54%\n",
      "\n",
      "Train_Epoch : 30, [0/60000](0%)\tTrain_Loss : 0.4669\n",
      "Train_Epoch : 30, [6400/60000](11%)\tTrain_Loss : 0.6308\n",
      "Train_Epoch : 30, [12800/60000](21%)\tTrain_Loss : 0.3672\n",
      "Train_Epoch : 30, [19200/60000](32%)\tTrain_Loss : 0.3593\n",
      "Train_Epoch : 30, [25600/60000](43%)\tTrain_Loss : 0.3668\n",
      "Train_Epoch : 30, [32000/60000](53%)\tTrain_Loss : 0.3942\n",
      "Train_Epoch : 30, [38400/60000](64%)\tTrain_Loss : 0.5039\n",
      "Train_Epoch : 30, [44800/60000](75%)\tTrain_Loss : 0.6208\n",
      "Train_Epoch : 30, [51200/60000](85%)\tTrain_Loss : 0.3690\n",
      "Train_Epoch : 30, [57600/60000](96%)\tTrain_Loss : 0.6885\n",
      "\n",
      "Epoch : 30\tTest_loss : 0.3745\tTest_accuracy : 88.59%\n",
      "\n",
      "Train_Epoch : 31, [0/60000](0%)\tTrain_Loss : 0.3724\n",
      "Train_Epoch : 31, [6400/60000](11%)\tTrain_Loss : 0.4098\n",
      "Train_Epoch : 31, [12800/60000](21%)\tTrain_Loss : 0.3756\n",
      "Train_Epoch : 31, [19200/60000](32%)\tTrain_Loss : 0.5329\n",
      "Train_Epoch : 31, [25600/60000](43%)\tTrain_Loss : 0.7112\n",
      "Train_Epoch : 31, [32000/60000](53%)\tTrain_Loss : 0.4133\n",
      "Train_Epoch : 31, [38400/60000](64%)\tTrain_Loss : 0.5185\n",
      "Train_Epoch : 31, [44800/60000](75%)\tTrain_Loss : 0.2301\n",
      "Train_Epoch : 31, [51200/60000](85%)\tTrain_Loss : 0.3853\n",
      "Train_Epoch : 31, [57600/60000](96%)\tTrain_Loss : 0.4132\n",
      "\n",
      "Epoch : 31\tTest_loss : 0.3898\tTest_accuracy : 88.32%\n",
      "\n",
      "Train_Epoch : 32, [0/60000](0%)\tTrain_Loss : 0.5751\n",
      "Train_Epoch : 32, [6400/60000](11%)\tTrain_Loss : 0.2891\n",
      "Train_Epoch : 32, [12800/60000](21%)\tTrain_Loss : 0.2397\n",
      "Train_Epoch : 32, [19200/60000](32%)\tTrain_Loss : 0.4574\n",
      "Train_Epoch : 32, [25600/60000](43%)\tTrain_Loss : 0.6026\n",
      "Train_Epoch : 32, [32000/60000](53%)\tTrain_Loss : 0.4107\n",
      "Train_Epoch : 32, [38400/60000](64%)\tTrain_Loss : 0.1477\n",
      "Train_Epoch : 32, [44800/60000](75%)\tTrain_Loss : 0.6876\n",
      "Train_Epoch : 32, [51200/60000](85%)\tTrain_Loss : 0.1852\n",
      "Train_Epoch : 32, [57600/60000](96%)\tTrain_Loss : 0.4135\n",
      "\n",
      "Epoch : 32\tTest_loss : 0.3598\tTest_accuracy : 89.12%\n",
      "\n",
      "Train_Epoch : 33, [0/60000](0%)\tTrain_Loss : 0.1673\n",
      "Train_Epoch : 33, [6400/60000](11%)\tTrain_Loss : 0.4645\n",
      "Train_Epoch : 33, [12800/60000](21%)\tTrain_Loss : 0.4457\n",
      "Train_Epoch : 33, [19200/60000](32%)\tTrain_Loss : 0.3568\n",
      "Train_Epoch : 33, [25600/60000](43%)\tTrain_Loss : 0.2297\n",
      "Train_Epoch : 33, [32000/60000](53%)\tTrain_Loss : 0.4630\n",
      "Train_Epoch : 33, [38400/60000](64%)\tTrain_Loss : 0.3100\n",
      "Train_Epoch : 33, [44800/60000](75%)\tTrain_Loss : 0.4089\n",
      "Train_Epoch : 33, [51200/60000](85%)\tTrain_Loss : 0.4321\n",
      "Train_Epoch : 33, [57600/60000](96%)\tTrain_Loss : 0.4981\n",
      "\n",
      "Epoch : 33\tTest_loss : 0.3603\tTest_accuracy : 88.90%\n",
      "\n",
      "Train_Epoch : 34, [0/60000](0%)\tTrain_Loss : 0.4117\n",
      "Train_Epoch : 34, [6400/60000](11%)\tTrain_Loss : 0.3251\n",
      "Train_Epoch : 34, [12800/60000](21%)\tTrain_Loss : 0.5246\n",
      "Train_Epoch : 34, [19200/60000](32%)\tTrain_Loss : 0.6043\n",
      "Train_Epoch : 34, [25600/60000](43%)\tTrain_Loss : 0.3769\n",
      "Train_Epoch : 34, [32000/60000](53%)\tTrain_Loss : 0.6054\n",
      "Train_Epoch : 34, [38400/60000](64%)\tTrain_Loss : 0.4034\n",
      "Train_Epoch : 34, [44800/60000](75%)\tTrain_Loss : 0.5654\n",
      "Train_Epoch : 34, [51200/60000](85%)\tTrain_Loss : 0.3542\n",
      "Train_Epoch : 34, [57600/60000](96%)\tTrain_Loss : 0.5673\n",
      "\n",
      "Epoch : 34\tTest_loss : 0.4914\tTest_accuracy : 85.15%\n",
      "\n",
      "Train_Epoch : 35, [0/60000](0%)\tTrain_Loss : 0.6134\n",
      "Train_Epoch : 35, [6400/60000](11%)\tTrain_Loss : 0.3035\n",
      "Train_Epoch : 35, [12800/60000](21%)\tTrain_Loss : 0.6210\n",
      "Train_Epoch : 35, [19200/60000](32%)\tTrain_Loss : 0.5290\n",
      "Train_Epoch : 35, [25600/60000](43%)\tTrain_Loss : 0.2926\n",
      "Train_Epoch : 35, [32000/60000](53%)\tTrain_Loss : 0.4623\n",
      "Train_Epoch : 35, [38400/60000](64%)\tTrain_Loss : 0.4048\n",
      "Train_Epoch : 35, [44800/60000](75%)\tTrain_Loss : 0.5480\n",
      "Train_Epoch : 35, [51200/60000](85%)\tTrain_Loss : 0.5973\n",
      "Train_Epoch : 35, [57600/60000](96%)\tTrain_Loss : 0.6452\n",
      "\n",
      "Epoch : 35\tTest_loss : 0.3951\tTest_accuracy : 88.09%\n",
      "\n",
      "Train_Epoch : 36, [0/60000](0%)\tTrain_Loss : 0.6010\n",
      "Train_Epoch : 36, [6400/60000](11%)\tTrain_Loss : 0.4839\n",
      "Train_Epoch : 36, [12800/60000](21%)\tTrain_Loss : 0.6519\n",
      "Train_Epoch : 36, [19200/60000](32%)\tTrain_Loss : 0.5072\n",
      "Train_Epoch : 36, [25600/60000](43%)\tTrain_Loss : 0.3621\n",
      "Train_Epoch : 36, [32000/60000](53%)\tTrain_Loss : 0.9373\n",
      "Train_Epoch : 36, [38400/60000](64%)\tTrain_Loss : 0.3476\n",
      "Train_Epoch : 36, [44800/60000](75%)\tTrain_Loss : 0.4208\n",
      "Train_Epoch : 36, [51200/60000](85%)\tTrain_Loss : 0.5766\n",
      "Train_Epoch : 36, [57600/60000](96%)\tTrain_Loss : 0.2580\n",
      "\n",
      "Epoch : 36\tTest_loss : 0.4061\tTest_accuracy : 87.57%\n",
      "\n",
      "Train_Epoch : 37, [0/60000](0%)\tTrain_Loss : 0.2272\n",
      "Train_Epoch : 37, [6400/60000](11%)\tTrain_Loss : 0.3143\n",
      "Train_Epoch : 37, [12800/60000](21%)\tTrain_Loss : 0.3380\n",
      "Train_Epoch : 37, [19200/60000](32%)\tTrain_Loss : 0.2576\n",
      "Train_Epoch : 37, [25600/60000](43%)\tTrain_Loss : 0.5667\n",
      "Train_Epoch : 37, [32000/60000](53%)\tTrain_Loss : 0.3738\n",
      "Train_Epoch : 37, [38400/60000](64%)\tTrain_Loss : 0.4880\n",
      "Train_Epoch : 37, [44800/60000](75%)\tTrain_Loss : 0.4593\n",
      "Train_Epoch : 37, [51200/60000](85%)\tTrain_Loss : 0.2295\n",
      "Train_Epoch : 37, [57600/60000](96%)\tTrain_Loss : 0.1746\n",
      "\n",
      "Epoch : 37\tTest_loss : 0.3428\tTest_accuracy : 89.97%\n",
      "\n",
      "Train_Epoch : 38, [0/60000](0%)\tTrain_Loss : 0.4250\n",
      "Train_Epoch : 38, [6400/60000](11%)\tTrain_Loss : 0.2420\n",
      "Train_Epoch : 38, [12800/60000](21%)\tTrain_Loss : 0.3157\n",
      "Train_Epoch : 38, [19200/60000](32%)\tTrain_Loss : 0.3301\n",
      "Train_Epoch : 38, [25600/60000](43%)\tTrain_Loss : 0.4426\n",
      "Train_Epoch : 38, [32000/60000](53%)\tTrain_Loss : 0.2617\n",
      "Train_Epoch : 38, [38400/60000](64%)\tTrain_Loss : 0.4434\n",
      "Train_Epoch : 38, [44800/60000](75%)\tTrain_Loss : 0.6698\n",
      "Train_Epoch : 38, [51200/60000](85%)\tTrain_Loss : 0.3438\n",
      "Train_Epoch : 38, [57600/60000](96%)\tTrain_Loss : 0.4079\n",
      "\n",
      "Epoch : 38\tTest_loss : 0.3614\tTest_accuracy : 89.42%\n",
      "\n",
      "Train_Epoch : 39, [0/60000](0%)\tTrain_Loss : 0.3249\n",
      "Train_Epoch : 39, [6400/60000](11%)\tTrain_Loss : 0.4183\n",
      "Train_Epoch : 39, [12800/60000](21%)\tTrain_Loss : 0.2080\n",
      "Train_Epoch : 39, [19200/60000](32%)\tTrain_Loss : 0.3751\n",
      "Train_Epoch : 39, [25600/60000](43%)\tTrain_Loss : 0.3812\n",
      "Train_Epoch : 39, [32000/60000](53%)\tTrain_Loss : 0.2242\n",
      "Train_Epoch : 39, [38400/60000](64%)\tTrain_Loss : 0.3474\n",
      "Train_Epoch : 39, [44800/60000](75%)\tTrain_Loss : 0.3543\n",
      "Train_Epoch : 39, [51200/60000](85%)\tTrain_Loss : 0.2673\n",
      "Train_Epoch : 39, [57600/60000](96%)\tTrain_Loss : 0.4664\n",
      "\n",
      "Epoch : 39\tTest_loss : 0.3747\tTest_accuracy : 89.03%\n",
      "\n",
      "Train_Epoch : 40, [0/60000](0%)\tTrain_Loss : 0.3779\n",
      "Train_Epoch : 40, [6400/60000](11%)\tTrain_Loss : 0.2663\n",
      "Train_Epoch : 40, [12800/60000](21%)\tTrain_Loss : 0.3914\n",
      "Train_Epoch : 40, [19200/60000](32%)\tTrain_Loss : 0.3613\n",
      "Train_Epoch : 40, [25600/60000](43%)\tTrain_Loss : 0.5014\n",
      "Train_Epoch : 40, [32000/60000](53%)\tTrain_Loss : 0.4627\n",
      "Train_Epoch : 40, [38400/60000](64%)\tTrain_Loss : 0.2455\n",
      "Train_Epoch : 40, [44800/60000](75%)\tTrain_Loss : 0.3088\n",
      "Train_Epoch : 40, [51200/60000](85%)\tTrain_Loss : 0.3065\n",
      "Train_Epoch : 40, [57600/60000](96%)\tTrain_Loss : 0.3318\n",
      "\n",
      "Epoch : 40\tTest_loss : 0.3699\tTest_accuracy : 89.13%\n",
      "\n",
      "Train_Epoch : 41, [0/60000](0%)\tTrain_Loss : 0.4295\n",
      "Train_Epoch : 41, [6400/60000](11%)\tTrain_Loss : 0.4337\n",
      "Train_Epoch : 41, [12800/60000](21%)\tTrain_Loss : 0.4027\n",
      "Train_Epoch : 41, [19200/60000](32%)\tTrain_Loss : 0.1849\n",
      "Train_Epoch : 41, [25600/60000](43%)\tTrain_Loss : 0.2574\n",
      "Train_Epoch : 41, [32000/60000](53%)\tTrain_Loss : 0.6172\n",
      "Train_Epoch : 41, [38400/60000](64%)\tTrain_Loss : 0.4222\n",
      "Train_Epoch : 41, [44800/60000](75%)\tTrain_Loss : 0.4538\n",
      "Train_Epoch : 41, [51200/60000](85%)\tTrain_Loss : 0.2215\n",
      "Train_Epoch : 41, [57600/60000](96%)\tTrain_Loss : 0.4684\n",
      "\n",
      "Epoch : 41\tTest_loss : 0.4158\tTest_accuracy : 88.10%\n",
      "\n",
      "Train_Epoch : 42, [0/60000](0%)\tTrain_Loss : 0.2943\n",
      "Train_Epoch : 42, [6400/60000](11%)\tTrain_Loss : 0.3136\n",
      "Train_Epoch : 42, [12800/60000](21%)\tTrain_Loss : 0.3066\n",
      "Train_Epoch : 42, [19200/60000](32%)\tTrain_Loss : 0.3866\n",
      "Train_Epoch : 42, [25600/60000](43%)\tTrain_Loss : 0.2953\n",
      "Train_Epoch : 42, [32000/60000](53%)\tTrain_Loss : 0.1368\n",
      "Train_Epoch : 42, [38400/60000](64%)\tTrain_Loss : 0.2589\n",
      "Train_Epoch : 42, [44800/60000](75%)\tTrain_Loss : 0.2350\n",
      "Train_Epoch : 42, [51200/60000](85%)\tTrain_Loss : 0.5567\n",
      "Train_Epoch : 42, [57600/60000](96%)\tTrain_Loss : 0.4226\n",
      "\n",
      "Epoch : 42\tTest_loss : 0.3715\tTest_accuracy : 89.08%\n",
      "\n",
      "Train_Epoch : 43, [0/60000](0%)\tTrain_Loss : 0.6178\n",
      "Train_Epoch : 43, [6400/60000](11%)\tTrain_Loss : 0.3773\n",
      "Train_Epoch : 43, [12800/60000](21%)\tTrain_Loss : 0.4179\n",
      "Train_Epoch : 43, [19200/60000](32%)\tTrain_Loss : 0.2697\n",
      "Train_Epoch : 43, [25600/60000](43%)\tTrain_Loss : 0.6363\n",
      "Train_Epoch : 43, [32000/60000](53%)\tTrain_Loss : 0.2786\n",
      "Train_Epoch : 43, [38400/60000](64%)\tTrain_Loss : 0.3684\n",
      "Train_Epoch : 43, [44800/60000](75%)\tTrain_Loss : 0.5506\n",
      "Train_Epoch : 43, [51200/60000](85%)\tTrain_Loss : 0.1470\n",
      "Train_Epoch : 43, [57600/60000](96%)\tTrain_Loss : 0.2748\n",
      "\n",
      "Epoch : 43\tTest_loss : 0.3461\tTest_accuracy : 89.61%\n",
      "\n",
      "Train_Epoch : 44, [0/60000](0%)\tTrain_Loss : 0.2600\n",
      "Train_Epoch : 44, [6400/60000](11%)\tTrain_Loss : 0.3375\n",
      "Train_Epoch : 44, [12800/60000](21%)\tTrain_Loss : 0.3989\n",
      "Train_Epoch : 44, [19200/60000](32%)\tTrain_Loss : 0.6074\n",
      "Train_Epoch : 44, [25600/60000](43%)\tTrain_Loss : 0.3827\n",
      "Train_Epoch : 44, [32000/60000](53%)\tTrain_Loss : 0.4173\n",
      "Train_Epoch : 44, [38400/60000](64%)\tTrain_Loss : 0.3272\n",
      "Train_Epoch : 44, [44800/60000](75%)\tTrain_Loss : 0.4493\n",
      "Train_Epoch : 44, [51200/60000](85%)\tTrain_Loss : 0.3075\n",
      "Train_Epoch : 44, [57600/60000](96%)\tTrain_Loss : 0.2832\n",
      "\n",
      "Epoch : 44\tTest_loss : 0.3568\tTest_accuracy : 89.40%\n",
      "\n",
      "Train_Epoch : 45, [0/60000](0%)\tTrain_Loss : 0.2808\n",
      "Train_Epoch : 45, [6400/60000](11%)\tTrain_Loss : 0.3737\n",
      "Train_Epoch : 45, [12800/60000](21%)\tTrain_Loss : 0.3240\n",
      "Train_Epoch : 45, [19200/60000](32%)\tTrain_Loss : 0.3970\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Admin\\TIL\\pytorch DL\\daily_pytorch_grammer_practice\\1019_TIL.ipynb  13\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/TIL/pytorch%20DL/daily_pytorch_grammer_practice/1019_TIL.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m best_accuracy \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/TIL/pytorch%20DL/daily_pytorch_grammer_practice/1019_TIL.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m Epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, EPOCHS \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m ):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Admin/TIL/pytorch%20DL/daily_pytorch_grammer_practice/1019_TIL.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     train(model, train_loader, optimizer)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/TIL/pytorch%20DL/daily_pytorch_grammer_practice/1019_TIL.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     test_loss, test_accuracy \u001b[39m=\u001b[39m evaluate(model, test_loader)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/TIL/pytorch%20DL/daily_pytorch_grammer_practice/1019_TIL.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mEpoch : \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mTest_loss : \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mTest_accuracy : \u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/TIL/pytorch%20DL/daily_pytorch_grammer_practice/1019_TIL.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         Epoch, test_loss, test_accuracy\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Admin/TIL/pytorch%20DL/daily_pytorch_grammer_practice/1019_TIL.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     ))\n",
      "\u001b[1;32mc:\\Users\\Admin\\TIL\\pytorch DL\\daily_pytorch_grammer_practice\\1019_TIL.ipynb  13\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, log_intervals)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/TIL/pytorch%20DL/daily_pytorch_grammer_practice/1019_TIL.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(model, train_loader, optimizer, log_intervals \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/TIL/pytorch%20DL/daily_pytorch_grammer_practice/1019_TIL.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Admin/TIL/pytorch%20DL/daily_pytorch_grammer_practice/1019_TIL.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mfor\u001b[39;00m batch_idx, (image, label) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/TIL/pytorch%20DL/daily_pytorch_grammer_practice/1019_TIL.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mto(DEVICE)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Admin/TIL/pytorch%20DL/daily_pytorch_grammer_practice/1019_TIL.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mto(DEVICE)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    651\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 652\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    655\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    656\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    691\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 692\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    693\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    694\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img\u001b[39m.\u001b[39mnumpy(), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    147\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:134\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m    127\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\functional.py:172\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    170\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mpermute((\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mcontiguous()\n\u001b[0;32m    171\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mByteTensor):\n\u001b[1;32m--> 172\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mto(dtype\u001b[39m=\u001b[39;49mdefault_float_dtype)\u001b[39m.\u001b[39mdiv(\u001b[39m255\u001b[39m)\n\u001b[0;32m    173\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "es = 0\n",
    "best_accuracy = 0\n",
    "\n",
    "for Epoch in range(1, EPOCHS + 1 ):\n",
    "    train(model, train_loader, optimizer)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    \n",
    "    print('\\nEpoch : {}\\tTest_loss : {:.4f}\\tTest_accuracy : {:.2f}%\\n'.format(\n",
    "        Epoch, test_loss, test_accuracy\n",
    "    ))\n",
    "\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        best_model = model\n",
    "        es = 0\n",
    "    else : \n",
    "        es += 1\n",
    "\n",
    "    if es == 30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  :  90.09\n"
     ]
    }
   ],
   "source": [
    "print('  : ', best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "334544a737ead5017040ac753f52220319955d2381f512ab105ce194db781c37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
