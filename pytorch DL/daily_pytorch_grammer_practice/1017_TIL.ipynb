{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1650 \t 1.12.0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else :\n",
    "    DEVICE = torch.device('cpu')\n",
    "print(torch.cuda.get_device_name(), '\\t', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATHC_SIZE = 128\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "train_dataset = datasets.MNIST(root='../../data/MNIST/',\n",
    "                            download=True,\n",
    "                            train=True,\n",
    "                            transform=transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root='../../data/MNIST/',\n",
    "                            download=True,\n",
    "                            train=False,\n",
    "                            transform=transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                            shuffle=True,\n",
    "                                            batch_size = BATHC_SIZE)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                            shuffle=False,\n",
    "                                            batch_size = BATHC_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
      "torch.FloatTensor torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "for (X_train, y_train) in train_loader:\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    print(X_train.type(), y_train.type())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pltsize = 1\n",
    "plt.figure(figsize=(pltsize*10, pltsize))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i, :, :, :].numpy().reshape(28, 28), cmap='gray_r')\n",
    "    plt.title('Class :' + str(y_train[i].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import dropout\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 512)\n",
    "        self.fc2 = nn.LSTM(input_size=512, hidden_size=128, dropout=0.3)\n",
    "        self.fc3 = nn.GRU(input_size=128, hidden_size=32, dropout=0.3)\n",
    "        self.fc4 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 28 * 28)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x, _ = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x, _ = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = F.log_softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): LSTM(512, 128, dropout=0.3)\n",
      "  (fc3): GRU(128, 32, dropout=0.3)\n",
      "  (fc4): Linear(in_features=32, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, log_intervals=100):\n",
    "    model.train()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        output = model(image)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_intervals == 0:\n",
    "            print('Train_Epoch : {}, [{} / {}]({:.0f}%)\\tTrain_loss : {:.6f}'.format(\n",
    "                Epoch, batch_idx * len(image),\n",
    "                len(train_loader.dataset), 100 * batch_idx / len(train_loader),\n",
    "                loss.item()\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss = criterion(output, label)\n",
    "            prediction = output.max(1, keepdim=True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "        test_loss /= len(test_loader)\n",
    "        test_accuracy = 100 * correct / len(test_loader.dataset)\n",
    "        return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_24088\\1859708491.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Epoch : 1, [0 / 60000](0%)\tTrain_loss : 2.307260\n",
      "Train_Epoch : 1, [12800 / 60000](21%)\tTrain_loss : 2.311649\n",
      "Train_Epoch : 1, [25600 / 60000](43%)\tTrain_loss : 2.305882\n",
      "Train_Epoch : 1, [38400 / 60000](64%)\tTrain_loss : 2.289255\n",
      "Train_Epoch : 1, [51200 / 60000](85%)\tTrain_loss : 2.288316\n",
      "\n",
      "[EPOCH : 1, \tTest_loss : 0.0291, \tTest_Accuracy : 19.14%\n",
      "\n",
      "Train_Epoch : 2, [0 / 60000](0%)\tTrain_loss : 2.286023\n",
      "Train_Epoch : 2, [12800 / 60000](21%)\tTrain_loss : 2.295238\n",
      "Train_Epoch : 2, [25600 / 60000](43%)\tTrain_loss : 2.276044\n",
      "Train_Epoch : 2, [38400 / 60000](64%)\tTrain_loss : 2.271126\n",
      "Train_Epoch : 2, [51200 / 60000](85%)\tTrain_loss : 2.277165\n",
      "\n",
      "[EPOCH : 2, \tTest_loss : 0.0287, \tTest_Accuracy : 27.08%\n",
      "\n",
      "Train_Epoch : 3, [0 / 60000](0%)\tTrain_loss : 2.265516\n",
      "Train_Epoch : 3, [12800 / 60000](21%)\tTrain_loss : 2.249424\n",
      "Train_Epoch : 3, [25600 / 60000](43%)\tTrain_loss : 2.241066\n",
      "Train_Epoch : 3, [38400 / 60000](64%)\tTrain_loss : 2.203709\n",
      "Train_Epoch : 3, [51200 / 60000](85%)\tTrain_loss : 2.189623\n",
      "\n",
      "[EPOCH : 3, \tTest_loss : 0.0276, \tTest_Accuracy : 30.90%\n",
      "\n",
      "Train_Epoch : 4, [0 / 60000](0%)\tTrain_loss : 2.167464\n",
      "Train_Epoch : 4, [12800 / 60000](21%)\tTrain_loss : 2.081496\n",
      "Train_Epoch : 4, [25600 / 60000](43%)\tTrain_loss : 2.073500\n",
      "Train_Epoch : 4, [38400 / 60000](64%)\tTrain_loss : 1.969957\n",
      "Train_Epoch : 4, [51200 / 60000](85%)\tTrain_loss : 1.900160\n",
      "\n",
      "[EPOCH : 4, \tTest_loss : 0.0222, \tTest_Accuracy : 52.49%\n",
      "\n",
      "Train_Epoch : 5, [0 / 60000](0%)\tTrain_loss : 1.797040\n",
      "Train_Epoch : 5, [12800 / 60000](21%)\tTrain_loss : 1.676813\n",
      "Train_Epoch : 5, [25600 / 60000](43%)\tTrain_loss : 1.561771\n",
      "Train_Epoch : 5, [38400 / 60000](64%)\tTrain_loss : 1.470060\n",
      "Train_Epoch : 5, [51200 / 60000](85%)\tTrain_loss : 1.284487\n",
      "\n",
      "[EPOCH : 5, \tTest_loss : 0.0145, \tTest_Accuracy : 72.62%\n",
      "\n",
      "Train_Epoch : 6, [0 / 60000](0%)\tTrain_loss : 1.268571\n",
      "Train_Epoch : 6, [12800 / 60000](21%)\tTrain_loss : 1.131907\n",
      "Train_Epoch : 6, [25600 / 60000](43%)\tTrain_loss : 1.173659\n",
      "Train_Epoch : 6, [38400 / 60000](64%)\tTrain_loss : 0.962428\n",
      "Train_Epoch : 6, [51200 / 60000](85%)\tTrain_loss : 0.861340\n",
      "\n",
      "[EPOCH : 6, \tTest_loss : 0.0094, \tTest_Accuracy : 84.14%\n",
      "\n",
      "Train_Epoch : 7, [0 / 60000](0%)\tTrain_loss : 0.793318\n",
      "Train_Epoch : 7, [12800 / 60000](21%)\tTrain_loss : 0.759144\n",
      "Train_Epoch : 7, [25600 / 60000](43%)\tTrain_loss : 0.800234\n",
      "Train_Epoch : 7, [38400 / 60000](64%)\tTrain_loss : 0.739802\n",
      "Train_Epoch : 7, [51200 / 60000](85%)\tTrain_loss : 0.701836\n",
      "\n",
      "[EPOCH : 7, \tTest_loss : 0.0067, \tTest_Accuracy : 87.66%\n",
      "\n",
      "Train_Epoch : 8, [0 / 60000](0%)\tTrain_loss : 0.615382\n",
      "Train_Epoch : 8, [12800 / 60000](21%)\tTrain_loss : 0.667433\n",
      "Train_Epoch : 8, [25600 / 60000](43%)\tTrain_loss : 0.601892\n",
      "Train_Epoch : 8, [38400 / 60000](64%)\tTrain_loss : 0.564778\n",
      "Train_Epoch : 8, [51200 / 60000](85%)\tTrain_loss : 0.591203\n",
      "\n",
      "[EPOCH : 8, \tTest_loss : 0.0052, \tTest_Accuracy : 89.44%\n",
      "\n",
      "Train_Epoch : 9, [0 / 60000](0%)\tTrain_loss : 0.480989\n",
      "Train_Epoch : 9, [12800 / 60000](21%)\tTrain_loss : 0.431823\n",
      "Train_Epoch : 9, [25600 / 60000](43%)\tTrain_loss : 0.469886\n",
      "Train_Epoch : 9, [38400 / 60000](64%)\tTrain_loss : 0.438561\n",
      "Train_Epoch : 9, [51200 / 60000](85%)\tTrain_loss : 0.423385\n",
      "\n",
      "[EPOCH : 9, \tTest_loss : 0.0041, \tTest_Accuracy : 90.99%\n",
      "\n",
      "Train_Epoch : 10, [0 / 60000](0%)\tTrain_loss : 0.372360\n",
      "Train_Epoch : 10, [12800 / 60000](21%)\tTrain_loss : 0.307286\n",
      "Train_Epoch : 10, [25600 / 60000](43%)\tTrain_loss : 0.273197\n",
      "Train_Epoch : 10, [38400 / 60000](64%)\tTrain_loss : 0.514721\n",
      "Train_Epoch : 10, [51200 / 60000](85%)\tTrain_loss : 0.296338\n",
      "\n",
      "[EPOCH : 10, \tTest_loss : 0.0038, \tTest_Accuracy : 91.85%\n",
      "\n",
      "Train_Epoch : 11, [0 / 60000](0%)\tTrain_loss : 0.307282\n",
      "Train_Epoch : 11, [12800 / 60000](21%)\tTrain_loss : 0.310309\n",
      "Train_Epoch : 11, [25600 / 60000](43%)\tTrain_loss : 0.350891\n",
      "Train_Epoch : 11, [38400 / 60000](64%)\tTrain_loss : 0.329017\n",
      "Train_Epoch : 11, [51200 / 60000](85%)\tTrain_loss : 0.390641\n",
      "\n",
      "[EPOCH : 11, \tTest_loss : 0.0035, \tTest_Accuracy : 92.58%\n",
      "\n",
      "Train_Epoch : 12, [0 / 60000](0%)\tTrain_loss : 0.357470\n",
      "Train_Epoch : 12, [12800 / 60000](21%)\tTrain_loss : 0.280455\n",
      "Train_Epoch : 12, [25600 / 60000](43%)\tTrain_loss : 0.220027\n",
      "Train_Epoch : 12, [38400 / 60000](64%)\tTrain_loss : 0.446310\n",
      "Train_Epoch : 12, [51200 / 60000](85%)\tTrain_loss : 0.209878\n",
      "\n",
      "[EPOCH : 12, \tTest_loss : 0.0027, \tTest_Accuracy : 93.28%\n",
      "\n",
      "Train_Epoch : 13, [0 / 60000](0%)\tTrain_loss : 0.268633\n",
      "Train_Epoch : 13, [12800 / 60000](21%)\tTrain_loss : 0.371718\n",
      "Train_Epoch : 13, [25600 / 60000](43%)\tTrain_loss : 0.388252\n",
      "Train_Epoch : 13, [38400 / 60000](64%)\tTrain_loss : 0.273838\n",
      "Train_Epoch : 13, [51200 / 60000](85%)\tTrain_loss : 0.268814\n",
      "\n",
      "[EPOCH : 13, \tTest_loss : 0.0022, \tTest_Accuracy : 93.69%\n",
      "\n",
      "Train_Epoch : 14, [0 / 60000](0%)\tTrain_loss : 0.222033\n",
      "Train_Epoch : 14, [12800 / 60000](21%)\tTrain_loss : 0.232851\n",
      "Train_Epoch : 14, [25600 / 60000](43%)\tTrain_loss : 0.228022\n",
      "Train_Epoch : 14, [38400 / 60000](64%)\tTrain_loss : 0.203754\n",
      "Train_Epoch : 14, [51200 / 60000](85%)\tTrain_loss : 0.311992\n",
      "\n",
      "[EPOCH : 14, \tTest_loss : 0.0025, \tTest_Accuracy : 93.98%\n",
      "\n",
      "Train_Epoch : 15, [0 / 60000](0%)\tTrain_loss : 0.273210\n",
      "Train_Epoch : 15, [12800 / 60000](21%)\tTrain_loss : 0.275640\n",
      "Train_Epoch : 15, [25600 / 60000](43%)\tTrain_loss : 0.180000\n",
      "Train_Epoch : 15, [38400 / 60000](64%)\tTrain_loss : 0.206243\n",
      "Train_Epoch : 15, [51200 / 60000](85%)\tTrain_loss : 0.225680\n",
      "\n",
      "[EPOCH : 15, \tTest_loss : 0.0027, \tTest_Accuracy : 94.27%\n",
      "\n",
      "Train_Epoch : 16, [0 / 60000](0%)\tTrain_loss : 0.204486\n",
      "Train_Epoch : 16, [12800 / 60000](21%)\tTrain_loss : 0.197433\n",
      "Train_Epoch : 16, [25600 / 60000](43%)\tTrain_loss : 0.219815\n",
      "Train_Epoch : 16, [38400 / 60000](64%)\tTrain_loss : 0.232403\n",
      "Train_Epoch : 16, [51200 / 60000](85%)\tTrain_loss : 0.218655\n",
      "\n",
      "[EPOCH : 16, \tTest_loss : 0.0015, \tTest_Accuracy : 94.83%\n",
      "\n",
      "Train_Epoch : 17, [0 / 60000](0%)\tTrain_loss : 0.121060\n",
      "Train_Epoch : 17, [12800 / 60000](21%)\tTrain_loss : 0.166209\n",
      "Train_Epoch : 17, [25600 / 60000](43%)\tTrain_loss : 0.255797\n",
      "Train_Epoch : 17, [38400 / 60000](64%)\tTrain_loss : 0.208591\n",
      "Train_Epoch : 17, [51200 / 60000](85%)\tTrain_loss : 0.176467\n",
      "\n",
      "[EPOCH : 17, \tTest_loss : 0.0013, \tTest_Accuracy : 95.12%\n",
      "\n",
      "Train_Epoch : 18, [0 / 60000](0%)\tTrain_loss : 0.238465\n",
      "Train_Epoch : 18, [12800 / 60000](21%)\tTrain_loss : 0.132625\n",
      "Train_Epoch : 18, [25600 / 60000](43%)\tTrain_loss : 0.169508\n",
      "Train_Epoch : 18, [38400 / 60000](64%)\tTrain_loss : 0.160693\n",
      "Train_Epoch : 18, [51200 / 60000](85%)\tTrain_loss : 0.229423\n",
      "\n",
      "[EPOCH : 18, \tTest_loss : 0.0010, \tTest_Accuracy : 95.61%\n",
      "\n",
      "Train_Epoch : 19, [0 / 60000](0%)\tTrain_loss : 0.121932\n",
      "Train_Epoch : 19, [12800 / 60000](21%)\tTrain_loss : 0.224265\n",
      "Train_Epoch : 19, [25600 / 60000](43%)\tTrain_loss : 0.148493\n",
      "Train_Epoch : 19, [38400 / 60000](64%)\tTrain_loss : 0.109932\n",
      "Train_Epoch : 19, [51200 / 60000](85%)\tTrain_loss : 0.146071\n",
      "\n",
      "[EPOCH : 19, \tTest_loss : 0.0009, \tTest_Accuracy : 95.70%\n",
      "\n",
      "Train_Epoch : 20, [0 / 60000](0%)\tTrain_loss : 0.150484\n",
      "Train_Epoch : 20, [12800 / 60000](21%)\tTrain_loss : 0.144343\n",
      "Train_Epoch : 20, [25600 / 60000](43%)\tTrain_loss : 0.127034\n",
      "Train_Epoch : 20, [38400 / 60000](64%)\tTrain_loss : 0.088011\n",
      "Train_Epoch : 20, [51200 / 60000](85%)\tTrain_loss : 0.152978\n",
      "\n",
      "[EPOCH : 20, \tTest_loss : 0.0009, \tTest_Accuracy : 95.69%\n",
      "\n",
      "Train_Epoch : 21, [0 / 60000](0%)\tTrain_loss : 0.166598\n",
      "Train_Epoch : 21, [12800 / 60000](21%)\tTrain_loss : 0.173906\n",
      "Train_Epoch : 21, [25600 / 60000](43%)\tTrain_loss : 0.171953\n",
      "Train_Epoch : 21, [38400 / 60000](64%)\tTrain_loss : 0.113877\n",
      "Train_Epoch : 21, [51200 / 60000](85%)\tTrain_loss : 0.073752\n",
      "\n",
      "[EPOCH : 21, \tTest_loss : 0.0009, \tTest_Accuracy : 95.89%\n",
      "\n",
      "Train_Epoch : 22, [0 / 60000](0%)\tTrain_loss : 0.130704\n",
      "Train_Epoch : 22, [12800 / 60000](21%)\tTrain_loss : 0.153604\n",
      "Train_Epoch : 22, [25600 / 60000](43%)\tTrain_loss : 0.161760\n",
      "Train_Epoch : 22, [38400 / 60000](64%)\tTrain_loss : 0.208950\n",
      "Train_Epoch : 22, [51200 / 60000](85%)\tTrain_loss : 0.180213\n",
      "\n",
      "[EPOCH : 22, \tTest_loss : 0.0007, \tTest_Accuracy : 96.28%\n",
      "\n",
      "Train_Epoch : 23, [0 / 60000](0%)\tTrain_loss : 0.233567\n",
      "Train_Epoch : 23, [12800 / 60000](21%)\tTrain_loss : 0.190605\n",
      "Train_Epoch : 23, [25600 / 60000](43%)\tTrain_loss : 0.080995\n",
      "Train_Epoch : 23, [38400 / 60000](64%)\tTrain_loss : 0.120243\n",
      "Train_Epoch : 23, [51200 / 60000](85%)\tTrain_loss : 0.150800\n",
      "\n",
      "[EPOCH : 23, \tTest_loss : 0.0009, \tTest_Accuracy : 96.23%\n",
      "\n",
      "Train_Epoch : 24, [0 / 60000](0%)\tTrain_loss : 0.107273\n",
      "Train_Epoch : 24, [12800 / 60000](21%)\tTrain_loss : 0.151954\n",
      "Train_Epoch : 24, [25600 / 60000](43%)\tTrain_loss : 0.141805\n",
      "Train_Epoch : 24, [38400 / 60000](64%)\tTrain_loss : 0.140110\n",
      "Train_Epoch : 24, [51200 / 60000](85%)\tTrain_loss : 0.082961\n",
      "\n",
      "[EPOCH : 24, \tTest_loss : 0.0010, \tTest_Accuracy : 96.24%\n",
      "\n",
      "Train_Epoch : 25, [0 / 60000](0%)\tTrain_loss : 0.131851\n",
      "Train_Epoch : 25, [12800 / 60000](21%)\tTrain_loss : 0.180821\n",
      "Train_Epoch : 25, [25600 / 60000](43%)\tTrain_loss : 0.136029\n",
      "Train_Epoch : 25, [38400 / 60000](64%)\tTrain_loss : 0.058786\n",
      "Train_Epoch : 25, [51200 / 60000](85%)\tTrain_loss : 0.209204\n",
      "\n",
      "[EPOCH : 25, \tTest_loss : 0.0005, \tTest_Accuracy : 96.48%\n",
      "\n",
      "Train_Epoch : 26, [0 / 60000](0%)\tTrain_loss : 0.140402\n",
      "Train_Epoch : 26, [12800 / 60000](21%)\tTrain_loss : 0.106271\n",
      "Train_Epoch : 26, [25600 / 60000](43%)\tTrain_loss : 0.150213\n",
      "Train_Epoch : 26, [38400 / 60000](64%)\tTrain_loss : 0.077412\n",
      "Train_Epoch : 26, [51200 / 60000](85%)\tTrain_loss : 0.086858\n",
      "\n",
      "[EPOCH : 26, \tTest_loss : 0.0005, \tTest_Accuracy : 96.56%\n",
      "\n",
      "Train_Epoch : 27, [0 / 60000](0%)\tTrain_loss : 0.064166\n",
      "Train_Epoch : 27, [12800 / 60000](21%)\tTrain_loss : 0.067322\n",
      "Train_Epoch : 27, [25600 / 60000](43%)\tTrain_loss : 0.067173\n",
      "Train_Epoch : 27, [38400 / 60000](64%)\tTrain_loss : 0.132714\n",
      "Train_Epoch : 27, [51200 / 60000](85%)\tTrain_loss : 0.074222\n",
      "\n",
      "[EPOCH : 27, \tTest_loss : 0.0005, \tTest_Accuracy : 96.72%\n",
      "\n",
      "Train_Epoch : 28, [0 / 60000](0%)\tTrain_loss : 0.070849\n",
      "Train_Epoch : 28, [12800 / 60000](21%)\tTrain_loss : 0.140307\n",
      "Train_Epoch : 28, [25600 / 60000](43%)\tTrain_loss : 0.077650\n",
      "Train_Epoch : 28, [38400 / 60000](64%)\tTrain_loss : 0.081649\n",
      "Train_Epoch : 28, [51200 / 60000](85%)\tTrain_loss : 0.158645\n",
      "\n",
      "[EPOCH : 28, \tTest_loss : 0.0004, \tTest_Accuracy : 96.77%\n",
      "\n",
      "Train_Epoch : 29, [0 / 60000](0%)\tTrain_loss : 0.100201\n",
      "Train_Epoch : 29, [12800 / 60000](21%)\tTrain_loss : 0.084109\n",
      "Train_Epoch : 29, [25600 / 60000](43%)\tTrain_loss : 0.090385\n",
      "Train_Epoch : 29, [38400 / 60000](64%)\tTrain_loss : 0.094454\n",
      "Train_Epoch : 29, [51200 / 60000](85%)\tTrain_loss : 0.046784\n",
      "\n",
      "[EPOCH : 29, \tTest_loss : 0.0003, \tTest_Accuracy : 96.89%\n",
      "\n",
      "Train_Epoch : 30, [0 / 60000](0%)\tTrain_loss : 0.075619\n",
      "Train_Epoch : 30, [12800 / 60000](21%)\tTrain_loss : 0.060258\n",
      "Train_Epoch : 30, [25600 / 60000](43%)\tTrain_loss : 0.079857\n",
      "Train_Epoch : 30, [38400 / 60000](64%)\tTrain_loss : 0.090976\n",
      "Train_Epoch : 30, [51200 / 60000](85%)\tTrain_loss : 0.060255\n",
      "\n",
      "[EPOCH : 30, \tTest_loss : 0.0003, \tTest_Accuracy : 97.00%\n",
      "\n",
      "Train_Epoch : 31, [0 / 60000](0%)\tTrain_loss : 0.092935\n",
      "Train_Epoch : 31, [12800 / 60000](21%)\tTrain_loss : 0.133231\n",
      "Train_Epoch : 31, [25600 / 60000](43%)\tTrain_loss : 0.072161\n",
      "Train_Epoch : 31, [38400 / 60000](64%)\tTrain_loss : 0.092831\n",
      "Train_Epoch : 31, [51200 / 60000](85%)\tTrain_loss : 0.089636\n",
      "\n",
      "[EPOCH : 31, \tTest_loss : 0.0003, \tTest_Accuracy : 97.10%\n",
      "\n",
      "Train_Epoch : 32, [0 / 60000](0%)\tTrain_loss : 0.130736\n",
      "Train_Epoch : 32, [12800 / 60000](21%)\tTrain_loss : 0.073095\n",
      "Train_Epoch : 32, [25600 / 60000](43%)\tTrain_loss : 0.087820\n",
      "Train_Epoch : 32, [38400 / 60000](64%)\tTrain_loss : 0.070535\n",
      "Train_Epoch : 32, [51200 / 60000](85%)\tTrain_loss : 0.067053\n",
      "\n",
      "[EPOCH : 32, \tTest_loss : 0.0002, \tTest_Accuracy : 97.09%\n",
      "\n",
      "Train_Epoch : 33, [0 / 60000](0%)\tTrain_loss : 0.087138\n",
      "Train_Epoch : 33, [12800 / 60000](21%)\tTrain_loss : 0.052552\n",
      "Train_Epoch : 33, [25600 / 60000](43%)\tTrain_loss : 0.093931\n",
      "Train_Epoch : 33, [38400 / 60000](64%)\tTrain_loss : 0.118846\n",
      "Train_Epoch : 33, [51200 / 60000](85%)\tTrain_loss : 0.083028\n",
      "\n",
      "[EPOCH : 33, \tTest_loss : 0.0002, \tTest_Accuracy : 96.78%\n",
      "\n",
      "Train_Epoch : 34, [0 / 60000](0%)\tTrain_loss : 0.077933\n",
      "Train_Epoch : 34, [12800 / 60000](21%)\tTrain_loss : 0.077191\n",
      "Train_Epoch : 34, [25600 / 60000](43%)\tTrain_loss : 0.100215\n",
      "Train_Epoch : 34, [38400 / 60000](64%)\tTrain_loss : 0.052333\n",
      "Train_Epoch : 34, [51200 / 60000](85%)\tTrain_loss : 0.095943\n",
      "\n",
      "[EPOCH : 34, \tTest_loss : 0.0002, \tTest_Accuracy : 97.32%\n",
      "\n",
      "Train_Epoch : 35, [0 / 60000](0%)\tTrain_loss : 0.091826\n",
      "Train_Epoch : 35, [12800 / 60000](21%)\tTrain_loss : 0.061733\n",
      "Train_Epoch : 35, [25600 / 60000](43%)\tTrain_loss : 0.072079\n",
      "Train_Epoch : 35, [38400 / 60000](64%)\tTrain_loss : 0.085583\n",
      "Train_Epoch : 35, [51200 / 60000](85%)\tTrain_loss : 0.103567\n",
      "\n",
      "[EPOCH : 35, \tTest_loss : 0.0002, \tTest_Accuracy : 97.34%\n",
      "\n",
      "Train_Epoch : 36, [0 / 60000](0%)\tTrain_loss : 0.063801\n",
      "Train_Epoch : 36, [12800 / 60000](21%)\tTrain_loss : 0.060790\n",
      "Train_Epoch : 36, [25600 / 60000](43%)\tTrain_loss : 0.065770\n",
      "Train_Epoch : 36, [38400 / 60000](64%)\tTrain_loss : 0.046746\n",
      "Train_Epoch : 36, [51200 / 60000](85%)\tTrain_loss : 0.099262\n",
      "\n",
      "[EPOCH : 36, \tTest_loss : 0.0002, \tTest_Accuracy : 96.97%\n",
      "\n",
      "Train_Epoch : 37, [0 / 60000](0%)\tTrain_loss : 0.057597\n",
      "Train_Epoch : 37, [12800 / 60000](21%)\tTrain_loss : 0.094428\n",
      "Train_Epoch : 37, [25600 / 60000](43%)\tTrain_loss : 0.144401\n",
      "Train_Epoch : 37, [38400 / 60000](64%)\tTrain_loss : 0.035943\n",
      "Train_Epoch : 37, [51200 / 60000](85%)\tTrain_loss : 0.058865\n",
      "\n",
      "[EPOCH : 37, \tTest_loss : 0.0005, \tTest_Accuracy : 97.02%\n",
      "\n",
      "Train_Epoch : 38, [0 / 60000](0%)\tTrain_loss : 0.087620\n",
      "Train_Epoch : 38, [12800 / 60000](21%)\tTrain_loss : 0.049681\n",
      "Train_Epoch : 38, [25600 / 60000](43%)\tTrain_loss : 0.061308\n",
      "Train_Epoch : 38, [38400 / 60000](64%)\tTrain_loss : 0.063428\n",
      "Train_Epoch : 38, [51200 / 60000](85%)\tTrain_loss : 0.044719\n",
      "\n",
      "[EPOCH : 38, \tTest_loss : 0.0002, \tTest_Accuracy : 97.28%\n",
      "\n",
      "Train_Epoch : 39, [0 / 60000](0%)\tTrain_loss : 0.046824\n",
      "Train_Epoch : 39, [12800 / 60000](21%)\tTrain_loss : 0.037035\n",
      "Train_Epoch : 39, [25600 / 60000](43%)\tTrain_loss : 0.057166\n",
      "Train_Epoch : 39, [38400 / 60000](64%)\tTrain_loss : 0.034928\n",
      "Train_Epoch : 39, [51200 / 60000](85%)\tTrain_loss : 0.094069\n",
      "\n",
      "[EPOCH : 39, \tTest_loss : 0.0002, \tTest_Accuracy : 97.52%\n",
      "\n",
      "Train_Epoch : 40, [0 / 60000](0%)\tTrain_loss : 0.034938\n",
      "Train_Epoch : 40, [12800 / 60000](21%)\tTrain_loss : 0.059330\n",
      "Train_Epoch : 40, [25600 / 60000](43%)\tTrain_loss : 0.050959\n",
      "Train_Epoch : 40, [38400 / 60000](64%)\tTrain_loss : 0.061956\n",
      "Train_Epoch : 40, [51200 / 60000](85%)\tTrain_loss : 0.065262\n",
      "\n",
      "[EPOCH : 40, \tTest_loss : 0.0002, \tTest_Accuracy : 97.35%\n",
      "\n",
      "Train_Epoch : 41, [0 / 60000](0%)\tTrain_loss : 0.021371\n",
      "Train_Epoch : 41, [12800 / 60000](21%)\tTrain_loss : 0.044037\n",
      "Train_Epoch : 41, [25600 / 60000](43%)\tTrain_loss : 0.038716\n",
      "Train_Epoch : 41, [38400 / 60000](64%)\tTrain_loss : 0.036077\n",
      "Train_Epoch : 41, [51200 / 60000](85%)\tTrain_loss : 0.020256\n",
      "\n",
      "[EPOCH : 41, \tTest_loss : 0.0001, \tTest_Accuracy : 97.44%\n",
      "\n",
      "Train_Epoch : 42, [0 / 60000](0%)\tTrain_loss : 0.066055\n",
      "Train_Epoch : 42, [12800 / 60000](21%)\tTrain_loss : 0.092298\n",
      "Train_Epoch : 42, [25600 / 60000](43%)\tTrain_loss : 0.064632\n",
      "Train_Epoch : 42, [38400 / 60000](64%)\tTrain_loss : 0.056452\n",
      "Train_Epoch : 42, [51200 / 60000](85%)\tTrain_loss : 0.043531\n",
      "\n",
      "[EPOCH : 42, \tTest_loss : 0.0002, \tTest_Accuracy : 97.26%\n",
      "\n",
      "Train_Epoch : 43, [0 / 60000](0%)\tTrain_loss : 0.038966\n",
      "Train_Epoch : 43, [12800 / 60000](21%)\tTrain_loss : 0.033686\n",
      "Train_Epoch : 43, [25600 / 60000](43%)\tTrain_loss : 0.030578\n",
      "Train_Epoch : 43, [38400 / 60000](64%)\tTrain_loss : 0.022751\n",
      "Train_Epoch : 43, [51200 / 60000](85%)\tTrain_loss : 0.036676\n",
      "\n",
      "[EPOCH : 43, \tTest_loss : 0.0001, \tTest_Accuracy : 97.59%\n",
      "\n",
      "Train_Epoch : 44, [0 / 60000](0%)\tTrain_loss : 0.055348\n",
      "Train_Epoch : 44, [12800 / 60000](21%)\tTrain_loss : 0.144793\n",
      "Train_Epoch : 44, [25600 / 60000](43%)\tTrain_loss : 0.041238\n",
      "Train_Epoch : 44, [38400 / 60000](64%)\tTrain_loss : 0.043712\n",
      "Train_Epoch : 44, [51200 / 60000](85%)\tTrain_loss : 0.047426\n",
      "\n",
      "[EPOCH : 44, \tTest_loss : 0.0001, \tTest_Accuracy : 97.58%\n",
      "\n",
      "Train_Epoch : 45, [0 / 60000](0%)\tTrain_loss : 0.031515\n",
      "Train_Epoch : 45, [12800 / 60000](21%)\tTrain_loss : 0.057212\n",
      "Train_Epoch : 45, [25600 / 60000](43%)\tTrain_loss : 0.090899\n",
      "Train_Epoch : 45, [38400 / 60000](64%)\tTrain_loss : 0.037357\n",
      "Train_Epoch : 45, [51200 / 60000](85%)\tTrain_loss : 0.020478\n",
      "\n",
      "[EPOCH : 45, \tTest_loss : 0.0001, \tTest_Accuracy : 97.57%\n",
      "\n",
      "Train_Epoch : 46, [0 / 60000](0%)\tTrain_loss : 0.022442\n",
      "Train_Epoch : 46, [12800 / 60000](21%)\tTrain_loss : 0.032780\n",
      "Train_Epoch : 46, [25600 / 60000](43%)\tTrain_loss : 0.021227\n",
      "Train_Epoch : 46, [38400 / 60000](64%)\tTrain_loss : 0.068291\n",
      "Train_Epoch : 46, [51200 / 60000](85%)\tTrain_loss : 0.036591\n",
      "\n",
      "[EPOCH : 46, \tTest_loss : 0.0001, \tTest_Accuracy : 97.52%\n",
      "\n",
      "Train_Epoch : 47, [0 / 60000](0%)\tTrain_loss : 0.045227\n",
      "Train_Epoch : 47, [12800 / 60000](21%)\tTrain_loss : 0.019500\n",
      "Train_Epoch : 47, [25600 / 60000](43%)\tTrain_loss : 0.032895\n",
      "Train_Epoch : 47, [38400 / 60000](64%)\tTrain_loss : 0.046023\n",
      "Train_Epoch : 47, [51200 / 60000](85%)\tTrain_loss : 0.030342\n",
      "\n",
      "[EPOCH : 47, \tTest_loss : 0.0001, \tTest_Accuracy : 97.60%\n",
      "\n",
      "Train_Epoch : 48, [0 / 60000](0%)\tTrain_loss : 0.028539\n",
      "Train_Epoch : 48, [12800 / 60000](21%)\tTrain_loss : 0.045211\n",
      "Train_Epoch : 48, [25600 / 60000](43%)\tTrain_loss : 0.037281\n",
      "Train_Epoch : 48, [38400 / 60000](64%)\tTrain_loss : 0.047448\n",
      "Train_Epoch : 48, [51200 / 60000](85%)\tTrain_loss : 0.029748\n",
      "\n",
      "[EPOCH : 48, \tTest_loss : 0.0001, \tTest_Accuracy : 97.65%\n",
      "\n",
      "Train_Epoch : 49, [0 / 60000](0%)\tTrain_loss : 0.030052\n",
      "Train_Epoch : 49, [12800 / 60000](21%)\tTrain_loss : 0.017036\n",
      "Train_Epoch : 49, [25600 / 60000](43%)\tTrain_loss : 0.062457\n",
      "Train_Epoch : 49, [38400 / 60000](64%)\tTrain_loss : 0.043670\n",
      "Train_Epoch : 49, [51200 / 60000](85%)\tTrain_loss : 0.041564\n",
      "\n",
      "[EPOCH : 49, \tTest_loss : 0.0001, \tTest_Accuracy : 97.69%\n",
      "\n",
      "Train_Epoch : 50, [0 / 60000](0%)\tTrain_loss : 0.058761\n",
      "Train_Epoch : 50, [12800 / 60000](21%)\tTrain_loss : 0.031454\n",
      "Train_Epoch : 50, [25600 / 60000](43%)\tTrain_loss : 0.012269\n",
      "Train_Epoch : 50, [38400 / 60000](64%)\tTrain_loss : 0.033626\n",
      "Train_Epoch : 50, [51200 / 60000](85%)\tTrain_loss : 0.032667\n",
      "\n",
      "[EPOCH : 50, \tTest_loss : 0.0001, \tTest_Accuracy : 97.69%\n",
      "\n",
      "Train_Epoch : 51, [0 / 60000](0%)\tTrain_loss : 0.026408\n",
      "Train_Epoch : 51, [12800 / 60000](21%)\tTrain_loss : 0.030239\n",
      "Train_Epoch : 51, [25600 / 60000](43%)\tTrain_loss : 0.027720\n",
      "Train_Epoch : 51, [38400 / 60000](64%)\tTrain_loss : 0.032614\n",
      "Train_Epoch : 51, [51200 / 60000](85%)\tTrain_loss : 0.074960\n",
      "\n",
      "[EPOCH : 51, \tTest_loss : 0.0001, \tTest_Accuracy : 97.51%\n",
      "\n",
      "Train_Epoch : 52, [0 / 60000](0%)\tTrain_loss : 0.028449\n",
      "Train_Epoch : 52, [12800 / 60000](21%)\tTrain_loss : 0.026562\n",
      "Train_Epoch : 52, [25600 / 60000](43%)\tTrain_loss : 0.036248\n",
      "Train_Epoch : 52, [38400 / 60000](64%)\tTrain_loss : 0.018639\n",
      "Train_Epoch : 52, [51200 / 60000](85%)\tTrain_loss : 0.022683\n",
      "\n",
      "[EPOCH : 52, \tTest_loss : 0.0001, \tTest_Accuracy : 97.49%\n",
      "\n",
      "Train_Epoch : 53, [0 / 60000](0%)\tTrain_loss : 0.023821\n",
      "Train_Epoch : 53, [12800 / 60000](21%)\tTrain_loss : 0.029195\n",
      "Train_Epoch : 53, [25600 / 60000](43%)\tTrain_loss : 0.060264\n",
      "Train_Epoch : 53, [38400 / 60000](64%)\tTrain_loss : 0.017187\n",
      "Train_Epoch : 53, [51200 / 60000](85%)\tTrain_loss : 0.037371\n",
      "\n",
      "[EPOCH : 53, \tTest_loss : 0.0001, \tTest_Accuracy : 97.71%\n",
      "\n",
      "Train_Epoch : 54, [0 / 60000](0%)\tTrain_loss : 0.039714\n",
      "Train_Epoch : 54, [12800 / 60000](21%)\tTrain_loss : 0.018140\n",
      "Train_Epoch : 54, [25600 / 60000](43%)\tTrain_loss : 0.032705\n",
      "Train_Epoch : 54, [38400 / 60000](64%)\tTrain_loss : 0.042890\n",
      "Train_Epoch : 54, [51200 / 60000](85%)\tTrain_loss : 0.021208\n",
      "\n",
      "[EPOCH : 54, \tTest_loss : 0.0001, \tTest_Accuracy : 97.61%\n",
      "\n",
      "Train_Epoch : 55, [0 / 60000](0%)\tTrain_loss : 0.016821\n",
      "Train_Epoch : 55, [12800 / 60000](21%)\tTrain_loss : 0.022275\n",
      "Train_Epoch : 55, [25600 / 60000](43%)\tTrain_loss : 0.019552\n",
      "Train_Epoch : 55, [38400 / 60000](64%)\tTrain_loss : 0.037623\n",
      "Train_Epoch : 55, [51200 / 60000](85%)\tTrain_loss : 0.024433\n",
      "\n",
      "[EPOCH : 55, \tTest_loss : 0.0001, \tTest_Accuracy : 97.74%\n",
      "\n",
      "Train_Epoch : 56, [0 / 60000](0%)\tTrain_loss : 0.026105\n",
      "Train_Epoch : 56, [12800 / 60000](21%)\tTrain_loss : 0.082783\n",
      "Train_Epoch : 56, [25600 / 60000](43%)\tTrain_loss : 0.034274\n",
      "Train_Epoch : 56, [38400 / 60000](64%)\tTrain_loss : 0.015611\n",
      "Train_Epoch : 56, [51200 / 60000](85%)\tTrain_loss : 0.034095\n",
      "\n",
      "[EPOCH : 56, \tTest_loss : 0.0001, \tTest_Accuracy : 97.85%\n",
      "\n",
      "Train_Epoch : 57, [0 / 60000](0%)\tTrain_loss : 0.013047\n",
      "Train_Epoch : 57, [12800 / 60000](21%)\tTrain_loss : 0.048118\n",
      "Train_Epoch : 57, [25600 / 60000](43%)\tTrain_loss : 0.027090\n",
      "Train_Epoch : 57, [38400 / 60000](64%)\tTrain_loss : 0.016456\n",
      "Train_Epoch : 57, [51200 / 60000](85%)\tTrain_loss : 0.062496\n",
      "\n",
      "[EPOCH : 57, \tTest_loss : 0.0001, \tTest_Accuracy : 97.73%\n",
      "\n",
      "Train_Epoch : 58, [0 / 60000](0%)\tTrain_loss : 0.046692\n",
      "Train_Epoch : 58, [12800 / 60000](21%)\tTrain_loss : 0.016447\n",
      "Train_Epoch : 58, [25600 / 60000](43%)\tTrain_loss : 0.021157\n",
      "Train_Epoch : 58, [38400 / 60000](64%)\tTrain_loss : 0.043154\n",
      "Train_Epoch : 58, [51200 / 60000](85%)\tTrain_loss : 0.046426\n",
      "\n",
      "[EPOCH : 58, \tTest_loss : 0.0001, \tTest_Accuracy : 97.63%\n",
      "\n",
      "Train_Epoch : 59, [0 / 60000](0%)\tTrain_loss : 0.021440\n",
      "Train_Epoch : 59, [12800 / 60000](21%)\tTrain_loss : 0.019029\n",
      "Train_Epoch : 59, [25600 / 60000](43%)\tTrain_loss : 0.013366\n",
      "Train_Epoch : 59, [38400 / 60000](64%)\tTrain_loss : 0.013970\n",
      "Train_Epoch : 59, [51200 / 60000](85%)\tTrain_loss : 0.023510\n",
      "\n",
      "[EPOCH : 59, \tTest_loss : 0.0001, \tTest_Accuracy : 97.80%\n",
      "\n",
      "Train_Epoch : 60, [0 / 60000](0%)\tTrain_loss : 0.036654\n",
      "Train_Epoch : 60, [12800 / 60000](21%)\tTrain_loss : 0.008704\n",
      "Train_Epoch : 60, [25600 / 60000](43%)\tTrain_loss : 0.041321\n",
      "Train_Epoch : 60, [38400 / 60000](64%)\tTrain_loss : 0.017473\n",
      "Train_Epoch : 60, [51200 / 60000](85%)\tTrain_loss : 0.026579\n",
      "\n",
      "[EPOCH : 60, \tTest_loss : 0.0001, \tTest_Accuracy : 97.73%\n",
      "\n",
      "Train_Epoch : 61, [0 / 60000](0%)\tTrain_loss : 0.015890\n",
      "Train_Epoch : 61, [12800 / 60000](21%)\tTrain_loss : 0.012035\n",
      "Train_Epoch : 61, [25600 / 60000](43%)\tTrain_loss : 0.046569\n",
      "Train_Epoch : 61, [38400 / 60000](64%)\tTrain_loss : 0.031850\n",
      "Train_Epoch : 61, [51200 / 60000](85%)\tTrain_loss : 0.029764\n",
      "\n",
      "[EPOCH : 61, \tTest_loss : 0.0001, \tTest_Accuracy : 97.66%\n",
      "\n",
      "Train_Epoch : 62, [0 / 60000](0%)\tTrain_loss : 0.021776\n",
      "Train_Epoch : 62, [12800 / 60000](21%)\tTrain_loss : 0.015838\n",
      "Train_Epoch : 62, [25600 / 60000](43%)\tTrain_loss : 0.016642\n",
      "Train_Epoch : 62, [38400 / 60000](64%)\tTrain_loss : 0.023694\n",
      "Train_Epoch : 62, [51200 / 60000](85%)\tTrain_loss : 0.046193\n",
      "\n",
      "[EPOCH : 62, \tTest_loss : 0.0001, \tTest_Accuracy : 97.69%\n",
      "\n",
      "Train_Epoch : 63, [0 / 60000](0%)\tTrain_loss : 0.019359\n",
      "Train_Epoch : 63, [12800 / 60000](21%)\tTrain_loss : 0.028635\n",
      "Train_Epoch : 63, [25600 / 60000](43%)\tTrain_loss : 0.027200\n",
      "Train_Epoch : 63, [38400 / 60000](64%)\tTrain_loss : 0.016899\n",
      "Train_Epoch : 63, [51200 / 60000](85%)\tTrain_loss : 0.014317\n",
      "\n",
      "[EPOCH : 63, \tTest_loss : 0.0001, \tTest_Accuracy : 97.82%\n",
      "\n",
      "Train_Epoch : 64, [0 / 60000](0%)\tTrain_loss : 0.009305\n",
      "Train_Epoch : 64, [12800 / 60000](21%)\tTrain_loss : 0.016999\n",
      "Train_Epoch : 64, [25600 / 60000](43%)\tTrain_loss : 0.010193\n",
      "Train_Epoch : 64, [38400 / 60000](64%)\tTrain_loss : 0.014438\n",
      "Train_Epoch : 64, [51200 / 60000](85%)\tTrain_loss : 0.025485\n",
      "\n",
      "[EPOCH : 64, \tTest_loss : 0.0001, \tTest_Accuracy : 97.68%\n",
      "\n",
      "Train_Epoch : 65, [0 / 60000](0%)\tTrain_loss : 0.038881\n",
      "Train_Epoch : 65, [12800 / 60000](21%)\tTrain_loss : 0.007922\n",
      "Train_Epoch : 65, [25600 / 60000](43%)\tTrain_loss : 0.023761\n",
      "Train_Epoch : 65, [38400 / 60000](64%)\tTrain_loss : 0.035458\n",
      "Train_Epoch : 65, [51200 / 60000](85%)\tTrain_loss : 0.035905\n",
      "\n",
      "[EPOCH : 65, \tTest_loss : 0.0001, \tTest_Accuracy : 97.73%\n",
      "\n",
      "Train_Epoch : 66, [0 / 60000](0%)\tTrain_loss : 0.024683\n",
      "Train_Epoch : 66, [12800 / 60000](21%)\tTrain_loss : 0.014042\n",
      "Train_Epoch : 66, [25600 / 60000](43%)\tTrain_loss : 0.021296\n",
      "Train_Epoch : 66, [38400 / 60000](64%)\tTrain_loss : 0.050031\n",
      "Train_Epoch : 66, [51200 / 60000](85%)\tTrain_loss : 0.007814\n",
      "\n",
      "[EPOCH : 66, \tTest_loss : 0.0001, \tTest_Accuracy : 97.84%\n",
      "\n",
      "Train_Epoch : 67, [0 / 60000](0%)\tTrain_loss : 0.010154\n",
      "Train_Epoch : 67, [12800 / 60000](21%)\tTrain_loss : 0.013178\n",
      "Train_Epoch : 67, [25600 / 60000](43%)\tTrain_loss : 0.031370\n",
      "Train_Epoch : 67, [38400 / 60000](64%)\tTrain_loss : 0.015808\n",
      "Train_Epoch : 67, [51200 / 60000](85%)\tTrain_loss : 0.025782\n",
      "\n",
      "[EPOCH : 67, \tTest_loss : 0.0000, \tTest_Accuracy : 97.85%\n",
      "\n",
      "Train_Epoch : 68, [0 / 60000](0%)\tTrain_loss : 0.021086\n",
      "Train_Epoch : 68, [12800 / 60000](21%)\tTrain_loss : 0.009010\n",
      "Train_Epoch : 68, [25600 / 60000](43%)\tTrain_loss : 0.009509\n",
      "Train_Epoch : 68, [38400 / 60000](64%)\tTrain_loss : 0.016928\n",
      "Train_Epoch : 68, [51200 / 60000](85%)\tTrain_loss : 0.016626\n",
      "\n",
      "[EPOCH : 68, \tTest_loss : 0.0000, \tTest_Accuracy : 97.82%\n",
      "\n",
      "Train_Epoch : 69, [0 / 60000](0%)\tTrain_loss : 0.008299\n",
      "Train_Epoch : 69, [12800 / 60000](21%)\tTrain_loss : 0.015530\n",
      "Train_Epoch : 69, [25600 / 60000](43%)\tTrain_loss : 0.017114\n",
      "Train_Epoch : 69, [38400 / 60000](64%)\tTrain_loss : 0.019533\n",
      "Train_Epoch : 69, [51200 / 60000](85%)\tTrain_loss : 0.014470\n",
      "\n",
      "[EPOCH : 69, \tTest_loss : 0.0000, \tTest_Accuracy : 97.75%\n",
      "\n",
      "Train_Epoch : 70, [0 / 60000](0%)\tTrain_loss : 0.009684\n",
      "Train_Epoch : 70, [12800 / 60000](21%)\tTrain_loss : 0.030187\n",
      "Train_Epoch : 70, [25600 / 60000](43%)\tTrain_loss : 0.022663\n",
      "Train_Epoch : 70, [38400 / 60000](64%)\tTrain_loss : 0.028735\n",
      "Train_Epoch : 70, [51200 / 60000](85%)\tTrain_loss : 0.014606\n",
      "\n",
      "[EPOCH : 70, \tTest_loss : 0.0001, \tTest_Accuracy : 97.87%\n",
      "\n",
      "Train_Epoch : 71, [0 / 60000](0%)\tTrain_loss : 0.015741\n",
      "Train_Epoch : 71, [12800 / 60000](21%)\tTrain_loss : 0.013421\n",
      "Train_Epoch : 71, [25600 / 60000](43%)\tTrain_loss : 0.012386\n",
      "Train_Epoch : 71, [38400 / 60000](64%)\tTrain_loss : 0.016419\n",
      "Train_Epoch : 71, [51200 / 60000](85%)\tTrain_loss : 0.053861\n",
      "\n",
      "[EPOCH : 71, \tTest_loss : 0.0000, \tTest_Accuracy : 97.90%\n",
      "\n",
      "Train_Epoch : 72, [0 / 60000](0%)\tTrain_loss : 0.014112\n",
      "Train_Epoch : 72, [12800 / 60000](21%)\tTrain_loss : 0.011048\n",
      "Train_Epoch : 72, [25600 / 60000](43%)\tTrain_loss : 0.029843\n",
      "Train_Epoch : 72, [38400 / 60000](64%)\tTrain_loss : 0.010328\n",
      "Train_Epoch : 72, [51200 / 60000](85%)\tTrain_loss : 0.011322\n",
      "\n",
      "[EPOCH : 72, \tTest_loss : 0.0000, \tTest_Accuracy : 97.87%\n",
      "\n",
      "Train_Epoch : 73, [0 / 60000](0%)\tTrain_loss : 0.078572\n",
      "Train_Epoch : 73, [12800 / 60000](21%)\tTrain_loss : 0.009669\n",
      "Train_Epoch : 73, [25600 / 60000](43%)\tTrain_loss : 0.022358\n",
      "Train_Epoch : 73, [38400 / 60000](64%)\tTrain_loss : 0.010435\n",
      "Train_Epoch : 73, [51200 / 60000](85%)\tTrain_loss : 0.024105\n",
      "\n",
      "[EPOCH : 73, \tTest_loss : 0.0000, \tTest_Accuracy : 97.79%\n",
      "\n",
      "Train_Epoch : 74, [0 / 60000](0%)\tTrain_loss : 0.013829\n",
      "Train_Epoch : 74, [12800 / 60000](21%)\tTrain_loss : 0.015783\n",
      "Train_Epoch : 74, [25600 / 60000](43%)\tTrain_loss : 0.025647\n",
      "Train_Epoch : 74, [38400 / 60000](64%)\tTrain_loss : 0.055110\n",
      "Train_Epoch : 74, [51200 / 60000](85%)\tTrain_loss : 0.079205\n",
      "\n",
      "[EPOCH : 74, \tTest_loss : 0.0000, \tTest_Accuracy : 97.81%\n",
      "\n",
      "Train_Epoch : 75, [0 / 60000](0%)\tTrain_loss : 0.011432\n",
      "Train_Epoch : 75, [12800 / 60000](21%)\tTrain_loss : 0.006567\n",
      "Train_Epoch : 75, [25600 / 60000](43%)\tTrain_loss : 0.022779\n",
      "Train_Epoch : 75, [38400 / 60000](64%)\tTrain_loss : 0.013978\n",
      "Train_Epoch : 75, [51200 / 60000](85%)\tTrain_loss : 0.023684\n",
      "\n",
      "[EPOCH : 75, \tTest_loss : 0.0000, \tTest_Accuracy : 97.89%\n",
      "\n",
      "Train_Epoch : 76, [0 / 60000](0%)\tTrain_loss : 0.039808\n",
      "Train_Epoch : 76, [12800 / 60000](21%)\tTrain_loss : 0.010929\n",
      "Train_Epoch : 76, [25600 / 60000](43%)\tTrain_loss : 0.013871\n",
      "Train_Epoch : 76, [38400 / 60000](64%)\tTrain_loss : 0.014428\n",
      "Train_Epoch : 76, [51200 / 60000](85%)\tTrain_loss : 0.021712\n",
      "\n",
      "[EPOCH : 76, \tTest_loss : 0.0000, \tTest_Accuracy : 97.89%\n",
      "\n",
      "Train_Epoch : 77, [0 / 60000](0%)\tTrain_loss : 0.008323\n",
      "Train_Epoch : 77, [12800 / 60000](21%)\tTrain_loss : 0.007235\n",
      "Train_Epoch : 77, [25600 / 60000](43%)\tTrain_loss : 0.012204\n",
      "Train_Epoch : 77, [38400 / 60000](64%)\tTrain_loss : 0.009357\n",
      "Train_Epoch : 77, [51200 / 60000](85%)\tTrain_loss : 0.021091\n",
      "\n",
      "[EPOCH : 77, \tTest_loss : 0.0000, \tTest_Accuracy : 97.87%\n",
      "\n",
      "Train_Epoch : 78, [0 / 60000](0%)\tTrain_loss : 0.028439\n",
      "Train_Epoch : 78, [12800 / 60000](21%)\tTrain_loss : 0.026718\n",
      "Train_Epoch : 78, [25600 / 60000](43%)\tTrain_loss : 0.008769\n",
      "Train_Epoch : 78, [38400 / 60000](64%)\tTrain_loss : 0.013890\n",
      "Train_Epoch : 78, [51200 / 60000](85%)\tTrain_loss : 0.013254\n",
      "\n",
      "[EPOCH : 78, \tTest_loss : 0.0000, \tTest_Accuracy : 97.94%\n",
      "\n",
      "Train_Epoch : 79, [0 / 60000](0%)\tTrain_loss : 0.008470\n",
      "Train_Epoch : 79, [12800 / 60000](21%)\tTrain_loss : 0.010950\n",
      "Train_Epoch : 79, [25600 / 60000](43%)\tTrain_loss : 0.008863\n",
      "Train_Epoch : 79, [38400 / 60000](64%)\tTrain_loss : 0.012698\n",
      "Train_Epoch : 79, [51200 / 60000](85%)\tTrain_loss : 0.012097\n",
      "\n",
      "[EPOCH : 79, \tTest_loss : 0.0000, \tTest_Accuracy : 97.82%\n",
      "\n",
      "Train_Epoch : 80, [0 / 60000](0%)\tTrain_loss : 0.005857\n",
      "Train_Epoch : 80, [12800 / 60000](21%)\tTrain_loss : 0.007053\n",
      "Train_Epoch : 80, [25600 / 60000](43%)\tTrain_loss : 0.008562\n",
      "Train_Epoch : 80, [38400 / 60000](64%)\tTrain_loss : 0.018325\n",
      "Train_Epoch : 80, [51200 / 60000](85%)\tTrain_loss : 0.017864\n",
      "\n",
      "[EPOCH : 80, \tTest_loss : 0.0000, \tTest_Accuracy : 97.85%\n",
      "\n",
      "Train_Epoch : 81, [0 / 60000](0%)\tTrain_loss : 0.007217\n",
      "Train_Epoch : 81, [12800 / 60000](21%)\tTrain_loss : 0.020971\n",
      "Train_Epoch : 81, [25600 / 60000](43%)\tTrain_loss : 0.008358\n",
      "Train_Epoch : 81, [38400 / 60000](64%)\tTrain_loss : 0.019007\n",
      "Train_Epoch : 81, [51200 / 60000](85%)\tTrain_loss : 0.012992\n",
      "\n",
      "[EPOCH : 81, \tTest_loss : 0.0000, \tTest_Accuracy : 97.93%\n",
      "\n",
      "Train_Epoch : 82, [0 / 60000](0%)\tTrain_loss : 0.009815\n",
      "Train_Epoch : 82, [12800 / 60000](21%)\tTrain_loss : 0.013627\n",
      "Train_Epoch : 82, [25600 / 60000](43%)\tTrain_loss : 0.005635\n",
      "Train_Epoch : 82, [38400 / 60000](64%)\tTrain_loss : 0.013183\n",
      "Train_Epoch : 82, [51200 / 60000](85%)\tTrain_loss : 0.018596\n",
      "\n",
      "[EPOCH : 82, \tTest_loss : 0.0000, \tTest_Accuracy : 97.81%\n",
      "\n",
      "Train_Epoch : 83, [0 / 60000](0%)\tTrain_loss : 0.011096\n",
      "Train_Epoch : 83, [12800 / 60000](21%)\tTrain_loss : 0.004948\n",
      "Train_Epoch : 83, [25600 / 60000](43%)\tTrain_loss : 0.012328\n",
      "Train_Epoch : 83, [38400 / 60000](64%)\tTrain_loss : 0.011343\n",
      "Train_Epoch : 83, [51200 / 60000](85%)\tTrain_loss : 0.014339\n",
      "\n",
      "[EPOCH : 83, \tTest_loss : 0.0000, \tTest_Accuracy : 97.91%\n",
      "\n",
      "Train_Epoch : 84, [0 / 60000](0%)\tTrain_loss : 0.011432\n",
      "Train_Epoch : 84, [12800 / 60000](21%)\tTrain_loss : 0.078815\n",
      "Train_Epoch : 84, [25600 / 60000](43%)\tTrain_loss : 0.012791\n",
      "Train_Epoch : 84, [38400 / 60000](64%)\tTrain_loss : 0.007778\n",
      "Train_Epoch : 84, [51200 / 60000](85%)\tTrain_loss : 0.015871\n",
      "\n",
      "[EPOCH : 84, \tTest_loss : 0.0000, \tTest_Accuracy : 97.95%\n",
      "\n",
      "Train_Epoch : 85, [0 / 60000](0%)\tTrain_loss : 0.016911\n",
      "Train_Epoch : 85, [12800 / 60000](21%)\tTrain_loss : 0.005010\n",
      "Train_Epoch : 85, [25600 / 60000](43%)\tTrain_loss : 0.008173\n",
      "Train_Epoch : 85, [38400 / 60000](64%)\tTrain_loss : 0.007691\n",
      "Train_Epoch : 85, [51200 / 60000](85%)\tTrain_loss : 0.011341\n",
      "\n",
      "[EPOCH : 85, \tTest_loss : 0.0000, \tTest_Accuracy : 97.81%\n",
      "\n",
      "Train_Epoch : 86, [0 / 60000](0%)\tTrain_loss : 0.014410\n",
      "Train_Epoch : 86, [12800 / 60000](21%)\tTrain_loss : 0.010891\n",
      "Train_Epoch : 86, [25600 / 60000](43%)\tTrain_loss : 0.008446\n",
      "Train_Epoch : 86, [38400 / 60000](64%)\tTrain_loss : 0.006180\n",
      "Train_Epoch : 86, [51200 / 60000](85%)\tTrain_loss : 0.013745\n",
      "\n",
      "[EPOCH : 86, \tTest_loss : 0.0000, \tTest_Accuracy : 97.88%\n",
      "\n",
      "Train_Epoch : 87, [0 / 60000](0%)\tTrain_loss : 0.009657\n",
      "Train_Epoch : 87, [12800 / 60000](21%)\tTrain_loss : 0.007350\n",
      "Train_Epoch : 87, [25600 / 60000](43%)\tTrain_loss : 0.007003\n",
      "Train_Epoch : 87, [38400 / 60000](64%)\tTrain_loss : 0.009420\n",
      "Train_Epoch : 87, [51200 / 60000](85%)\tTrain_loss : 0.008679\n",
      "\n",
      "[EPOCH : 87, \tTest_loss : 0.0000, \tTest_Accuracy : 97.91%\n",
      "\n",
      "Train_Epoch : 88, [0 / 60000](0%)\tTrain_loss : 0.009363\n",
      "Train_Epoch : 88, [12800 / 60000](21%)\tTrain_loss : 0.005351\n",
      "Train_Epoch : 88, [25600 / 60000](43%)\tTrain_loss : 0.008430\n",
      "Train_Epoch : 88, [38400 / 60000](64%)\tTrain_loss : 0.006342\n",
      "Train_Epoch : 88, [51200 / 60000](85%)\tTrain_loss : 0.019919\n",
      "\n",
      "[EPOCH : 88, \tTest_loss : 0.0000, \tTest_Accuracy : 97.87%\n",
      "\n",
      "Train_Epoch : 89, [0 / 60000](0%)\tTrain_loss : 0.016601\n",
      "Train_Epoch : 89, [12800 / 60000](21%)\tTrain_loss : 0.006274\n",
      "Train_Epoch : 89, [25600 / 60000](43%)\tTrain_loss : 0.004456\n",
      "Train_Epoch : 89, [38400 / 60000](64%)\tTrain_loss : 0.009231\n",
      "Train_Epoch : 89, [51200 / 60000](85%)\tTrain_loss : 0.011149\n",
      "\n",
      "[EPOCH : 89, \tTest_loss : 0.0000, \tTest_Accuracy : 97.88%\n",
      "\n",
      "Train_Epoch : 90, [0 / 60000](0%)\tTrain_loss : 0.007252\n",
      "Train_Epoch : 90, [12800 / 60000](21%)\tTrain_loss : 0.005999\n",
      "Train_Epoch : 90, [25600 / 60000](43%)\tTrain_loss : 0.010560\n",
      "Train_Epoch : 90, [38400 / 60000](64%)\tTrain_loss : 0.011330\n",
      "Train_Epoch : 90, [51200 / 60000](85%)\tTrain_loss : 0.005982\n",
      "\n",
      "[EPOCH : 90, \tTest_loss : 0.0000, \tTest_Accuracy : 97.86%\n",
      "\n",
      "Train_Epoch : 91, [0 / 60000](0%)\tTrain_loss : 0.012406\n",
      "Train_Epoch : 91, [12800 / 60000](21%)\tTrain_loss : 0.008830\n",
      "Train_Epoch : 91, [25600 / 60000](43%)\tTrain_loss : 0.009972\n",
      "Train_Epoch : 91, [38400 / 60000](64%)\tTrain_loss : 0.014730\n",
      "Train_Epoch : 91, [51200 / 60000](85%)\tTrain_loss : 0.008638\n",
      "\n",
      "[EPOCH : 91, \tTest_loss : 0.0000, \tTest_Accuracy : 97.94%\n",
      "\n",
      "Train_Epoch : 92, [0 / 60000](0%)\tTrain_loss : 0.011543\n",
      "Train_Epoch : 92, [12800 / 60000](21%)\tTrain_loss : 0.007994\n",
      "Train_Epoch : 92, [25600 / 60000](43%)\tTrain_loss : 0.011953\n",
      "Train_Epoch : 92, [38400 / 60000](64%)\tTrain_loss : 0.011173\n",
      "Train_Epoch : 92, [51200 / 60000](85%)\tTrain_loss : 0.008632\n",
      "\n",
      "[EPOCH : 92, \tTest_loss : 0.0000, \tTest_Accuracy : 98.00%\n",
      "\n",
      "Train_Epoch : 93, [0 / 60000](0%)\tTrain_loss : 0.006656\n",
      "Train_Epoch : 93, [12800 / 60000](21%)\tTrain_loss : 0.007790\n",
      "Train_Epoch : 93, [25600 / 60000](43%)\tTrain_loss : 0.004007\n",
      "Train_Epoch : 93, [38400 / 60000](64%)\tTrain_loss : 0.007965\n",
      "Train_Epoch : 93, [51200 / 60000](85%)\tTrain_loss : 0.008970\n",
      "\n",
      "[EPOCH : 93, \tTest_loss : 0.0000, \tTest_Accuracy : 97.94%\n",
      "\n",
      "Train_Epoch : 94, [0 / 60000](0%)\tTrain_loss : 0.004185\n",
      "Train_Epoch : 94, [12800 / 60000](21%)\tTrain_loss : 0.005339\n",
      "Train_Epoch : 94, [25600 / 60000](43%)\tTrain_loss : 0.009795\n",
      "Train_Epoch : 94, [38400 / 60000](64%)\tTrain_loss : 0.004315\n",
      "Train_Epoch : 94, [51200 / 60000](85%)\tTrain_loss : 0.006622\n",
      "\n",
      "[EPOCH : 94, \tTest_loss : 0.0000, \tTest_Accuracy : 97.95%\n",
      "\n",
      "Train_Epoch : 95, [0 / 60000](0%)\tTrain_loss : 0.009653\n",
      "Train_Epoch : 95, [12800 / 60000](21%)\tTrain_loss : 0.005701\n",
      "Train_Epoch : 95, [25600 / 60000](43%)\tTrain_loss : 0.008066\n",
      "Train_Epoch : 95, [38400 / 60000](64%)\tTrain_loss : 0.006053\n",
      "Train_Epoch : 95, [51200 / 60000](85%)\tTrain_loss : 0.008020\n",
      "\n",
      "[EPOCH : 95, \tTest_loss : 0.0000, \tTest_Accuracy : 97.89%\n",
      "\n",
      "Train_Epoch : 96, [0 / 60000](0%)\tTrain_loss : 0.004745\n",
      "Train_Epoch : 96, [12800 / 60000](21%)\tTrain_loss : 0.007238\n",
      "Train_Epoch : 96, [25600 / 60000](43%)\tTrain_loss : 0.007507\n",
      "Train_Epoch : 96, [38400 / 60000](64%)\tTrain_loss : 0.007015\n",
      "Train_Epoch : 96, [51200 / 60000](85%)\tTrain_loss : 0.012002\n",
      "\n",
      "[EPOCH : 96, \tTest_loss : 0.0000, \tTest_Accuracy : 97.88%\n",
      "\n",
      "Train_Epoch : 97, [0 / 60000](0%)\tTrain_loss : 0.005164\n",
      "Train_Epoch : 97, [12800 / 60000](21%)\tTrain_loss : 0.011453\n",
      "Train_Epoch : 97, [25600 / 60000](43%)\tTrain_loss : 0.007635\n",
      "Train_Epoch : 97, [38400 / 60000](64%)\tTrain_loss : 0.005266\n",
      "Train_Epoch : 97, [51200 / 60000](85%)\tTrain_loss : 0.018877\n",
      "\n",
      "[EPOCH : 97, \tTest_loss : 0.0000, \tTest_Accuracy : 97.89%\n",
      "\n",
      "Train_Epoch : 98, [0 / 60000](0%)\tTrain_loss : 0.013984\n",
      "Train_Epoch : 98, [12800 / 60000](21%)\tTrain_loss : 0.008428\n",
      "Train_Epoch : 98, [25600 / 60000](43%)\tTrain_loss : 0.008947\n",
      "Train_Epoch : 98, [38400 / 60000](64%)\tTrain_loss : 0.050499\n",
      "Train_Epoch : 98, [51200 / 60000](85%)\tTrain_loss : 0.006353\n",
      "\n",
      "[EPOCH : 98, \tTest_loss : 0.0000, \tTest_Accuracy : 97.92%\n",
      "\n",
      "Train_Epoch : 99, [0 / 60000](0%)\tTrain_loss : 0.009044\n",
      "Train_Epoch : 99, [12800 / 60000](21%)\tTrain_loss : 0.003700\n",
      "Train_Epoch : 99, [25600 / 60000](43%)\tTrain_loss : 0.008364\n",
      "Train_Epoch : 99, [38400 / 60000](64%)\tTrain_loss : 0.007001\n",
      "Train_Epoch : 99, [51200 / 60000](85%)\tTrain_loss : 0.007538\n",
      "\n",
      "[EPOCH : 99, \tTest_loss : 0.0000, \tTest_Accuracy : 97.99%\n",
      "\n",
      "Train_Epoch : 100, [0 / 60000](0%)\tTrain_loss : 0.006560\n",
      "Train_Epoch : 100, [12800 / 60000](21%)\tTrain_loss : 0.006961\n",
      "Train_Epoch : 100, [25600 / 60000](43%)\tTrain_loss : 0.013291\n",
      "Train_Epoch : 100, [38400 / 60000](64%)\tTrain_loss : 0.019895\n",
      "Train_Epoch : 100, [51200 / 60000](85%)\tTrain_loss : 0.007310\n",
      "\n",
      "[EPOCH : 100, \tTest_loss : 0.0000, \tTest_Accuracy : 97.87%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "es = 0\n",
    "for Epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer)\n",
    "    test_loss , test_accuracy =  evaluate(model, test_loader)\n",
    "    if test_accuracy > best_accuracy :\n",
    "        best_model = model\n",
    "        best_accuracy = test_accuracy\n",
    "        es = 0\n",
    "    else :\n",
    "        es += 1\n",
    "    if es == 30 :\n",
    "        break\n",
    "    print('\\n[EPOCH : {}, \\tTest_loss : {:.4f}, \\tTest_Accuracy : {:.2f}%\\n'.format(\n",
    "        Epoch, test_loss, test_accuracy\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최고 정확도 :  98.0\n"
     ]
    }
   ],
   "source": [
    "print('최고 정확도 : ', best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "334544a737ead5017040ac753f52220319955d2381f512ab105ce194db781c37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
