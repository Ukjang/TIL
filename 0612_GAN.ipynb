{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image \n",
    "import numpy as np \n",
    "import math\n",
    "import os \n",
    "\n",
    "import tensorflow as tf  \n",
    "from keras.datasets import mnist, cifar10 \n",
    "from keras import models, layers, optimizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, \\\n",
    "                         Reshape, UpSampling2D, MaxPooling2D, Flatten\n",
    "import keras.backend as K \n",
    "print(K.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_4d(y_true, y_pred) :\n",
    "    return K.mean(K.square(y_pred - y_true), axis=(1, 2, 3))\n",
    "def mse_4d_tf(y_true, y_pred) :\n",
    "    # tf.reduce_mean 은 열단위로 연산\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_tre), axis = (1, 2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(Sequential) :\n",
    "    def __init__(self, input_dim = 32):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim \n",
    "        self.generator = self.GENERATOR()\n",
    "        self.discriminator = self.DISCRIMINATOR()\n",
    "        self.add(self.generator)\n",
    "        self.discriminator.trainable = False \n",
    "        self.add(self.discriminator)\n",
    "\n",
    "        self.compile_all() \n",
    "    \n",
    "    def compile_all(self) :\n",
    "        d_optim = optimizers.SGD(lr = 5e-4, momentum=0.9, nesterov= True)\n",
    "        g_optim = optimizers.SGD(lr = 5e-4, momentum=0.9, nesterov= True)\n",
    "        self.generator.compile(loss = mse_4d_tf, optimizer = 'SGD')\n",
    "        self.compile(loss = 'binary_crossentropy', optimizer = g_optim)\n",
    "        self.discriminator.trainable = True \n",
    "        self.discriminator.compile(loss = 'binary_crossentropy', optimizer = d_optim)\n",
    "\n",
    "    def GENERATOR(self) :\n",
    "        input_dim = self.input_dim \n",
    "\n",
    "        model = Sequential([\n",
    "            Dense(1024, activation='relu', input_dim = input_dim),\n",
    "            # CIFAR 10 은 32크기, MNIST는 28크기\n",
    "            Dense(7*7*128, activation='tanh'),\n",
    "            BatchNormalization(),\n",
    "            Reshape((7, 7, 128), input_shape = (7 * 7 * 128, )),\n",
    "            UpSampling2D(size = (2, 2)),\n",
    "            Conv2D(128, (5,5), padding ='same', activation='tanh'),\n",
    "            UpSampling2D(size = (2,2)),\n",
    "            # 컬러이면 Conv2D(3,~) / 흑백이면 1\n",
    "            Conv2D(1, (5, 5), padding = 'same', activation='tanh')\n",
    "        ])\n",
    "        return model \n",
    "    \n",
    "    def DISCRIMINATOR(self) :\n",
    "        model = Sequential([\n",
    "            Conv2D(128, (5, 5), padding = 'same', activation='tanh',\n",
    "                   input_shape = (28, 28, 1)),\n",
    "            MaxPooling2D(pool_size=(2, 2)),\n",
    "            Conv2D(256, (5, 5), activation='tanh'),\n",
    "            MaxPooling2D(pool_size = (2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(1024, activation='tanh'),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        return model \n",
    "    \n",
    "    def get_z(self, ln) :\n",
    "        input_dim = self.input_dim \n",
    "        return np.random.uniform(-1, 1, (ln, input_dim))\n",
    "\n",
    "    def train_both(self, x) :\n",
    "        ln = x.shape[0]\n",
    "        z = self.get_z(ln)\n",
    "        w = self.generator.predict(z, verbose = 0)\n",
    "        xw = np.concatenate((x, w))\n",
    "        y2 = np.array([1] * ln + [0] * ln).reshape(-1, 1)\n",
    "        d_loss = self.discriminator.train_on_batch(xw, y2)\n",
    "\n",
    "        z = self.get_z(ln)\n",
    "        self.discriminator.trainable = False \n",
    "        g_loss = self.train_on_batch(z, np.array([1] * ln).reshape(-1, 1))\n",
    "        self.discriminator.trainable = TabError\n",
    "\n",
    "        return d_loss, g_loss \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_images(generated_images) :\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num) / width))\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height * shape[0], width * shape[1]),\n",
    "                     dtype = generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images) :\n",
    "        i = int(index / width)\n",
    "        j = index % width \n",
    "        image[i * shape[0]:(i+1)*shape[0],\n",
    "              j*shape[1]:(j+1)*shape[1]] = img[: , : , 0]\n",
    "    return image \n",
    "\n",
    "def get_x(X_train, index, BATCH_SIZE) :\n",
    "    return X_train[index * BATCH_SIZE:(index + 1) * BATCH_SIZE]\n",
    "\n",
    "def save_images(generated_images, output_fold, epoch, index) :\n",
    "    image = combine_images(generated_images)\n",
    "    image = image * 127.5 + 127.5\n",
    "    Image.fromarray(image.astype(np.uint8)).save(\n",
    "        output_fold + '/' +\n",
    "        str(epoch) + '_' + str(index) + '.png'\n",
    "    )\n",
    "\n",
    "def load_data(n_train) :\n",
    "    (X_train, y_train), (_, _) = mnist.load_data() \n",
    "    return X_train[:n_train]\n",
    "\n",
    "def train(args) :\n",
    "    BATCH_SIZE = args.batch_size\n",
    "    epochs = args.epochs\n",
    "    output_fold = args.output_fold\n",
    "    input_dim = args.input_dim \n",
    "    n_train = args.n_train\n",
    "\n",
    "    os.makedirs(output_fold, exist_ok= True)\n",
    "    print('Output_fold is', output_fold)\n",
    "    \n",
    "    X_train = load_data(n_train)\n",
    "\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5 \n",
    "    X_train = X_train.reshape(X_train.shape + (1,))\n",
    "\n",
    "    gan = GAN(input_dim)\n",
    "\n",
    "    d_loss_ll = []\n",
    "    g_loss_ll = []\n",
    "    \n",
    "    for epoch in range(epochs) :\n",
    "        if epoch % 10 == 0 :\n",
    "            print('Epoch is', epoch)\n",
    "            print('Number of batches', int(X_train.shape[0] / BATCH_SIZE))\n",
    "\n",
    "        d_loss_l = []\n",
    "        g_loss_l = []\n",
    "        for index in range(int(X_train.shape[0] / BATCH_SIZE)) :\n",
    "            x = get_x(X_train, index, BATCH_SIZE)\n",
    "\n",
    "            d_loss, g_loss = gan.train_both(x)\n",
    "\n",
    "            d_loss_l.append(d_loss)\n",
    "            g_loss_l.append(g_loss)\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == epochs - 1 :\n",
    "            z = gan.get_z(x.shape[0])\n",
    "            w = gan.generator.predict(z, verbose = 0)\n",
    "            save_images(w, output_fold, epoch, 0)\n",
    "\n",
    "        d_loss_ll.append(d_loss_l)\n",
    "        g_loss_ll.append(g_loss_l)\n",
    "\n",
    "    gan.generator.save_weights(output_fold + '/' + 'generator', True)\n",
    "    gan .discriminator.save_weights(output_fold + '/' + 'discriminator', True)\n",
    "\n",
    "    np.savetxt(output_fold + '/' + 'd_loss' + d_loss_ll)\n",
    "    np.savetxt(output_fold + '/' + 'g_loss' , g_loss_ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output_fold is GAN_OUT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\tensor_gpu\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 0\n",
      "Number of batches 2\n",
      "Epoch is 10\n",
      "Number of batches 2\n",
      "Epoch is 20\n",
      "Number of batches 2\n",
      "Epoch is 30\n",
      "Number of batches 2\n",
      "Epoch is 40\n",
      "Number of batches 2\n",
      "Epoch is 50\n",
      "Number of batches 2\n",
      "Epoch is 60\n",
      "Number of batches 2\n",
      "Epoch is 70\n",
      "Number of batches 2\n",
      "Epoch is 80\n",
      "Number of batches 2\n",
      "Epoch is 90\n",
      "Number of batches 2\n",
      "Epoch is 100\n",
      "Number of batches 2\n",
      "Epoch is 110\n",
      "Number of batches 2\n",
      "Epoch is 120\n",
      "Number of batches 2\n",
      "Epoch is 130\n",
      "Number of batches 2\n",
      "Epoch is 140\n",
      "Number of batches 2\n",
      "Epoch is 150\n",
      "Number of batches 2\n",
      "Epoch is 160\n",
      "Number of batches 2\n",
      "Epoch is 170\n",
      "Number of batches 2\n",
      "Epoch is 180\n",
      "Number of batches 2\n",
      "Epoch is 190\n",
      "Number of batches 2\n",
      "Epoch is 200\n",
      "Number of batches 2\n",
      "Epoch is 210\n",
      "Number of batches 2\n",
      "Epoch is 220\n",
      "Number of batches 2\n",
      "Epoch is 230\n",
      "Number of batches 2\n",
      "Epoch is 240\n",
      "Number of batches 2\n",
      "Epoch is 250\n",
      "Number of batches 2\n",
      "Epoch is 260\n",
      "Number of batches 2\n",
      "Epoch is 270\n",
      "Number of batches 2\n",
      "Epoch is 280\n",
      "Number of batches 2\n",
      "Epoch is 290\n",
      "Number of batches 2\n",
      "Epoch is 300\n",
      "Number of batches 2\n",
      "Epoch is 310\n",
      "Number of batches 2\n",
      "Epoch is 320\n",
      "Number of batches 2\n",
      "Epoch is 330\n",
      "Number of batches 2\n",
      "Epoch is 340\n",
      "Number of batches 2\n",
      "Epoch is 350\n",
      "Number of batches 2\n",
      "Epoch is 360\n",
      "Number of batches 2\n",
      "Epoch is 370\n",
      "Number of batches 2\n",
      "Epoch is 380\n",
      "Number of batches 2\n",
      "Epoch is 390\n",
      "Number of batches 2\n",
      "Epoch is 400\n",
      "Number of batches 2\n",
      "Epoch is 410\n",
      "Number of batches 2\n",
      "Epoch is 420\n",
      "Number of batches 2\n",
      "Epoch is 430\n",
      "Number of batches 2\n",
      "Epoch is 440\n",
      "Number of batches 2\n",
      "Epoch is 450\n",
      "Number of batches 2\n",
      "Epoch is 460\n",
      "Number of batches 2\n",
      "Epoch is 470\n",
      "Number of batches 2\n",
      "Epoch is 480\n",
      "Number of batches 2\n",
      "Epoch is 490\n",
      "Number of batches 2\n",
      "Epoch is 500\n",
      "Number of batches 2\n",
      "Epoch is 510\n",
      "Number of batches 2\n",
      "Epoch is 520\n",
      "Number of batches 2\n",
      "Epoch is 530\n",
      "Number of batches 2\n",
      "Epoch is 540\n",
      "Number of batches 2\n",
      "Epoch is 550\n",
      "Number of batches 2\n",
      "Epoch is 560\n",
      "Number of batches 2\n",
      "Epoch is 570\n",
      "Number of batches 2\n",
      "Epoch is 580\n",
      "Number of batches 2\n",
      "Epoch is 590\n",
      "Number of batches 2\n",
      "Epoch is 600\n",
      "Number of batches 2\n",
      "Epoch is 610\n",
      "Number of batches 2\n",
      "Epoch is 620\n",
      "Number of batches 2\n",
      "Epoch is 630\n",
      "Number of batches 2\n",
      "Epoch is 640\n",
      "Number of batches 2\n",
      "Epoch is 650\n",
      "Number of batches 2\n",
      "Epoch is 660\n",
      "Number of batches 2\n",
      "Epoch is 670\n",
      "Number of batches 2\n",
      "Epoch is 680\n",
      "Number of batches 2\n",
      "Epoch is 690\n",
      "Number of batches 2\n",
      "Epoch is 700\n",
      "Number of batches 2\n",
      "Epoch is 710\n",
      "Number of batches 2\n",
      "Epoch is 720\n",
      "Number of batches 2\n",
      "Epoch is 730\n",
      "Number of batches 2\n",
      "Epoch is 740\n",
      "Number of batches 2\n",
      "Epoch is 750\n",
      "Number of batches 2\n",
      "Epoch is 760\n",
      "Number of batches 2\n",
      "Epoch is 770\n",
      "Number of batches 2\n",
      "Epoch is 780\n",
      "Number of batches 2\n",
      "Epoch is 790\n",
      "Number of batches 2\n",
      "Epoch is 800\n",
      "Number of batches 2\n",
      "Epoch is 810\n",
      "Number of batches 2\n",
      "Epoch is 820\n",
      "Number of batches 2\n",
      "Epoch is 830\n",
      "Number of batches 2\n",
      "Epoch is 840\n",
      "Number of batches 2\n",
      "Epoch is 850\n",
      "Number of batches 2\n",
      "Epoch is 860\n",
      "Number of batches 2\n",
      "Epoch is 870\n",
      "Number of batches 2\n",
      "Epoch is 880\n",
      "Number of batches 2\n",
      "Epoch is 890\n",
      "Number of batches 2\n",
      "Epoch is 900\n",
      "Number of batches 2\n",
      "Epoch is 910\n",
      "Number of batches 2\n",
      "Epoch is 920\n",
      "Number of batches 2\n",
      "Epoch is 930\n",
      "Number of batches 2\n",
      "Epoch is 940\n",
      "Number of batches 2\n",
      "Epoch is 950\n",
      "Number of batches 2\n",
      "Epoch is 960\n",
      "Number of batches 2\n",
      "Epoch is 970\n",
      "Number of batches 2\n",
      "Epoch is 980\n",
      "Number of batches 2\n",
      "Epoch is 990\n",
      "Number of batches 2\n",
      "Epoch is 1000\n",
      "Number of batches 2\n",
      "Epoch is 1010\n",
      "Number of batches 2\n",
      "Epoch is 1020\n",
      "Number of batches 2\n",
      "Epoch is 1030\n",
      "Number of batches 2\n",
      "Epoch is 1040\n",
      "Number of batches 2\n",
      "Epoch is 1050\n",
      "Number of batches 2\n",
      "Epoch is 1060\n",
      "Number of batches 2\n",
      "Epoch is 1070\n",
      "Number of batches 2\n",
      "Epoch is 1080\n",
      "Number of batches 2\n",
      "Epoch is 1090\n",
      "Number of batches 2\n",
      "Epoch is 1100\n",
      "Number of batches 2\n",
      "Epoch is 1110\n",
      "Number of batches 2\n",
      "Epoch is 1120\n",
      "Number of batches 2\n",
      "Epoch is 1130\n",
      "Number of batches 2\n",
      "Epoch is 1140\n",
      "Number of batches 2\n",
      "Epoch is 1150\n",
      "Number of batches 2\n",
      "Epoch is 1160\n",
      "Number of batches 2\n",
      "Epoch is 1170\n",
      "Number of batches 2\n",
      "Epoch is 1180\n",
      "Number of batches 2\n",
      "Epoch is 1190\n",
      "Number of batches 2\n",
      "Epoch is 1200\n",
      "Number of batches 2\n",
      "Epoch is 1210\n",
      "Number of batches 2\n",
      "Epoch is 1220\n",
      "Number of batches 2\n",
      "Epoch is 1230\n",
      "Number of batches 2\n",
      "Epoch is 1240\n",
      "Number of batches 2\n",
      "Epoch is 1250\n",
      "Number of batches 2\n",
      "Epoch is 1260\n",
      "Number of batches 2\n",
      "Epoch is 1270\n",
      "Number of batches 2\n",
      "Epoch is 1280\n",
      "Number of batches 2\n",
      "Epoch is 1290\n",
      "Number of batches 2\n",
      "Epoch is 1300\n",
      "Number of batches 2\n",
      "Epoch is 1310\n",
      "Number of batches 2\n",
      "Epoch is 1320\n",
      "Number of batches 2\n",
      "Epoch is 1330\n",
      "Number of batches 2\n",
      "Epoch is 1340\n",
      "Number of batches 2\n",
      "Epoch is 1350\n",
      "Number of batches 2\n",
      "Epoch is 1360\n",
      "Number of batches 2\n",
      "Epoch is 1370\n",
      "Number of batches 2\n",
      "Epoch is 1380\n",
      "Number of batches 2\n",
      "Epoch is 1390\n",
      "Number of batches 2\n",
      "Epoch is 1400\n",
      "Number of batches 2\n",
      "Epoch is 1410\n",
      "Number of batches 2\n",
      "Epoch is 1420\n",
      "Number of batches 2\n",
      "Epoch is 1430\n",
      "Number of batches 2\n",
      "Epoch is 1440\n",
      "Number of batches 2\n",
      "Epoch is 1450\n",
      "Number of batches 2\n",
      "Epoch is 1460\n",
      "Number of batches 2\n",
      "Epoch is 1470\n",
      "Number of batches 2\n",
      "Epoch is 1480\n",
      "Number of batches 2\n",
      "Epoch is 1490\n",
      "Number of batches 2\n",
      "Epoch is 1500\n",
      "Number of batches 2\n",
      "Epoch is 1510\n",
      "Number of batches 2\n",
      "Epoch is 1520\n",
      "Number of batches 2\n",
      "Epoch is 1530\n",
      "Number of batches 2\n",
      "Epoch is 1540\n",
      "Number of batches 2\n",
      "Epoch is 1550\n",
      "Number of batches 2\n",
      "Epoch is 1560\n",
      "Number of batches 2\n",
      "Epoch is 1570\n",
      "Number of batches 2\n",
      "Epoch is 1580\n",
      "Number of batches 2\n",
      "Epoch is 1590\n",
      "Number of batches 2\n",
      "Epoch is 1600\n",
      "Number of batches 2\n",
      "Epoch is 1610\n",
      "Number of batches 2\n",
      "Epoch is 1620\n",
      "Number of batches 2\n",
      "Epoch is 1630\n",
      "Number of batches 2\n",
      "Epoch is 1640\n",
      "Number of batches 2\n",
      "Epoch is 1650\n",
      "Number of batches 2\n",
      "Epoch is 1660\n",
      "Number of batches 2\n",
      "Epoch is 1670\n",
      "Number of batches 2\n",
      "Epoch is 1680\n",
      "Number of batches 2\n",
      "Epoch is 1690\n",
      "Number of batches 2\n",
      "Epoch is 1700\n",
      "Number of batches 2\n",
      "Epoch is 1710\n",
      "Number of batches 2\n",
      "Epoch is 1720\n",
      "Number of batches 2\n",
      "Epoch is 1730\n",
      "Number of batches 2\n",
      "Epoch is 1740\n",
      "Number of batches 2\n",
      "Epoch is 1750\n",
      "Number of batches 2\n",
      "Epoch is 1760\n",
      "Number of batches 2\n",
      "Epoch is 1770\n",
      "Number of batches 2\n",
      "Epoch is 1780\n",
      "Number of batches 2\n",
      "Epoch is 1790\n",
      "Number of batches 2\n",
      "Epoch is 1800\n",
      "Number of batches 2\n",
      "Epoch is 1810\n",
      "Number of batches 2\n",
      "Epoch is 1820\n",
      "Number of batches 2\n",
      "Epoch is 1830\n",
      "Number of batches 2\n",
      "Epoch is 1840\n",
      "Number of batches 2\n",
      "Epoch is 1850\n",
      "Number of batches 2\n",
      "Epoch is 1860\n",
      "Number of batches 2\n",
      "Epoch is 1870\n",
      "Number of batches 2\n",
      "Epoch is 1880\n",
      "Number of batches 2\n",
      "Epoch is 1890\n",
      "Number of batches 2\n",
      "Epoch is 1900\n",
      "Number of batches 2\n",
      "Epoch is 1910\n",
      "Number of batches 2\n",
      "Epoch is 1920\n",
      "Number of batches 2\n",
      "Epoch is 1930\n",
      "Number of batches 2\n",
      "Epoch is 1940\n",
      "Number of batches 2\n",
      "Epoch is 1950\n",
      "Number of batches 2\n",
      "Epoch is 1960\n",
      "Number of batches 2\n",
      "Epoch is 1970\n",
      "Number of batches 2\n",
      "Epoch is 1980\n",
      "Number of batches 2\n",
      "Epoch is 1990\n",
      "Number of batches 2\n",
      "Epoch is 2000\n",
      "Number of batches 2\n",
      "Epoch is 2010\n",
      "Number of batches 2\n",
      "Epoch is 2020\n",
      "Number of batches 2\n",
      "Epoch is 2030\n",
      "Number of batches 2\n",
      "Epoch is 2040\n",
      "Number of batches 2\n",
      "Epoch is 2050\n",
      "Number of batches 2\n",
      "Epoch is 2060\n",
      "Number of batches 2\n",
      "Epoch is 2070\n",
      "Number of batches 2\n",
      "Epoch is 2080\n",
      "Number of batches 2\n",
      "Epoch is 2090\n",
      "Number of batches 2\n",
      "Epoch is 2100\n",
      "Number of batches 2\n",
      "Epoch is 2110\n",
      "Number of batches 2\n",
      "Epoch is 2120\n",
      "Number of batches 2\n",
      "Epoch is 2130\n",
      "Number of batches 2\n",
      "Epoch is 2140\n",
      "Number of batches 2\n",
      "Epoch is 2150\n",
      "Number of batches 2\n",
      "Epoch is 2160\n",
      "Number of batches 2\n",
      "Epoch is 2170\n",
      "Number of batches 2\n",
      "Epoch is 2180\n",
      "Number of batches 2\n",
      "Epoch is 2190\n",
      "Number of batches 2\n",
      "Epoch is 2200\n",
      "Number of batches 2\n",
      "Epoch is 2210\n",
      "Number of batches 2\n",
      "Epoch is 2220\n",
      "Number of batches 2\n",
      "Epoch is 2230\n",
      "Number of batches 2\n",
      "Epoch is 2240\n",
      "Number of batches 2\n",
      "Epoch is 2250\n",
      "Number of batches 2\n",
      "Epoch is 2260\n",
      "Number of batches 2\n",
      "Epoch is 2270\n",
      "Number of batches 2\n",
      "Epoch is 2280\n",
      "Number of batches 2\n",
      "Epoch is 2290\n",
      "Number of batches 2\n",
      "Epoch is 2300\n",
      "Number of batches 2\n",
      "Epoch is 2310\n",
      "Number of batches 2\n",
      "Epoch is 2320\n",
      "Number of batches 2\n",
      "Epoch is 2330\n",
      "Number of batches 2\n",
      "Epoch is 2340\n",
      "Number of batches 2\n",
      "Epoch is 2350\n",
      "Number of batches 2\n",
      "Epoch is 2360\n",
      "Number of batches 2\n",
      "Epoch is 2370\n",
      "Number of batches 2\n",
      "Epoch is 2380\n",
      "Number of batches 2\n",
      "Epoch is 2390\n",
      "Number of batches 2\n",
      "Epoch is 2400\n",
      "Number of batches 2\n",
      "Epoch is 2410\n",
      "Number of batches 2\n",
      "Epoch is 2420\n",
      "Number of batches 2\n",
      "Epoch is 2430\n",
      "Number of batches 2\n",
      "Epoch is 2440\n",
      "Number of batches 2\n",
      "Epoch is 2450\n",
      "Number of batches 2\n",
      "Epoch is 2460\n",
      "Number of batches 2\n",
      "Epoch is 2470\n",
      "Number of batches 2\n",
      "Epoch is 2480\n",
      "Number of batches 2\n",
      "Epoch is 2490\n",
      "Number of batches 2\n",
      "Epoch is 2500\n",
      "Number of batches 2\n",
      "Epoch is 2510\n",
      "Number of batches 2\n",
      "Epoch is 2520\n",
      "Number of batches 2\n",
      "Epoch is 2530\n",
      "Number of batches 2\n",
      "Epoch is 2540\n",
      "Number of batches 2\n",
      "Epoch is 2550\n",
      "Number of batches 2\n",
      "Epoch is 2560\n",
      "Number of batches 2\n",
      "Epoch is 2570\n",
      "Number of batches 2\n",
      "Epoch is 2580\n",
      "Number of batches 2\n",
      "Epoch is 2590\n",
      "Number of batches 2\n",
      "Epoch is 2600\n",
      "Number of batches 2\n",
      "Epoch is 2610\n",
      "Number of batches 2\n",
      "Epoch is 2620\n",
      "Number of batches 2\n",
      "Epoch is 2630\n",
      "Number of batches 2\n",
      "Epoch is 2640\n",
      "Number of batches 2\n",
      "Epoch is 2650\n",
      "Number of batches 2\n",
      "Epoch is 2660\n",
      "Number of batches 2\n",
      "Epoch is 2670\n",
      "Number of batches 2\n",
      "Epoch is 2680\n",
      "Number of batches 2\n",
      "Epoch is 2690\n",
      "Number of batches 2\n",
      "Epoch is 2700\n",
      "Number of batches 2\n",
      "Epoch is 2710\n",
      "Number of batches 2\n",
      "Epoch is 2720\n",
      "Number of batches 2\n",
      "Epoch is 2730\n",
      "Number of batches 2\n",
      "Epoch is 2740\n",
      "Number of batches 2\n",
      "Epoch is 2750\n",
      "Number of batches 2\n",
      "Epoch is 2760\n",
      "Number of batches 2\n",
      "Epoch is 2770\n",
      "Number of batches 2\n",
      "Epoch is 2780\n",
      "Number of batches 2\n",
      "Epoch is 2790\n",
      "Number of batches 2\n",
      "Epoch is 2800\n",
      "Number of batches 2\n",
      "Epoch is 2810\n",
      "Number of batches 2\n",
      "Epoch is 2820\n",
      "Number of batches 2\n",
      "Epoch is 2830\n",
      "Number of batches 2\n",
      "Epoch is 2840\n",
      "Number of batches 2\n",
      "Epoch is 2850\n",
      "Number of batches 2\n",
      "Epoch is 2860\n",
      "Number of batches 2\n",
      "Epoch is 2870\n",
      "Number of batches 2\n",
      "Epoch is 2880\n",
      "Number of batches 2\n",
      "Epoch is 2890\n",
      "Number of batches 2\n",
      "Epoch is 2900\n",
      "Number of batches 2\n",
      "Epoch is 2910\n",
      "Number of batches 2\n",
      "Epoch is 2920\n",
      "Number of batches 2\n",
      "Epoch is 2930\n",
      "Number of batches 2\n",
      "Epoch is 2940\n",
      "Number of batches 2\n",
      "Epoch is 2950\n",
      "Number of batches 2\n",
      "Epoch is 2960\n",
      "Number of batches 2\n",
      "Epoch is 2970\n",
      "Number of batches 2\n",
      "Epoch is 2980\n",
      "Number of batches 2\n",
      "Epoch is 2990\n",
      "Number of batches 2\n",
      "Epoch is 3000\n",
      "Number of batches 2\n",
      "Epoch is 3010\n",
      "Number of batches 2\n",
      "Epoch is 3020\n",
      "Number of batches 2\n",
      "Epoch is 3030\n",
      "Number of batches 2\n",
      "Epoch is 3040\n",
      "Number of batches 2\n",
      "Epoch is 3050\n",
      "Number of batches 2\n",
      "Epoch is 3060\n",
      "Number of batches 2\n",
      "Epoch is 3070\n",
      "Number of batches 2\n",
      "Epoch is 3080\n",
      "Number of batches 2\n",
      "Epoch is 3090\n",
      "Number of batches 2\n",
      "Epoch is 3100\n",
      "Number of batches 2\n",
      "Epoch is 3110\n",
      "Number of batches 2\n",
      "Epoch is 3120\n",
      "Number of batches 2\n",
      "Epoch is 3130\n",
      "Number of batches 2\n",
      "Epoch is 3140\n",
      "Number of batches 2\n",
      "Epoch is 3150\n",
      "Number of batches 2\n",
      "Epoch is 3160\n",
      "Number of batches 2\n",
      "Epoch is 3170\n",
      "Number of batches 2\n",
      "Epoch is 3180\n",
      "Number of batches 2\n",
      "Epoch is 3190\n",
      "Number of batches 2\n",
      "Epoch is 3200\n",
      "Number of batches 2\n",
      "Epoch is 3210\n",
      "Number of batches 2\n",
      "Epoch is 3220\n",
      "Number of batches 2\n",
      "Epoch is 3230\n",
      "Number of batches 2\n",
      "Epoch is 3240\n",
      "Number of batches 2\n",
      "Epoch is 3250\n",
      "Number of batches 2\n",
      "Epoch is 3260\n",
      "Number of batches 2\n",
      "Epoch is 3270\n",
      "Number of batches 2\n",
      "Epoch is 3280\n",
      "Number of batches 2\n",
      "Epoch is 3290\n",
      "Number of batches 2\n",
      "Epoch is 3300\n",
      "Number of batches 2\n",
      "Epoch is 3310\n",
      "Number of batches 2\n",
      "Epoch is 3320\n",
      "Number of batches 2\n",
      "Epoch is 3330\n",
      "Number of batches 2\n",
      "Epoch is 3340\n",
      "Number of batches 2\n",
      "Epoch is 3350\n",
      "Number of batches 2\n",
      "Epoch is 3360\n",
      "Number of batches 2\n",
      "Epoch is 3370\n",
      "Number of batches 2\n",
      "Epoch is 3380\n",
      "Number of batches 2\n",
      "Epoch is 3390\n",
      "Number of batches 2\n",
      "Epoch is 3400\n",
      "Number of batches 2\n",
      "Epoch is 3410\n",
      "Number of batches 2\n",
      "Epoch is 3420\n",
      "Number of batches 2\n",
      "Epoch is 3430\n",
      "Number of batches 2\n",
      "Epoch is 3440\n",
      "Number of batches 2\n",
      "Epoch is 3450\n",
      "Number of batches 2\n",
      "Epoch is 3460\n",
      "Number of batches 2\n",
      "Epoch is 3470\n",
      "Number of batches 2\n",
      "Epoch is 3480\n",
      "Number of batches 2\n",
      "Epoch is 3490\n",
      "Number of batches 2\n",
      "Epoch is 3500\n",
      "Number of batches 2\n",
      "Epoch is 3510\n",
      "Number of batches 2\n",
      "Epoch is 3520\n",
      "Number of batches 2\n",
      "Epoch is 3530\n",
      "Number of batches 2\n",
      "Epoch is 3540\n",
      "Number of batches 2\n",
      "Epoch is 3550\n",
      "Number of batches 2\n",
      "Epoch is 3560\n",
      "Number of batches 2\n",
      "Epoch is 3570\n",
      "Number of batches 2\n",
      "Epoch is 3580\n",
      "Number of batches 2\n",
      "Epoch is 3590\n",
      "Number of batches 2\n",
      "Epoch is 3600\n",
      "Number of batches 2\n",
      "Epoch is 3610\n",
      "Number of batches 2\n",
      "Epoch is 3620\n",
      "Number of batches 2\n",
      "Epoch is 3630\n",
      "Number of batches 2\n",
      "Epoch is 3640\n",
      "Number of batches 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m     args \u001b[39m=\u001b[39m ARGS()\n\u001b[0;32m     10\u001b[0m     train(args)\n\u001b[1;32m---> 11\u001b[0m main()\n",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m         args\u001b[39m.\u001b[39mn_train \u001b[39m=\u001b[39m \u001b[39m128\u001b[39m\n\u001b[0;32m      9\u001b[0m args \u001b[39m=\u001b[39m ARGS()\n\u001b[1;32m---> 10\u001b[0m train(args)\n",
      "Cell \u001b[1;32mIn[4], line 60\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mint\u001b[39m(X_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m/\u001b[39m BATCH_SIZE)) :\n\u001b[0;32m     58\u001b[0m     x \u001b[39m=\u001b[39m get_x(X_train, index, BATCH_SIZE)\n\u001b[1;32m---> 60\u001b[0m     d_loss, g_loss \u001b[39m=\u001b[39m gan\u001b[39m.\u001b[39;49mtrain_both(x)\n\u001b[0;32m     62\u001b[0m     d_loss_l\u001b[39m.\u001b[39mappend(d_loss)\n\u001b[0;32m     63\u001b[0m     g_loss_l\u001b[39m.\u001b[39mappend(g_loss)\n",
      "Cell \u001b[1;32mIn[3], line 61\u001b[0m, in \u001b[0;36mGAN.train_both\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     59\u001b[0m xw \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((x, w))\n\u001b[0;32m     60\u001b[0m y2 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m ln \u001b[39m+\u001b[39m [\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m ln)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m---> 61\u001b[0m d_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdiscriminator\u001b[39m.\u001b[39;49mtrain_on_batch(xw, y2)\n\u001b[0;32m     63\u001b[0m z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_z(ln)\n\u001b[0;32m     64\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdiscriminator\u001b[39m.\u001b[39mtrainable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m \n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\tensor_gpu\\lib\\site-packages\\keras\\engine\\training.py:2383\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   2380\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_train_function()\n\u001b[0;32m   2381\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m-> 2383\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   2384\u001b[0m \u001b[39mif\u001b[39;00m return_dict:\n\u001b[0;32m   2385\u001b[0m     \u001b[39mreturn\u001b[39;00m logs\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\tensor_gpu\\lib\\site-packages\\keras\\utils\\tf_utils.py:635\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[0;32m    633\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[1;32m--> 635\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\tensor_gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\tensor_gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\tensor_gpu\\lib\\site-packages\\keras\\utils\\tf_utils.py:628\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    626\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m--> 628\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    629\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[0;32m    631\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\tensor_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1157\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m \n\u001b[0;32m   1136\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1154\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1157\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1158\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32mc:\\Users\\Admin\\anaconda3\\envs\\tensor_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1123\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1122\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[0;32m   1124\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main() :\n",
    "    class ARGS :\n",
    "        def __init__(args):\n",
    "            args.batch_size = 64\n",
    "            args.epochs = 4000\n",
    "            args.output_fold = 'GAN_OUT'\n",
    "            args.input_dim = 10\n",
    "            args.n_train = 128\n",
    "    args = ARGS()\n",
    "    train(args)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
